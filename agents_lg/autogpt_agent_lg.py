#!/usr/bin/env python3
"""
AutoGPT — Generated by OpenClaw Instantiation Engine (LangGraph backend)
Spec: Goal-driven autonomous agent with planning, self-criticism, and iterative execution
"""

import json
import operator
import os
import sys
import time
from datetime import datetime
from typing import Any, TypedDict, Annotated

from langgraph.graph import StateGraph, END

# ═══════════════════════════════════════════════════════════
# Trace Log
# ═══════════════════════════════════════════════════════════

TRACE = []

def trace_call(agent_label, model, system_prompt, user_message, response, duration_ms):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "agent": agent_label,
        "model": model,
        "system_prompt": system_prompt,
        "user_message": user_message,
        "response": response,
        "duration_ms": duration_ms,
    }
    TRACE.append(entry)
    print(f"    [{agent_label}] ({model}, {duration_ms}ms)")
    print(f"      IN:  {user_message[:300]}")
    print(f"      OUT: {response[:300]}")


def dump_trace(path="trace.json", iterations=0, clean_exit=True):
    total_ms = sum(e["duration_ms"] for e in TRACE)
    agents_used = list(set(e["agent"] for e in TRACE))
    schema_ok = 0
    for e in TRACE:
        try:
            r = e["response"].strip()
            if r.startswith("```"): r = "\n".join(r.split("\n")[1:-1])
            json.loads(r if r.startswith("{") else r[r.find("{"):r.rfind("}")+1])
            schema_ok += 1
        except (json.JSONDecodeError, ValueError):
            pass
    est_input_tokens = sum(len(e.get("user_message",""))//4 for e in TRACE)
    est_output_tokens = sum(len(e.get("response",""))//4 for e in TRACE)
    metrics = {
        "total_llm_calls": len(TRACE),
        "total_duration_ms": total_ms,
        "avg_call_ms": total_ms // max(len(TRACE), 1),
        "iterations": iterations,
        "clean_exit": clean_exit,
        "agents_used": agents_used,
        "schema_compliance": f"{schema_ok}/{len(TRACE)}",
        "est_input_tokens": est_input_tokens,
        "est_output_tokens": est_output_tokens,
    }
    output = {"metrics": metrics, "trace": TRACE}
    with open(path, "w") as f:
        json.dump(output, f, indent=2)
    print(f"\nTrace written to {path} ({len(TRACE)} calls, {total_ms}ms total)")
    print(f"  Schema compliance: {schema_ok}/{len(TRACE)}, est tokens: ~{est_input_tokens}in/~{est_output_tokens}out")
    return metrics

# ═══════════════════════════════════════════════════════════
# LLM Call Infrastructure
# ═══════════════════════════════════════════════════════════

_MODEL_OVERRIDE = os.environ.get("OPENCLAW_MODEL", "")
_OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")


def _openrouter_model_id(model):
    """Map spec model names to OpenRouter model IDs (provider/model format)."""
    if "/" in model:
        return model
    if model.startswith("gemini"):
        return f"google/{model}"
    if model.startswith("claude") or model.startswith("anthropic"):
        return f"anthropic/{model}"
    if model.startswith("gpt") or model.startswith("o1") or model.startswith("o3"):
        return f"openai/{model}"
    return model


def _get_chat_model(model, temperature=0.7, max_tokens=4096):
    """Get a LangChain ChatModel instance for the given model name."""
    if _OPENROUTER_API_KEY:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=_openrouter_model_id(model),
            temperature=temperature,
            max_tokens=max_tokens,
            base_url="https://openrouter.ai/api/v1",
            api_key=_OPENROUTER_API_KEY,
        )
    if model.startswith("gemini"):
        from langchain_google_genai import ChatGoogleGenerativeAI
        return ChatGoogleGenerativeAI(model=model, temperature=temperature,
                                      max_output_tokens=max_tokens,
                                      google_api_key=os.environ.get("GEMINI_API_KEY", ""))
    elif model.startswith("claude") or model.startswith("anthropic"):
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(model=model, temperature=temperature, max_tokens=max_tokens)
    else:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(model=model, temperature=temperature, max_tokens=max_tokens)


def call_llm(model, system_prompt, user_message, temperature=0.7, max_tokens=4096, retries=3):
    if _MODEL_OVERRIDE:
        model = _MODEL_OVERRIDE
    from langchain_core.messages import SystemMessage, HumanMessage
    for attempt in range(retries):
        try:
            chat = _get_chat_model(model, temperature, max_tokens)
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_message)]
            response = chat.invoke(messages)
            content = response.content
            # LangChain may return content as a list of blocks (e.g. Gemini)
            if isinstance(content, list):
                content = " ".join(b.get("text", str(b)) if isinstance(b, dict) else str(b) for b in content)
            return content
        except Exception as e:
            if attempt < retries - 1:
                wait = 2 ** attempt
                print(f"    [RETRY] {type(e).__name__}: {e} — retrying in {wait}s (attempt {attempt+1}/{retries})")
                import time as _time; _time.sleep(wait)
            else:
                print(f"    [FAIL] {type(e).__name__}: {e} after {retries} attempts")
                return json.dumps({"stub": True, "model": model, "error": str(e)})

# ═══════════════════════════════════════════════════════════
# Schema Registry
# ═══════════════════════════════════════════════════════════

SCHEMAS = {
    "PlanInput": {
        "description": """Input to the planner""",
        "fields": [{"name": "objective", "type": "string"}, {"name": "constraints", "type": "list<string>"}],
    },
    "Plan": {
        "description": """A plan of action steps""",
        "fields": [{"name": "plan", "type": "list<string>"}, {"name": "objective", "type": "string"}],
    },
    "ThinkInput": {
        "description": """Input to the thinker""",
        "fields": [{"name": "objective", "type": "string"}, {"name": "current_step", "type": "string"}, {"name": "results", "type": "list<string>"}, {"name": "stored_memories", "type": "list<string>"}, {"name": "feedback", "type": "string"}],
    },
    "Thought": {
        "description": """Reasoning output""",
        "fields": [{"name": "reasoning", "type": "string"}, {"name": "proposed_action", "type": "string"}],
    },
    "CriticInput": {
        "description": """Input to the critic""",
        "fields": [{"name": "objective", "type": "string"}, {"name": "current_step", "type": "string"}, {"name": "reasoning", "type": "string"}, {"name": "proposed_action", "type": "string"}],
    },
    "Criticism": {
        "description": """Critic evaluation""",
        "fields": [{"name": "rating", "type": "integer"}, {"name": "approved", "type": "boolean"}, {"name": "improvements", "type": "string"}],
    },
    "ActionInput": {
        "description": """Input to executor""",
        "fields": [{"name": "proposed_action", "type": "string"}, {"name": "current_step", "type": "string"}, {"name": "objective", "type": "string"}],
    },
    "ActionResult": {
        "description": """Result of action execution""",
        "fields": [{"name": "action_result", "type": "string"}, {"name": "success", "type": "boolean"}],
    },
    "MemoryEntry": {
        "description": """Memory entry for vector store""",
        "fields": [{"name": "text", "type": "string"}, {"name": "embedding", "type": "list<float>"}, {"name": "metadata", "type": "object"}],
    },
    "WorkspaceEntry": {
        "description": """Workspace key-value entry""",
        "fields": [{"name": "key", "type": "string"}, {"name": "value", "type": "string"}],
    },
}


def validate_output(data, schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema or "raw" in data:
        return []
    issues = []
    for field in schema["fields"]:
        fname = field["name"]
        ftype = field["type"]
        if fname not in data:
            issues.append(f"Missing field '{fname}' ({ftype})")
            continue
        val = data[fname]
        if ftype == "string" and not isinstance(val, str):
            issues.append(f"Field '{fname}' expected string, got {type(val).__name__}")
        elif ftype == "integer" and not isinstance(val, (int, float)):
            issues.append(f"Field '{fname}' expected integer, got {type(val).__name__}")
        elif ftype.startswith("list") and not isinstance(val, list):
            issues.append(f"Field '{fname}' expected list, got {type(val).__name__}")
        elif ftype.startswith("enum["):
            allowed = [v.strip() for v in ftype[5:-1].split(",")]
            if val not in allowed:
                issues.append(f"Field '{fname}' value '{val}' not in {allowed}")
    if issues:
        print(f"    [SCHEMA] {schema_name}: {len(issues)} issue(s): {issues[0]}")
    return issues


def build_input(state, schema_name):
    """Build an input dict for an agent call using schema field names."""
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return dict(state)
    result = {}
    for field in schema["fields"]:
        fname = field["name"]
        if fname in state:
            result[fname] = state[fname]
        else:
            for _k, _v in state.items():
                if isinstance(_v, dict) and fname in _v:
                    result[fname] = _v[fname]
                    break
    return result


def output_instruction(schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return ""
    fields = ", ".join(f'"{f["name"]}": <{f["type"]}>' for f in schema["fields"])
    return f"\n\nRespond with ONLY valid JSON matching this schema: {{{fields}}}"


def parse_response(response, schema_name):
    import re as _re
    text = response.strip()
    if text.startswith("```"):
        lines = text.split("\n")
        lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        text = "\n".join(lines)
    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
        return {"value": parsed}
    except json.JSONDecodeError:
        pass
    start = text.find("{")
    end = text.rfind("}") + 1
    if start >= 0 and end > start:
        candidate = text[start:end]
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass
        fixed = _re.sub(r",\s*}", "}", candidate)
        fixed = _re.sub(r",\s*]", "]", fixed)
        try:
            return json.loads(fixed)
        except json.JSONDecodeError:
            pass
        depth = 0
        for i, ch in enumerate(text[start:], start):
            if ch == "{": depth += 1
            elif ch == "}": depth -= 1
            if depth == 0:
                try:
                    return json.loads(text[start:i+1])
                except json.JSONDecodeError:
                    break
    return {"raw": response}

# ═══════════════════════════════════════════════════════════
# State TypedDict
# ═══════════════════════════════════════════════════════════

class AgentState(TypedDict, total=False):
    """Typed state for AutoGPT"""
    _canned_responses: list
    _done: bool
    _iteration: int
    _schema_violations: Annotated[int, operator.add]
    act_result: Any
    action_result: str
    approved: bool
    completed_steps: Any
    constraints: list
    criticism_count: Any
    criticize_result: Any
    current_step: str
    current_step_idx: Any
    decompose_result: Any
    embedding: list
    feedback: str
    improvements: str
    key: str
    max_criticism_retries: Any
    memory_store: list
    metadata: Any
    objective: str
    plan: list
    proposed_action: str
    rating: int
    reasoning: str
    results: list
    stored_memories: list
    success: bool
    text: str
    think_result: Any
    total_steps: Any
    value: str
    workspace: dict


# ═══════════════════════════════════════════════════════════
# Stores
# ═══════════════════════════════════════════════════════════

try:
    import chromadb
    _chroma_client = chromadb.Client()
    _USE_CHROMA = True
except ImportError:
    _USE_CHROMA = False


class _ChromaVectorStore:
    def __init__(self, name):
        self._fallback = []
        self._collection = None
        if _USE_CHROMA:
            self._collection = _chroma_client.get_or_create_collection(name)
        else:
            print(f"    [VectorStore] using in-memory fallback")

    def read(self, query=None, top_k=5):
        if self._collection is not None:
            if query:
                results = self._collection.query(query_texts=[query], n_results=min(top_k, max(self._collection.count(), 1)))
                docs = results.get("documents", [[]])[0]
                metas = results.get("metadatas", [[]])[0]
                return [{"text": d, "metadata": m} for d, m in zip(docs, metas)]
            else:
                if self._collection.count() == 0:
                    return []
                all_data = self._collection.get()
                docs = all_data.get("documents", [])
                metas = all_data.get("metadatas", [])
                return [{"text": d, "metadata": m} for d, m in zip(docs, metas)]
        return self._fallback

    def write(self, value, key=None):
        text = value.get("text", str(value)) if isinstance(value, dict) else str(value)
        metadata = value.get("metadata", {}) if isinstance(value, dict) else {}
        clean_meta = {}
        for k, v in (metadata or {}).items():
            if isinstance(v, (str, int, float, bool)):
                clean_meta[k] = v
            elif v is not None:
                clean_meta[k] = str(v)
        if self._collection is not None:
            doc_id = key or f"doc_{self._collection.count()}"
            self._collection.add(documents=[text], metadatas=[clean_meta], ids=[doc_id])
        else:
            self._fallback.append(value if isinstance(value, dict) else {"text": text, "metadata": clean_meta})


class Store_memory_store:
    """Agent Memory (vector)"""
    def __init__(self):
        self._store = _ChromaVectorStore("memory_store")

    def read(self, key=None):
        return self._store.read(query=key)

    def write(self, value, key=None):
        self._store.write(value, key=key)


class Store_workspace:
    """Workspace (kv)"""
    def __init__(self):
        self.data = {}

    def read(self, key=None):
        return self.data if key is None else self.data.get(key)

    def write(self, value, key=None):
        if key is not None:
            self.data[key] = value
        else:
            self.data = value


# Store instances
_store_memory_store = Store_memory_store()
_store_workspace = Store_workspace()


# ═══════════════════════════════════════════════════════════
# Agent Wrappers
# ═══════════════════════════════════════════════════════════

def invoke_planner(user_message, output_schema=None):
    """Planner"""
    system = """You are an autonomous AI agent planner. Given an objective, break it down into
a concrete plan of 3-7 actionable steps. Each step should be specific enough to execute.
Consider dependencies between steps. Return the plan as a JSON list of steps.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Planner", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_thinker(user_message, output_schema=None):
    """Thinker"""
    system = """You are the reasoning component of an autonomous agent. Given the current goal,
plan, completed results, and current step, reason about what specific action to take.
Consider what information you have, what you need, and the best approach.
Output your thought process and a proposed action.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Thinker", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_critic(user_message, output_schema=None):
    """Critic"""
    system = """You are a self-critic for an autonomous agent. Review the proposed thought and action.
Check for: logical errors, missing information, better alternatives, potential risks.
Rate the proposal 1-10 and suggest improvements. If rating >= 7, approve. Otherwise, reject
with specific feedback.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Critic", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_executor(user_message, output_schema=None):
    """Executor"""
    system = """You execute a specific action. You receive the action description and any context.
Perform the action to the best of your ability and return the result.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Executor", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result



# ═══════════════════════════════════════════════════════════
# Node Functions
# ═══════════════════════════════════════════════════════════

def node_set_goal(state: AgentState) -> dict:
    """
    Set Goal
    Accept the user's objective and initialize the agent
    """
    print(f"  → Set Goal")
    updates = {}

    # Logic from spec
    updates["completed_steps"] = []
    updates["current_step_idx"] = 0
    updates["criticism_count"] = 0
    updates["max_criticism_retries"] = 3
    updates["results"] = []
    print(f"    Goal: {state.get('objective', '')}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_decompose(state: AgentState) -> dict:
    """
    Decompose
    Break the objective into a plan of concrete steps
    """
    print(f"  → Decompose")
    updates = {}

    # Invoke: Create plan
    _cur = dict(state)
    _cur.update(updates)
    planner_input = build_input(_cur, "PlanInput")
    planner_msg = json.dumps(planner_input, default=str)
    planner_raw = invoke_planner(planner_msg, output_schema="Plan")
    planner_result = parse_response(planner_raw, "Plan")
    updates["_schema_violations"] = len(validate_output(planner_result, "Plan"))
    updates.update(planner_result)
    updates["plan_schema"] = planner_result
    updates["decompose_result"] = planner_result
    print(f"    ← Planner: {planner_result}")

    return updates


def node_think(state: AgentState) -> dict:
    """
    Think
    Reason about the current step and propose an action
    """
    print(f"  → Think")
    updates = {}

    # Read: Read memory context
    memory_store_data = _store_memory_store.read()
    updates["memory_store"] = memory_store_data

    # Logic from spec
    plan = state.get("plan", [])
    updates["total_steps"] = len(plan)
    idx = state.get("current_step_idx", 0)
    if idx < len(plan):
        updates["current_step"] = plan[idx]
    else:
        updates["current_step"] = "Review and finalize results"
    updates["stored_memories"] = [e.get("text", "") for e in state.get("memory_store", []) if e.get("text")][-5:]
    print(f"    Step {idx + 1}/{len(plan)}: {state.get('current_step', '')[:100]}")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Reason about step
    _cur = dict(state)
    _cur.update(updates)
    thinker_input = build_input(_cur, "ThinkInput")
    thinker_msg = json.dumps(thinker_input, default=str)
    thinker_raw = invoke_thinker(thinker_msg, output_schema="Thought")
    thinker_result = parse_response(thinker_raw, "Thought")
    updates["_schema_violations"] = len(validate_output(thinker_result, "Thought"))
    updates.update(thinker_result)
    updates["thought"] = thinker_result
    updates["think_result"] = thinker_result
    print(f"    ← Thinker: {thinker_result}")

    return updates


def node_criticize(state: AgentState) -> dict:
    """
    Criticize
    Self-critique the proposed thought and action
    """
    print(f"  → Criticize")
    updates = {}

    # Invoke: Evaluate proposal
    _cur = dict(state)
    _cur.update(updates)
    critic_input = build_input(_cur, "CriticInput")
    critic_msg = json.dumps(critic_input, default=str)
    critic_raw = invoke_critic(critic_msg, output_schema="Criticism")
    critic_result = parse_response(critic_raw, "Criticism")
    updates["_schema_violations"] = len(validate_output(critic_result, "Criticism"))
    updates.update(critic_result)
    updates["criticism"] = critic_result
    updates["criticize_result"] = critic_result
    print(f"    ← Critic: {critic_result}")

    return updates


def node_handle_rejection(state: AgentState) -> dict:
    """
    Handle Rejection
    Process critic feedback and retry or skip
    """
    print(f"  → Handle Rejection")
    updates = {}

    # Logic from spec
    count = state.get("criticism_count", 0) + 1
    updates["criticism_count"] = count
    max_retries = state.get("max_criticism_retries", 3)
    if count >= max_retries:
        print(f"    Max retries ({max_retries}) reached, proceeding anyway")
        updates["criticism_count"] = 0
    else:
        updates["feedback"] = state.get("improvements", "Try a different approach")
        print(f"    Retry {count}/{max_retries}: {state.get('improvements', '')[:100]}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_act(state: AgentState) -> dict:
    """
    Act
    Execute the approved action
    """
    print(f"  → Act")
    updates = {}

    # Logic from spec
    action = state.get("proposed_action", "")
    print(f"    Executing: {action[:100]}")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Execute action
    _cur = dict(state)
    _cur.update(updates)
    executor_input = build_input(_cur, "ActionInput")
    executor_msg = json.dumps(executor_input, default=str)
    executor_raw = invoke_executor(executor_msg, output_schema="ActionResult")
    executor_result = parse_response(executor_raw, "ActionResult")
    updates["_schema_violations"] = len(validate_output(executor_result, "ActionResult"))
    updates.update(executor_result)
    updates["action_result_schema"] = executor_result
    updates["act_result"] = executor_result
    print(f"    ← Executor: {executor_result}")

    return updates


def node_observe(state: AgentState) -> dict:
    """
    Observe
    Process the action result and update memory
    """
    print(f"  → Observe")
    updates = {}

    # Logic from spec
    result = state.get("action_result", "")
    results = state.get("results", [])
    results.append(result)
    updates["results"] = results
    updates["text"] = result
    updates["embedding"] = []
    updates["metadata"] = {"step": state.get("current_step_idx", 0), "action": state.get("proposed_action", "")}
    updates["current_step_idx"] = state.get("current_step_idx", 0) + 1
    updates["criticism_count"] = 0
    print(f"    Result recorded. Completed {state.get('current_step_idx', "")} steps.")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Write: Store memory
    _cur = dict(state)
    _cur.update(updates)
    memory_store_write = build_input(_cur, "MemoryEntry")
    _store_memory_store.write(memory_store_write)

    # Write: Update workspace
    _cur = dict(state)
    _cur.update(updates)
    workspace_write = build_input(_cur, "WorkspaceEntry")
    _store_workspace.write(workspace_write)

    return updates


def node_synthesize(state: AgentState) -> dict:
    """
    Synthesize
    Combine all results into a final output
    """
    print(f"  → Synthesize")
    updates = {}

    # Logic from spec
    results = state.get("results", [])
    print(f"    Synthesizing {len(results)} results")
    updates["_done"] = True
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


# ═══════════════════════════════════════════════════════════
# Gate Routing Functions
# ═══════════════════════════════════════════════════════════

def route_critic_gate(state: AgentState) -> str:
    """Gate: Critic approved? — rating >= 7"""
    if (state.get("rating", 0)) >= 7:
        print(f"    → approved (rating >= 7)")
        return "act"
    else:
        print(f"    → rejected (rating < 7)")
        return "handle_rejection"


def route_retry_or_proceed(state: AgentState) -> str:
    """Gate: Retry or proceed? — criticism_count >= max_criticism_retries"""
    if (state.get("criticism_count", 0)) >= (state.get("max_criticism_retries", 0)):
        print(f"    → at retry limit")
        return "act"
    else:
        print(f"    → under retry limit")
        return "think"


def route_check_done(state: AgentState) -> str:
    """Gate: All steps done? — current_step_idx >= total_steps"""
    if (state.get("current_step_idx", 0)) >= (state.get("total_steps", 0)):
        print(f"    → all done")
        return "synthesize"
    else:
        print(f"    → not done")
        return "think"


# ═══════════════════════════════════════════════════════════
# Graph Construction
# ═══════════════════════════════════════════════════════════

def build_graph():
    graph = StateGraph(AgentState)

    graph.add_node("set_goal", node_set_goal)
    graph.add_node("decompose", node_decompose)
    graph.add_node("think", node_think)
    graph.add_node("criticize", node_criticize)
    graph.add_node("handle_rejection", node_handle_rejection)
    graph.add_node("act", node_act)
    graph.add_node("observe", node_observe)
    graph.add_node("synthesize", node_synthesize)

    graph.set_entry_point("set_goal")

    graph.add_edge("set_goal", "decompose")
    graph.add_edge("decompose", "think")
    graph.add_edge("think", "criticize")
    graph.add_conditional_edges(
        "criticize",
        route_critic_gate,
        {
            "handle_rejection": "handle_rejection",
            "act": "act",
        }
    )
    graph.add_conditional_edges(
        "handle_rejection",
        route_retry_or_proceed,
        {
            "think": "think",
            "act": "act",
        }
    )
    graph.add_edge("act", "observe")
    graph.add_conditional_edges(
        "observe",
        route_check_done,
        {
            "think": "think",
            "synthesize": "synthesize",
        }
    )
    graph.add_edge("synthesize", END)

    return graph.compile()


# ═══════════════════════════════════════════════════════════
# Entry Point
# ═══════════════════════════════════════════════════════════

class _StateCompat:
    """Wrapper to make LangGraph state compatible with test harness."""
    def __init__(self, state_dict):
        self.data = {k: v for k, v in state_dict.items() if not k.startswith("_")}
        self.data.update({k: v for k, v in state_dict.items() if k.startswith("_")})
        self.iteration = state_dict.get("_iteration", 0)
        self.schema_violations = state_dict.get("_schema_violations", 0)

    def get(self, key, default=None):
        return self.data.get(key, default)


MAX_ITERATIONS = int(os.environ.get("OPENCLAW_MAX_ITER", "100"))


def run(initial_data=None):
    """AutoGPT — LangGraph execution"""
    app = build_graph()

    # Build initial state
    state = {}
    if initial_data:
        state.update(initial_data)
    state["_iteration"] = 0
    state["_schema_violations"] = 0
    state["_done"] = False

    print(f"\n════════════════════════════════════════════════════════════")
    print(f"  AutoGPT (LangGraph)")
    print(f"  Goal-driven autonomous agent with planning, self-criticism, and iterative execution")
    print(f"════════════════════════════════════════════════════════════\n")

    # LangGraph recursion limit maps roughly to our MAX_ITERATIONS
    try:
        final_state = app.invoke(state, {"recursion_limit": MAX_ITERATIONS * 3})
    except Exception as e:
        print(f"\n  [ERROR] {type(e).__name__}: {e}")
        final_state = state

    _clean_exit = True
    dump_trace(iterations=final_state.get("_iteration", 0), clean_exit=_clean_exit)
    print(f"\nFinal state keys: {list(final_state.keys())}")
    return _StateCompat(final_state)


if __name__ == "__main__":
    run()