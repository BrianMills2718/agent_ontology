#!/usr/bin/env python3
"""
Debate Agent — Generated by OpenClaw Instantiation Engine (LangGraph backend)
Spec: A multi-agent debate system with pro/con agents moderated by a judge agent over multiple rounds.
"""

import json
import os
import sys
import time
from datetime import datetime
from typing import Any, TypedDict, Annotated

from langgraph.graph import StateGraph, END

# ═══════════════════════════════════════════════════════════
# Trace Log
# ═══════════════════════════════════════════════════════════

TRACE = []

def trace_call(agent_label, model, system_prompt, user_message, response, duration_ms):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "agent": agent_label,
        "model": model,
        "system_prompt": system_prompt,
        "user_message": user_message,
        "response": response,
        "duration_ms": duration_ms,
    }
    TRACE.append(entry)
    print(f"    [{agent_label}] ({model}, {duration_ms}ms)")
    print(f"      IN:  {user_message[:300]}")
    print(f"      OUT: {response[:300]}")


def dump_trace(path="trace.json", iterations=0, clean_exit=True):
    total_ms = sum(e["duration_ms"] for e in TRACE)
    agents_used = list(set(e["agent"] for e in TRACE))
    schema_ok = 0
    for e in TRACE:
        try:
            r = e["response"].strip()
            if r.startswith("```"): r = "\n".join(r.split("\n")[1:-1])
            json.loads(r if r.startswith("{") else r[r.find("{"):r.rfind("}")+1])
            schema_ok += 1
        except (json.JSONDecodeError, ValueError):
            pass
    est_input_tokens = sum(len(e.get("user_message",""))//4 for e in TRACE)
    est_output_tokens = sum(len(e.get("response",""))//4 for e in TRACE)
    metrics = {
        "total_llm_calls": len(TRACE),
        "total_duration_ms": total_ms,
        "avg_call_ms": total_ms // max(len(TRACE), 1),
        "iterations": iterations,
        "clean_exit": clean_exit,
        "agents_used": agents_used,
        "schema_compliance": f"{schema_ok}/{len(TRACE)}",
        "est_input_tokens": est_input_tokens,
        "est_output_tokens": est_output_tokens,
    }
    output = {"metrics": metrics, "trace": TRACE}
    with open(path, "w") as f:
        json.dump(output, f, indent=2)
    print(f"\nTrace written to {path} ({len(TRACE)} calls, {total_ms}ms total)")
    print(f"  Schema compliance: {schema_ok}/{len(TRACE)}, est tokens: ~{est_input_tokens}in/~{est_output_tokens}out")
    return metrics

# ═══════════════════════════════════════════════════════════
# LLM Call Infrastructure
# ═══════════════════════════════════════════════════════════

_MODEL_OVERRIDE = os.environ.get("OPENCLAW_MODEL", "")
_OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")


def _openrouter_model_id(model):
    """Map spec model names to OpenRouter model IDs (provider/model format)."""
    if "/" in model:
        return model
    if model.startswith("gemini"):
        return f"google/{model}"
    if model.startswith("claude") or model.startswith("anthropic"):
        return f"anthropic/{model}"
    if model.startswith("gpt") or model.startswith("o1") or model.startswith("o3"):
        return f"openai/{model}"
    return model


def _get_chat_model(model, temperature=0.7, max_tokens=4096):
    """Get a LangChain ChatModel instance for the given model name."""
    if _OPENROUTER_API_KEY:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=_openrouter_model_id(model),
            temperature=temperature,
            max_tokens=max_tokens,
            base_url="https://openrouter.ai/api/v1",
            api_key=_OPENROUTER_API_KEY,
        )
    if model.startswith("gemini"):
        from langchain_google_genai import ChatGoogleGenerativeAI
        return ChatGoogleGenerativeAI(model=model, temperature=temperature,
                                      max_output_tokens=max_tokens,
                                      google_api_key=os.environ.get("GEMINI_API_KEY", ""))
    elif model.startswith("claude") or model.startswith("anthropic"):
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(model=model, temperature=temperature, max_tokens=max_tokens)
    else:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(model=model, temperature=temperature, max_tokens=max_tokens)


def call_llm(model, system_prompt, user_message, temperature=0.7, max_tokens=4096, retries=3):
    if _MODEL_OVERRIDE:
        model = _MODEL_OVERRIDE
    from langchain_core.messages import SystemMessage, HumanMessage
    for attempt in range(retries):
        try:
            chat = _get_chat_model(model, temperature, max_tokens)
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_message)]
            response = chat.invoke(messages)
            content = response.content
            # LangChain may return content as a list of blocks (e.g. Gemini)
            if isinstance(content, list):
                content = " ".join(b.get("text", str(b)) if isinstance(b, dict) else str(b) for b in content)
            return content
        except Exception as e:
            if attempt < retries - 1:
                wait = 2 ** attempt
                print(f"    [RETRY] {type(e).__name__}: {e} — retrying in {wait}s (attempt {attempt+1}/{retries})")
                import time as _time; _time.sleep(wait)
            else:
                print(f"    [FAIL] {type(e).__name__}: {e} after {retries} attempts")
                return json.dumps({"stub": True, "model": model, "error": str(e)})

# ═══════════════════════════════════════════════════════════
# Schema Registry
# ═══════════════════════════════════════════════════════════

SCHEMAS = {
    "TopicInput": {
        "description": """User-provided debate topic""",
        "fields": [{"name": "topic", "type": "string"}],
    },
    "DebateSetup": {
        "description": """Moderator's framing of proposition and assigned positions""",
        "fields": [{"name": "proposition", "type": "string"}, {"name": "pro_position", "type": "string"}, {"name": "con_position", "type": "string"}],
    },
    "DebateTurn": {
        "description": """A single turn in the debate history""",
        "fields": [{"name": "round", "type": "integer"}, {"name": "side", "type": "enum[pro, con]"}, {"name": "argument", "type": "string"}, {"name": "position", "type": "string"}, {"name": "timestamp", "type": "string"}],
    },
    "DebateTurnInput": {
        "description": """Input to pro/con agents containing debate history, position, and proposition""",
        "fields": [{"name": "proposition", "type": "string"}, {"name": "debate_history", "type": "list<DebateTurn>"}, {"name": "position", "type": "string"}, {"name": "round", "type": "integer"}],
    },
    "ArgumentOutput": {
        "description": """Agent's argument or rebuttal output""",
        "fields": [{"name": "argument", "type": "string"}],
    },
    "DebateHistoryInput": {
        "description": """Input to judge agent with full debate history""",
        "fields": [{"name": "debate_history", "type": "list<DebateTurn>"}, {"name": "proposition", "type": "string"}, {"name": "pro_position", "type": "string"}, {"name": "con_position", "type": "string"}, {"name": "rounds_completed", "type": "integer"}],
    },
    "JudgmentOutput": {
        "description": """Judge's evaluation of the debate""",
        "fields": [{"name": "pro_score", "type": "integer"}, {"name": "con_score", "type": "integer"}, {"name": "rebuttal_quality", "type": "integer"}, {"name": "winner", "type": "enum[pro, con, tie]"}, {"name": "summary", "type": "string"}],
    },
}


def validate_output(data, schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema or "raw" in data:
        return []
    issues = []
    for field in schema["fields"]:
        fname = field["name"]
        ftype = field["type"]
        if fname not in data:
            issues.append(f"Missing field '{fname}' ({ftype})")
            continue
        val = data[fname]
        if ftype == "string" and not isinstance(val, str):
            issues.append(f"Field '{fname}' expected string, got {type(val).__name__}")
        elif ftype == "integer" and not isinstance(val, (int, float)):
            issues.append(f"Field '{fname}' expected integer, got {type(val).__name__}")
        elif ftype.startswith("list") and not isinstance(val, list):
            issues.append(f"Field '{fname}' expected list, got {type(val).__name__}")
        elif ftype.startswith("enum["):
            allowed = [v.strip() for v in ftype[5:-1].split(",")]
            if val not in allowed:
                issues.append(f"Field '{fname}' value '{val}' not in {allowed}")
    if issues:
        print(f"    [SCHEMA] {schema_name}: {len(issues)} issue(s): {issues[0]}")
    return issues


def build_input(state, schema_name):
    """Build an input dict for an agent call using schema field names."""
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return dict(state)
    result = {}
    for field in schema["fields"]:
        fname = field["name"]
        if fname in state:
            result[fname] = state[fname]
        else:
            for _k, _v in state.items():
                if isinstance(_v, dict) and fname in _v:
                    result[fname] = _v[fname]
                    break
    return result


def output_instruction(schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return ""
    fields = ", ".join(f'"{f["name"]}": <{f["type"]}>' for f in schema["fields"])
    return f"\n\nRespond with ONLY valid JSON matching this schema: {{{fields}}}"


def parse_response(response, schema_name):
    import re as _re
    text = response.strip()
    if text.startswith("```"):
        lines = text.split("\n")
        lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        text = "\n".join(lines)
    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
        return {"value": parsed}
    except json.JSONDecodeError:
        pass
    start = text.find("{")
    end = text.rfind("}") + 1
    if start >= 0 and end > start:
        candidate = text[start:end]
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass
        fixed = _re.sub(r",\s*}", "}", candidate)
        fixed = _re.sub(r",\s*]", "]", fixed)
        try:
            return json.loads(fixed)
        except json.JSONDecodeError:
            pass
        depth = 0
        for i, ch in enumerate(text[start:], start):
            if ch == "{": depth += 1
            elif ch == "}": depth -= 1
            if depth == 0:
                try:
                    return json.loads(text[start:i+1])
                except json.JSONDecodeError:
                    break
    return {"raw": response}

# ═══════════════════════════════════════════════════════════
# State TypedDict
# ═══════════════════════════════════════════════════════════

class AgentState(TypedDict, total=False):
    """Typed state for Debate Agent"""
    _canned_responses: list
    _continue_debate: Any
    _done: bool
    _iteration: int
    _schema_violations: int
    argument: str
    con_position: str
    con_score: int
    debate_history: list
    debate_history_store: list
    max_rounds: Any
    position: str
    pro_position: str
    pro_score: int
    proposition: str
    rebuttal_quality: int
    round: int
    rounds_completed: int
    side: str
    summary: str
    timestamp: str
    topic: str
    winner: str


# ═══════════════════════════════════════════════════════════
# Stores
# ═══════════════════════════════════════════════════════════

class Store_debate_history_store:
    """Debate History (queue)"""
    def __init__(self):
        self.queue = []

    def read(self, key=None):
        return self.queue[0] if self.queue else None

    def write(self, value, key=None):
        self.queue.append(value)


# Store instances
_store_debate_history_store = Store_debate_history_store()


# ═══════════════════════════════════════════════════════════
# Agent Wrappers
# ═══════════════════════════════════════════════════════════

def invoke_moderator_agent(user_message, output_schema=None):
    """Moderator Agent"""
    system = """You are the Moderator Agent. Given a user-provided topic, you will frame it as a clear proposition and assign pro and con positions to two agents. Output a DebateSetup object with the proposition and assigned positions.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Moderator Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_pro_agent(user_message, output_schema=None):
    """Pro Agent"""
    system = """You are the Pro Agent arguing in favor of the proposition. You will receive the debate history and your position. Provide your argument or rebuttal for the current round.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Pro Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_con_agent(user_message, output_schema=None):
    """Con Agent"""
    system = """You are the Con Agent arguing against the proposition. You will receive the debate history and your position. Provide your argument or rebuttal for the current round.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Con Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_judge_agent(user_message, output_schema=None):
    """Judge Agent"""
    system = """You are the Judge Agent. After the debate rounds, evaluate the strength of arguments (1-10 per side), quality of rebuttals, determine the overall winner, and summarize key points from each side. If the combined score is less than 12, request one more round.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Judge Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result



# ═══════════════════════════════════════════════════════════
# Node Functions
# ═══════════════════════════════════════════════════════════

def node_topic_setup(state: AgentState) -> dict:
    """
    Topic Setup
    User provides a topic; moderator frames proposition and assigns positions
    """
    print(f"  → Topic Setup")
    updates = {}

    # Logic from spec
    # Expect state.get('topic', "") from user input
    if "topic" not in dict(state) or not state.get("topic", ""):
        print("    Waiting for user to provide a debate topic.")
        return state
    print(f"    Received topic: {state.get('topic', "")}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_moderate_topic(state: AgentState) -> dict:
    """
    Moderate Topic
    Invoke moderator agent to frame proposition and assign positions
    """
    print(f"  → Moderate Topic")
    updates = {}

    # Invoke: Frame proposition and assign positions
    _cur = dict(state)
    _cur.update(updates)
    moderator_agent_input = build_input(_cur, "TopicInput")
    moderator_agent_msg = json.dumps(moderator_agent_input, default=str)
    moderator_agent_raw = invoke_moderator_agent(moderator_agent_msg, output_schema="DebateSetup")
    moderator_agent_result = parse_response(moderator_agent_raw, "DebateSetup")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(moderator_agent_result, "DebateSetup"))
    updates.update(moderator_agent_result)
    updates["debate_setup"] = moderator_agent_result
    updates["moderate_topic_result"] = moderator_agent_result
    print(f"    ← Moderator Agent: {moderator_agent_result}")

    return updates


def node_initialize_debate(state: AgentState) -> dict:
    """
    Initialize Debate
    Initialize debate state, set round count to 1, clear history
    """
    print(f"  → Initialize Debate")
    updates = {}

    # Logic from spec
    updates["round"] = 1
    updates["max_rounds"] = 3
    updates["debate_history"] = []
    updates["pro_position"] = state.get("pro_position", "Pro")
    updates["con_position"] = state.get("con_position", "Con")
    print(f"    Debate initialized with proposition: {state.get('proposition', '')}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_pro_argument(state: AgentState) -> dict:
    """
    Pro Agent Argument
    Invoke Pro Agent to present argument
    """
    print(f"  → Pro Agent Argument")
    updates = {}

    # Logic from spec
    updates["position"] = state.get("pro_position", "Pro")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Pro presents argument
    _cur = dict(state)
    _cur.update(updates)
    pro_agent_input = build_input(_cur, "DebateTurnInput")
    pro_agent_msg = json.dumps(pro_agent_input, default=str)
    pro_agent_raw = invoke_pro_agent(pro_agent_msg, output_schema="ArgumentOutput")
    pro_agent_result = parse_response(pro_agent_raw, "ArgumentOutput")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(pro_agent_result, "ArgumentOutput"))
    updates.update(pro_agent_result)
    updates["argument_output"] = pro_agent_result
    updates["pro_argument_result"] = pro_agent_result
    print(f"    ← Pro Agent: {pro_agent_result}")

    return updates


def node_con_argument(state: AgentState) -> dict:
    """
    Con Agent Argument
    Invoke Con Agent to present argument
    """
    print(f"  → Con Agent Argument")
    updates = {}

    # Logic from spec
    updates["position"] = state.get("con_position", "Con")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Con presents argument
    _cur = dict(state)
    _cur.update(updates)
    con_agent_input = build_input(_cur, "DebateTurnInput")
    con_agent_msg = json.dumps(con_agent_input, default=str)
    con_agent_raw = invoke_con_agent(con_agent_msg, output_schema="ArgumentOutput")
    con_agent_result = parse_response(con_agent_raw, "ArgumentOutput")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(con_agent_result, "ArgumentOutput"))
    updates.update(con_agent_result)
    updates["argument_output"] = con_agent_result
    updates["con_argument_result"] = con_agent_result
    print(f"    ← Con Agent: {con_agent_result}")

    return updates


def node_record_pro_argument(state: AgentState) -> dict:
    """
    Record Pro Argument
    Append Pro Agent's argument to debate history
    """
    print(f"  → Record Pro Argument")
    updates = {}

    # Logic from spec
    turn = {
        "round": state.get("round", 1),
        "side": "pro",
        "argument": state.get("argument", ""),
        "position": state.get("pro_position", "Pro"),
        "timestamp": None
    }
    history = state.get("debate_history", [])
    history.append(turn)
    updates["debate_history"] = history
    print(f"    Recorded Pro argument for round {turn['round']}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_record_con_argument(state: AgentState) -> dict:
    """
    Record Con Argument
    Append Con Agent's argument to debate history
    """
    print(f"  → Record Con Argument")
    updates = {}

    # Logic from spec
    turn = {
        "round": state.get("round", 1),
        "side": "con",
        "argument": state.get("argument", ""),
        "position": state.get("con_position", "Con"),
        "timestamp": None
    }
    history = state.get("debate_history", [])
    history.append(turn)
    updates["debate_history"] = history
    print(f"    Recorded Con argument for round {turn['round']}")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Write: Persist debate round
    _cur = dict(state)
    _cur.update(updates)
    debate_history_store_write = build_input(_cur, "DebateTurn")
    _store_debate_history_store.write(debate_history_store_write)

    return updates


def node_judge_evaluation(state: AgentState) -> dict:
    """
    Judge Evaluation
    Invoke Judge Agent to evaluate debate
    """
    print(f"  → Judge Evaluation")
    updates = {}

    # Read: Read full debate history
    debate_history_store_data = _store_debate_history_store.read()
    updates["debate_history_store"] = debate_history_store_data

    # Invoke: Judge evaluates debate
    _cur = dict(state)
    _cur.update(updates)
    judge_agent_input = build_input(_cur, "DebateHistoryInput")
    judge_agent_msg = json.dumps(judge_agent_input, default=str)
    judge_agent_raw = invoke_judge_agent(judge_agent_msg, output_schema="JudgmentOutput")
    judge_agent_result = parse_response(judge_agent_raw, "JudgmentOutput")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(judge_agent_result, "JudgmentOutput"))
    updates.update(judge_agent_result)
    updates["judgment_output"] = judge_agent_result
    updates["judge_evaluation_result"] = judge_agent_result
    print(f"    ← Judge Agent: {judge_agent_result}")

    return updates


def node_evaluate_judgment(state: AgentState) -> dict:
    """
    Evaluate Judgment
    Check judge scores and decide if another round is needed
    """
    print(f"  → Evaluate Judgment")
    updates = {}

    # Logic from spec
    combined_score = state.get("pro_score", 0) + state.get("con_score", 0)
    print(f"    Combined judge score: {combined_score}")
    if combined_score < 12:
        print("    Debate quality low, adding one more round.")
        updates["_continue_debate"] = True
    else:
        updates["_done"] = True
        updates["_continue_debate"] = False
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_end_debate(state: AgentState) -> dict:
    """
    End Debate
    Finalize debate and output judgment summary
    """
    print(f"  → End Debate")
    updates = {}

    # Logic from spec
    print("    Debate ended. Final judgment summary:")
    print(state.get("summary", "No summary available."))
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_increment_round(state: AgentState) -> dict:
    """
    Increment Round
    Increment the debate round counter
    """
    print(f"  → Increment Round")
    updates = {}

    # Logic from spec
    updates["round"] = state.get("round", 1) + 1
    print(f"    Moving to round {state.get('round', "")}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


# ═══════════════════════════════════════════════════════════
# Gate Routing Functions
# ═══════════════════════════════════════════════════════════

def route_check_rounds(state: AgentState) -> str:
    """Gate: Check Rounds — round > max_rounds"""
    if (state.get("round", 0)) > (state.get("max_rounds", 0)):
        print(f"    → round > max_rounds")
        return "judge_evaluation"
    else:
        print(f"    → round <= max_rounds")
        return "pro_argument"


def route_continue_or_end(state: AgentState) -> str:
    """Gate: Continue or End Debate? — _continue_debate == True"""
    if state.get("_continue_debate") == True:
        print(f"    → continue debate")
        return "pro_argument"
    else:
        print(f"    → end debate")
        return "end_debate"


# ═══════════════════════════════════════════════════════════
# Graph Construction
# ═══════════════════════════════════════════════════════════

def build_graph():
    graph = StateGraph(AgentState)

    graph.add_node("topic_setup", node_topic_setup)
    graph.add_node("moderate_topic", node_moderate_topic)
    graph.add_node("initialize_debate", node_initialize_debate)
    graph.add_node("pro_argument", node_pro_argument)
    graph.add_node("con_argument", node_con_argument)
    graph.add_node("record_pro_argument", node_record_pro_argument)
    graph.add_node("record_con_argument", node_record_con_argument)
    graph.add_node("judge_evaluation", node_judge_evaluation)
    graph.add_node("evaluate_judgment", node_evaluate_judgment)
    graph.add_node("end_debate", node_end_debate)
    graph.add_node("increment_round", node_increment_round)

    graph.set_entry_point("topic_setup")

    graph.add_edge("topic_setup", "moderate_topic")
    graph.add_edge("moderate_topic", "initialize_debate")
    graph.add_conditional_edges(
        "initialize_debate",
        route_check_rounds,
        {
            "pro_argument": "pro_argument",
            "judge_evaluation": "judge_evaluation",
        }
    )
    graph.add_edge("pro_argument", "record_pro_argument")
    graph.add_edge("con_argument", "record_con_argument")
    graph.add_edge("record_pro_argument", "con_argument")
    graph.add_edge("record_con_argument", "increment_round")
    graph.add_edge("judge_evaluation", "evaluate_judgment")
    graph.add_conditional_edges(
        "evaluate_judgment",
        route_continue_or_end,
        {
            "pro_argument": "pro_argument",
            "end_debate": "end_debate",
        }
    )
    graph.add_edge("end_debate", END)
    graph.add_conditional_edges(
        "increment_round",
        route_check_rounds,
        {
            "pro_argument": "pro_argument",
            "judge_evaluation": "judge_evaluation",
        }
    )

    return graph.compile()


# ═══════════════════════════════════════════════════════════
# Entry Point
# ═══════════════════════════════════════════════════════════

class _StateCompat:
    """Wrapper to make LangGraph state compatible with test harness."""
    def __init__(self, state_dict):
        self.data = {k: v for k, v in state_dict.items() if not k.startswith("_")}
        self.data.update({k: v for k, v in state_dict.items() if k.startswith("_")})
        self.iteration = state_dict.get("_iteration", 0)
        self.schema_violations = state_dict.get("_schema_violations", 0)


MAX_ITERATIONS = int(os.environ.get("OPENCLAW_MAX_ITER", "100"))


def run(initial_data=None):
    """Debate Agent — LangGraph execution"""
    app = build_graph()

    # Build initial state
    state = {}
    if initial_data:
        state.update(initial_data)
    state["_iteration"] = 0
    state["_schema_violations"] = 0
    state["_done"] = False

    print(f"\n════════════════════════════════════════════════════════════")
    print(f"  Debate Agent (LangGraph)")
    print(f"  A multi-agent debate system with pro/con agents moderated by a judge agent over multiple rounds.")
    print(f"════════════════════════════════════════════════════════════\n")

    # LangGraph recursion limit maps roughly to our MAX_ITERATIONS
    try:
        final_state = app.invoke(state, {"recursion_limit": MAX_ITERATIONS * 3})
    except Exception as e:
        print(f"\n  [ERROR] {type(e).__name__}: {e}")
        final_state = state

    _clean_exit = True
    dump_trace(iterations=final_state.get("_iteration", 0), clean_exit=_clean_exit)
    print(f"\nFinal state keys: {list(final_state.keys())}")
    return _StateCompat(final_state)


if __name__ == "__main__":
    initial = {}
    initial["topic"] = input("Enter topic: ")
    run(initial)