#!/usr/bin/env python3
"""
Multi-Agent Code Generation Pipeline — Generated by Agent Ontology Instantiation Engine (LangGraph backend)
Spec: Automated pipeline for generating, testing, and reviewing code from natural language specs using specialized agents with parallel artifact generation.
"""

import json
import operator
import os
import sys
import time
from datetime import datetime
from typing import Any, TypedDict, Annotated

from langgraph.graph import StateGraph, END

# ═══════════════════════════════════════════════════════════
# Trace Log
# ═══════════════════════════════════════════════════════════

TRACE = []

def trace_call(agent_label, model, system_prompt, user_message, response, duration_ms):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "agent": agent_label,
        "model": model,
        "system_prompt": system_prompt,
        "user_message": user_message,
        "response": response,
        "duration_ms": duration_ms,
    }
    TRACE.append(entry)
    print(f"    [{agent_label}] ({model}, {duration_ms}ms)")
    print(f"      IN:  {user_message[:300]}")
    print(f"      OUT: {response[:300]}")


def dump_trace(path="trace.json", iterations=0, clean_exit=True):
    total_ms = sum(e["duration_ms"] for e in TRACE)
    agents_used = list(set(e["agent"] for e in TRACE))
    schema_ok = 0
    for e in TRACE:
        try:
            r = e["response"].strip()
            if r.startswith("```"): r = "\n".join(r.split("\n")[1:-1])
            json.loads(r if r.startswith("{") else r[r.find("{"):r.rfind("}")+1])
            schema_ok += 1
        except (json.JSONDecodeError, ValueError):
            pass
    est_input_tokens = sum(len(e.get("user_message",""))//4 for e in TRACE)
    est_output_tokens = sum(len(e.get("response",""))//4 for e in TRACE)
    metrics = {
        "total_llm_calls": len(TRACE),
        "total_duration_ms": total_ms,
        "avg_call_ms": total_ms // max(len(TRACE), 1),
        "iterations": iterations,
        "clean_exit": clean_exit,
        "agents_used": agents_used,
        "schema_compliance": f"{schema_ok}/{len(TRACE)}",
        "est_input_tokens": est_input_tokens,
        "est_output_tokens": est_output_tokens,
    }
    output = {"metrics": metrics, "trace": TRACE}
    with open(path, "w") as f:
        json.dump(output, f, indent=2)
    print(f"\nTrace written to {path} ({len(TRACE)} calls, {total_ms}ms total)")
    print(f"  Schema compliance: {schema_ok}/{len(TRACE)}, est tokens: ~{est_input_tokens}in/~{est_output_tokens}out")
    return metrics

# ═══════════════════════════════════════════════════════════
# LLM Call Infrastructure
# ═══════════════════════════════════════════════════════════

_MODEL_OVERRIDE = os.environ.get("AGENT_ONTOLOGY_MODEL", "")
_OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")


def _openrouter_model_id(model):
    """Map spec model names to OpenRouter model IDs (provider/model format)."""
    if "/" in model:
        return model
    if model.startswith("gemini"):
        return f"google/{model}"
    if model.startswith("claude") or model.startswith("anthropic"):
        return f"anthropic/{model}"
    if model.startswith("gpt") or model.startswith("o1") or model.startswith("o3"):
        return f"openai/{model}"
    return model


def _get_chat_model(model, temperature=0.7, max_tokens=4096):
    """Get a LangChain ChatModel instance for the given model name."""
    if _OPENROUTER_API_KEY:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=_openrouter_model_id(model),
            temperature=temperature,
            max_tokens=max_tokens,
            base_url="https://openrouter.ai/api/v1",
            api_key=_OPENROUTER_API_KEY,
        )
    if model.startswith("gemini"):
        from langchain_google_genai import ChatGoogleGenerativeAI
        return ChatGoogleGenerativeAI(model=model, temperature=temperature,
                                      max_output_tokens=max_tokens,
                                      google_api_key=os.environ.get("GEMINI_API_KEY", ""))
    elif model.startswith("claude") or model.startswith("anthropic"):
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(model=model, temperature=temperature, max_tokens=max_tokens)
    else:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(model=model, temperature=temperature, max_tokens=max_tokens)


def call_llm(model, system_prompt, user_message, temperature=0.7, max_tokens=4096, retries=3):
    if _MODEL_OVERRIDE:
        model = _MODEL_OVERRIDE
    from langchain_core.messages import SystemMessage, HumanMessage
    for attempt in range(retries):
        try:
            chat = _get_chat_model(model, temperature, max_tokens)
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_message)]
            response = chat.invoke(messages)
            content = response.content
            # LangChain may return content as a list of blocks (e.g. Gemini)
            if isinstance(content, list):
                content = " ".join(b.get("text", str(b)) if isinstance(b, dict) else str(b) for b in content)
            return content
        except Exception as e:
            if attempt < retries - 1:
                wait = 2 ** attempt
                print(f"    [RETRY] {type(e).__name__}: {e} — retrying in {wait}s (attempt {attempt+1}/{retries})")
                import time as _time; _time.sleep(wait)
            else:
                print(f"    [FAIL] {type(e).__name__}: {e} after {retries} attempts")
                return json.dumps({"stub": True, "model": model, "error": str(e)})

# ═══════════════════════════════════════════════════════════
# Schema Registry
# ═══════════════════════════════════════════════════════════

SCHEMAS = {
    "CodegenRequest": {
        "description": """Initial user requirements""",
        "fields": [{"name": "prompt", "type": "string"}],
    },
    "TechnicalSpecOutput": {
        "description": """Structured technical specification""",
        "fields": [{"name": "spec_content", "type": "string"}, {"name": "architecture_notes", "type": "string"}, {"name": "dependencies", "type": "list<string>"}],
    },
    "GeneratorInput": {
        "description": """Input for the code generator""",
        "fields": [{"name": "spec", "type": "string"}],
    },
    "CodeArtifactOutput": {
        "description": """Generated code implementation""",
        "fields": [{"name": "code", "type": "string"}, {"name": "dependencies", "type": "list<string>"}],
    },
    "TestWriterInput": {
        "description": """Input for the test writer""",
        "fields": [{"name": "spec", "type": "string"}],
    },
    "TestArtifactOutput": {
        "description": """Generated test suite""",
        "fields": [{"name": "tests", "type": "string"}],
    },
    "FinalArtifacts": {
        "description": """Combined code and test package""",
        "fields": [{"name": "code", "type": "string"}, {"name": "tests", "type": "string"}, {"name": "dependencies", "type": "list<string>"}],
    },
}


def validate_output(data, schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema or "raw" in data:
        return []
    issues = []
    for field in schema["fields"]:
        fname = field["name"]
        ftype = field["type"]
        if fname not in data:
            issues.append(f"Missing field '{fname}' ({ftype})")
            continue
        val = data[fname]
        if ftype == "string" and not isinstance(val, str):
            issues.append(f"Field '{fname}' expected string, got {type(val).__name__}")
        elif ftype == "integer" and not isinstance(val, (int, float)):
            issues.append(f"Field '{fname}' expected integer, got {type(val).__name__}")
        elif ftype.startswith("list") and not isinstance(val, list):
            issues.append(f"Field '{fname}' expected list, got {type(val).__name__}")
        elif ftype.startswith("enum["):
            allowed = [v.strip() for v in ftype[5:-1].split(",")]
            if val not in allowed:
                issues.append(f"Field '{fname}' value '{val}' not in {allowed}")
    if issues:
        print(f"    [SCHEMA] {schema_name}: {len(issues)} issue(s): {issues[0]}")
    return issues


def build_input(state, schema_name):
    """Build an input dict for an agent call using schema field names."""
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return dict(state)
    result = {}
    for field in schema["fields"]:
        fname = field["name"]
        if fname in state:
            result[fname] = state[fname]
        else:
            for _k, _v in state.items():
                if isinstance(_v, dict) and fname in _v:
                    result[fname] = _v[fname]
                    break
    return result


def output_instruction(schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return ""
    fields = ", ".join(f'"{f["name"]}": <{f["type"]}>' for f in schema["fields"])
    return f"\n\nRespond with ONLY valid JSON matching this schema: {{{fields}}}"


def parse_response(response, schema_name):
    import re as _re
    text = response.strip()
    if text.startswith("```"):
        lines = text.split("\n")
        lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        text = "\n".join(lines)
    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
        return {"value": parsed}
    except json.JSONDecodeError:
        pass
    start = text.find("{")
    end = text.rfind("}") + 1
    if start >= 0 and end > start:
        candidate = text[start:end]
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass
        fixed = _re.sub(r",\s*}", "}", candidate)
        fixed = _re.sub(r",\s*]", "]", fixed)
        try:
            return json.loads(fixed)
        except json.JSONDecodeError:
            pass
        depth = 0
        for i, ch in enumerate(text[start:], start):
            if ch == "{": depth += 1
            elif ch == "}": depth -= 1
            if depth == 0:
                try:
                    return json.loads(text[start:i+1])
                except json.JSONDecodeError:
                    break
    return {"raw": response}

# ═══════════════════════════════════════════════════════════
# State TypedDict
# ═══════════════════════════════════════════════════════════

class AgentState(TypedDict, total=False):
    """Typed state for Multi-Agent Code Generation Pipeline"""
    _canned_responses: list
    _done: bool
    _iteration: int
    _schema_violations: Annotated[int, operator.add]
    analyst_input: Any
    analyze_spec_result: Any
    architecture_notes: str
    artifact_store: dict
    code: str
    code_artifact_output: Any
    dependencies: list
    final_package: Any
    generate_artifacts_result: Any
    generator_input: Any
    prompt: str
    spec: str
    spec_content: str
    technical_spec_output: Any
    test_artifact_output: Any
    test_writer_input: Any
    tests: str


# ═══════════════════════════════════════════════════════════
# Stores
# ═══════════════════════════════════════════════════════════

class Store_artifact_store:
    """Artifact Store (file)"""
    def __init__(self):
        self.data = {}

    def read(self, key=None):
        return self.data if key is None else self.data.get(key)

    def write(self, value, key=None):
        if key is not None:
            self.data[key] = value
        else:
            self.data = value


# Store instances
_store_artifact_store = Store_artifact_store()


# ═══════════════════════════════════════════════════════════
# Agent Wrappers
# ═══════════════════════════════════════════════════════════

def invoke_spec_analyst_agent(user_message, output_schema=None):
    """Specification Analyst"""
    system = """You are a technical architect. Analyze natural language requirements and produce a structured technical specification.
Identify all functions, classes, data models, external dependencies, and edge cases.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Specification Analyst", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_code_generator_agent(user_message, output_schema=None):
    """Code Generator"""
    system = """You are an expert software engineer. Generate implementation code based on a technical specification.
Include inline comments and a dependency manifest.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Code Generator", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_test_writer_agent(user_message, output_schema=None):
    """Test Writer"""
    system = """You are a QA engineer. Write comprehensive tests based ONLY on a technical specification.
Cover happy paths, edge cases, and error handling.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Test Writer", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result



# ═══════════════════════════════════════════════════════════
# Node Functions
# ═══════════════════════════════════════════════════════════

def node_intake_request(state: AgentState) -> dict:
    """
    Intake Request
    Receive natural language prompt from user
    """
    print(f"  → Intake Request")
    updates = {}

    # Logic from spec
    updates["prompt"] = state.get("prompt", "")
    print(f"Received request: {state.get('prompt', "")[:100]}...")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_analyze_spec(state: AgentState) -> dict:
    """
    Analyze Specification
    Invoke the Analyst to create a technical spec
    """
    print(f"  → Analyze Specification")
    updates = {}

    # Logic from spec
    # Prepare input for the analyst
    updates["analyst_input"] = {"prompt": state.get("prompt")}
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Get Technical Spec
    _cur = dict(state)
    _cur.update(updates)
    spec_analyst_agent_input = build_input(_cur, "CodegenRequest")
    spec_analyst_agent_msg = json.dumps(spec_analyst_agent_input, default=str)
    spec_analyst_agent_raw = invoke_spec_analyst_agent(spec_analyst_agent_msg, output_schema="TechnicalSpecOutput")
    spec_analyst_agent_result = parse_response(spec_analyst_agent_raw, "TechnicalSpecOutput")
    updates["_schema_violations"] = len(validate_output(spec_analyst_agent_result, "TechnicalSpecOutput"))
    updates.update(spec_analyst_agent_result)
    updates["technical_spec_output"] = spec_analyst_agent_result
    updates["analyze_spec_result"] = spec_analyst_agent_result
    print(f"    ← Specification Analyst: {spec_analyst_agent_result}")

    return updates


def node_generate_artifacts(state: AgentState) -> dict:
    """
    Generate Artifacts (Fan-Out)
    Invoke Code Generator and Test Writer in parallel
    """
    print(f"  → Generate Artifacts (Fan-Out)")
    updates = {}

    # Logic from spec
    # Prepare inputs for parallel agents from the analyst's output
    spec = state.get("technical_spec_output", {})
    updates["generator_input"] = {"spec": spec.get("spec_content")}
    updates["test_writer_input"] = {"spec": spec.get("spec_content")}
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Generate Code
    _cur = dict(state)
    _cur.update(updates)
    code_generator_agent_input = build_input(_cur, "GeneratorInput")
    code_generator_agent_msg = json.dumps(code_generator_agent_input, default=str)
    code_generator_agent_raw = invoke_code_generator_agent(code_generator_agent_msg, output_schema="CodeArtifactOutput")
    code_generator_agent_result = parse_response(code_generator_agent_raw, "CodeArtifactOutput")
    updates["_schema_violations"] = len(validate_output(code_generator_agent_result, "CodeArtifactOutput"))
    updates.update(code_generator_agent_result)
    updates["code_artifact_output"] = code_generator_agent_result
    updates["generate_artifacts_result"] = code_generator_agent_result
    print(f"    ← Code Generator: {code_generator_agent_result}")

    # Invoke: Generate Tests
    _cur = dict(state)
    _cur.update(updates)
    test_writer_agent_input = build_input(_cur, "TestWriterInput")
    test_writer_agent_msg = json.dumps(test_writer_agent_input, default=str)
    test_writer_agent_raw = invoke_test_writer_agent(test_writer_agent_msg, output_schema="TestArtifactOutput")
    test_writer_agent_result = parse_response(test_writer_agent_raw, "TestArtifactOutput")
    updates["_schema_violations"] = len(validate_output(test_writer_agent_result, "TestArtifactOutput"))
    updates.update(test_writer_agent_result)
    updates["test_artifact_output"] = test_writer_agent_result
    updates["generate_artifacts_result"] = test_writer_agent_result
    print(f"    ← Test Writer: {test_writer_agent_result}")

    return updates


def node_synthesis(state: AgentState) -> dict:
    """
    Synthesize Results
    Combine code and tests into a final package
    """
    print(f"  → Synthesize Results")
    updates = {}

    # Logic from spec
    # Merge namespaced outputs
    code_out = state.get("code_artifact_output", {})
    test_out = state.get("test_artifact_output", {})
    updates["final_package"] = {
      "code": code_out.get("code"),
      "tests": test_out.get("tests"),
      "dependencies": code_out.get("dependencies")
    }
    if updates.get("_done") or state.get("_done"):
        return updates

    # Write: Save artifacts
    _cur = dict(state)
    _cur.update(updates)
    artifact_store_write = build_input(_cur, "FinalArtifacts")
    _store_artifact_store.write(artifact_store_write)

    return updates


def node_final_output(state: AgentState) -> dict:
    """
    Final Output
    Mark process as complete
    """
    print(f"  → Final Output")
    updates = {}

    # Logic from spec
    print("Generation complete. Artifacts stored.")
    updates["_done"] = True
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


# ═══════════════════════════════════════════════════════════
# Gate Routing Functions
# ═══════════════════════════════════════════════════════════

# ═══════════════════════════════════════════════════════════
# Graph Construction
# ═══════════════════════════════════════════════════════════

def build_graph():
    graph = StateGraph(AgentState)

    graph.add_node("intake_request", node_intake_request)
    graph.add_node("analyze_spec", node_analyze_spec)
    graph.add_node("generate_artifacts", node_generate_artifacts)
    graph.add_node("synthesis", node_synthesis)
    graph.add_node("final_output", node_final_output)

    graph.set_entry_point("intake_request")

    graph.add_edge("intake_request", "analyze_spec")
    graph.add_edge("analyze_spec", "generate_artifacts")
    graph.add_edge("generate_artifacts", "synthesis")
    graph.add_edge("synthesis", "final_output")
    graph.add_edge("final_output", END)

    return graph.compile()


# ═══════════════════════════════════════════════════════════
# Entry Point
# ═══════════════════════════════════════════════════════════

class _StateCompat:
    """Wrapper to make LangGraph state compatible with test harness."""
    def __init__(self, state_dict):
        self.data = {k: v for k, v in state_dict.items() if not k.startswith("_")}
        self.data.update({k: v for k, v in state_dict.items() if k.startswith("_")})
        self.iteration = state_dict.get("_iteration", 0)
        self.schema_violations = state_dict.get("_schema_violations", 0)

    def get(self, key, default=None):
        return self.data.get(key, default)


MAX_ITERATIONS = int(os.environ.get("AGENT_ONTOLOGY_MAX_ITER", "100"))


def run(initial_data=None):
    """Multi-Agent Code Generation Pipeline — LangGraph execution"""
    app = build_graph()

    # Build initial state
    state = {}
    if initial_data:
        state.update(initial_data)
    state["_iteration"] = 0
    state["_schema_violations"] = 0
    state["_done"] = False

    print(f"\n════════════════════════════════════════════════════════════")
    print(f"  Multi-Agent Code Generation Pipeline (LangGraph)")
    print(f"  Automated pipeline for generating, testing, and reviewing code from natural language specs using specialized agents with parallel artifact generation.")
    print(f"════════════════════════════════════════════════════════════\n")

    # LangGraph recursion limit maps roughly to our MAX_ITERATIONS
    try:
        final_state = app.invoke(state, {"recursion_limit": MAX_ITERATIONS * 3})
    except Exception as e:
        print(f"\n  [ERROR] {type(e).__name__}: {e}")
        final_state = state

    _clean_exit = True
    dump_trace(iterations=final_state.get("_iteration", 0), clean_exit=_clean_exit)
    print(f"\nFinal state keys: {list(final_state.keys())}")
    return _StateCompat(final_state)


if __name__ == "__main__":
    run()