#!/usr/bin/env python3
"""
ReAct — Generated by OpenClaw Instantiation Engine (LangGraph backend)
Spec: Reason + Act agent that interleaves thinking with tool use to solve problems
"""

import json
import operator
import os
import sys
import time
from datetime import datetime
from typing import Any, TypedDict, Annotated

from langgraph.graph import StateGraph, END

# ═══════════════════════════════════════════════════════════
# Trace Log
# ═══════════════════════════════════════════════════════════

TRACE = []

def trace_call(agent_label, model, system_prompt, user_message, response, duration_ms):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "agent": agent_label,
        "model": model,
        "system_prompt": system_prompt,
        "user_message": user_message,
        "response": response,
        "duration_ms": duration_ms,
    }
    TRACE.append(entry)
    print(f"    [{agent_label}] ({model}, {duration_ms}ms)")
    print(f"      IN:  {user_message[:300]}")
    print(f"      OUT: {response[:300]}")


def dump_trace(path="trace.json", iterations=0, clean_exit=True):
    total_ms = sum(e["duration_ms"] for e in TRACE)
    agents_used = list(set(e["agent"] for e in TRACE))
    schema_ok = 0
    for e in TRACE:
        try:
            r = e["response"].strip()
            if r.startswith("```"): r = "\n".join(r.split("\n")[1:-1])
            json.loads(r if r.startswith("{") else r[r.find("{"):r.rfind("}")+1])
            schema_ok += 1
        except (json.JSONDecodeError, ValueError):
            pass
    est_input_tokens = sum(len(e.get("user_message",""))//4 for e in TRACE)
    est_output_tokens = sum(len(e.get("response",""))//4 for e in TRACE)
    metrics = {
        "total_llm_calls": len(TRACE),
        "total_duration_ms": total_ms,
        "avg_call_ms": total_ms // max(len(TRACE), 1),
        "iterations": iterations,
        "clean_exit": clean_exit,
        "agents_used": agents_used,
        "schema_compliance": f"{schema_ok}/{len(TRACE)}",
        "est_input_tokens": est_input_tokens,
        "est_output_tokens": est_output_tokens,
    }
    output = {"metrics": metrics, "trace": TRACE}
    with open(path, "w") as f:
        json.dump(output, f, indent=2)
    print(f"\nTrace written to {path} ({len(TRACE)} calls, {total_ms}ms total)")
    print(f"  Schema compliance: {schema_ok}/{len(TRACE)}, est tokens: ~{est_input_tokens}in/~{est_output_tokens}out")
    return metrics

# ═══════════════════════════════════════════════════════════
# LLM Call Infrastructure
# ═══════════════════════════════════════════════════════════

_MODEL_OVERRIDE = os.environ.get("OPENCLAW_MODEL", "")
_OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")


def _openrouter_model_id(model):
    """Map spec model names to OpenRouter model IDs (provider/model format)."""
    if "/" in model:
        return model
    if model.startswith("gemini"):
        return f"google/{model}"
    if model.startswith("claude") or model.startswith("anthropic"):
        return f"anthropic/{model}"
    if model.startswith("gpt") or model.startswith("o1") or model.startswith("o3"):
        return f"openai/{model}"
    return model


def _get_chat_model(model, temperature=0.7, max_tokens=4096):
    """Get a LangChain ChatModel instance for the given model name."""
    if _OPENROUTER_API_KEY:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=_openrouter_model_id(model),
            temperature=temperature,
            max_tokens=max_tokens,
            base_url="https://openrouter.ai/api/v1",
            api_key=_OPENROUTER_API_KEY,
        )
    if model.startswith("gemini"):
        from langchain_google_genai import ChatGoogleGenerativeAI
        return ChatGoogleGenerativeAI(model=model, temperature=temperature,
                                      max_output_tokens=max_tokens,
                                      google_api_key=os.environ.get("GEMINI_API_KEY", ""))
    elif model.startswith("claude") or model.startswith("anthropic"):
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(model=model, temperature=temperature, max_tokens=max_tokens)
    else:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(model=model, temperature=temperature, max_tokens=max_tokens)


def call_llm(model, system_prompt, user_message, temperature=0.7, max_tokens=4096, retries=3):
    if _MODEL_OVERRIDE:
        model = _MODEL_OVERRIDE
    from langchain_core.messages import SystemMessage, HumanMessage
    for attempt in range(retries):
        try:
            chat = _get_chat_model(model, temperature, max_tokens)
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_message)]
            response = chat.invoke(messages)
            content = response.content
            # LangChain may return content as a list of blocks (e.g. Gemini)
            if isinstance(content, list):
                content = " ".join(b.get("text", str(b)) if isinstance(b, dict) else str(b) for b in content)
            return content
        except Exception as e:
            if attempt < retries - 1:
                wait = 2 ** attempt
                print(f"    [RETRY] {type(e).__name__}: {e} — retrying in {wait}s (attempt {attempt+1}/{retries})")
                import time as _time; _time.sleep(wait)
            else:
                print(f"    [FAIL] {type(e).__name__}: {e} after {retries} attempts")
                return json.dumps({"stub": True, "model": model, "error": str(e)})

# ═══════════════════════════════════════════════════════════
# Schema Registry
# ═══════════════════════════════════════════════════════════

SCHEMAS = {
    "ReActInput": {
        "description": """Input to the reasoning agent""",
        "fields": [{"name": "query", "type": "string"}, {"name": "trajectory", "type": "list<TrajectoryEntry>"}, {"name": "step_count", "type": "integer"}],
    },
    "ReActStep": {
        "description": """One reasoning or action step""",
        "fields": [{"name": "type", "type": "enum[thought, action, answer]"}, {"name": "thought", "type": "string"}, {"name": "action", "type": "string"}, {"name": "tool_name", "type": "string"}, {"name": "tool_input", "type": "string"}, {"name": "answer", "type": "string"}],
    },
    "ToolInput": {
        "description": """Input to a tool""",
        "fields": [{"name": "tool_name", "type": "string"}, {"name": "input", "type": "string"}],
    },
    "ToolOutput": {
        "description": """Output from a tool""",
        "fields": [{"name": "output", "type": "string"}, {"name": "success", "type": "boolean"}],
    },
    "Observation": {
        "description": """Result of executing an action""",
        "fields": [{"name": "observation", "type": "string"}, {"name": "tool_name", "type": "string"}],
    },
    "TrajectoryEntry": {
        "description": """One step in the trajectory""",
        "fields": [{"name": "step_num", "type": "integer"}, {"name": "thought", "type": "string"}, {"name": "action", "type": "string"}, {"name": "observation", "type": "string"}],
    },
    "UserQuery": {
        "description": """User's question to the agent""",
        "fields": [{"name": "query", "type": "string"}],
    },
    "Answer": {
        "description": """Final answer""",
        "fields": [{"name": "answer", "type": "string"}, {"name": "trajectory", "type": "list<TrajectoryEntry>"}],
    },
}


def validate_output(data, schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema or "raw" in data:
        return []
    issues = []
    for field in schema["fields"]:
        fname = field["name"]
        ftype = field["type"]
        if fname not in data:
            issues.append(f"Missing field '{fname}' ({ftype})")
            continue
        val = data[fname]
        if ftype == "string" and not isinstance(val, str):
            issues.append(f"Field '{fname}' expected string, got {type(val).__name__}")
        elif ftype == "integer" and not isinstance(val, (int, float)):
            issues.append(f"Field '{fname}' expected integer, got {type(val).__name__}")
        elif ftype.startswith("list") and not isinstance(val, list):
            issues.append(f"Field '{fname}' expected list, got {type(val).__name__}")
        elif ftype.startswith("enum["):
            allowed = [v.strip() for v in ftype[5:-1].split(",")]
            if val not in allowed:
                issues.append(f"Field '{fname}' value '{val}' not in {allowed}")
    if issues:
        print(f"    [SCHEMA] {schema_name}: {len(issues)} issue(s): {issues[0]}")
    return issues


def build_input(state, schema_name):
    """Build an input dict for an agent call using schema field names."""
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return dict(state)
    result = {}
    for field in schema["fields"]:
        fname = field["name"]
        if fname in state:
            result[fname] = state[fname]
        else:
            for _k, _v in state.items():
                if isinstance(_v, dict) and fname in _v:
                    result[fname] = _v[fname]
                    break
    return result


def output_instruction(schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return ""
    fields = ", ".join(f'"{f["name"]}": <{f["type"]}>' for f in schema["fields"])
    return f"\n\nRespond with ONLY valid JSON matching this schema: {{{fields}}}"


def parse_response(response, schema_name):
    import re as _re
    text = response.strip()
    if text.startswith("```"):
        lines = text.split("\n")
        lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        text = "\n".join(lines)
    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
        return {"value": parsed}
    except json.JSONDecodeError:
        pass
    start = text.find("{")
    end = text.rfind("}") + 1
    if start >= 0 and end > start:
        candidate = text[start:end]
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass
        fixed = _re.sub(r",\s*}", "}", candidate)
        fixed = _re.sub(r",\s*]", "]", fixed)
        try:
            return json.loads(fixed)
        except json.JSONDecodeError:
            pass
        depth = 0
        for i, ch in enumerate(text[start:], start):
            if ch == "{": depth += 1
            elif ch == "}": depth -= 1
            if depth == 0:
                try:
                    return json.loads(text[start:i+1])
                except json.JSONDecodeError:
                    break
    return {"raw": response}

# ═══════════════════════════════════════════════════════════
# State TypedDict
# ═══════════════════════════════════════════════════════════

class AgentState(TypedDict, total=False):
    """Typed state for ReAct"""
    _canned_responses: list
    _done: bool
    _iteration: int
    _schema_violations: Annotated[int, operator.add]
    action: str
    answer: str
    input: str
    max_steps: Any
    observation: str
    output: str
    query: str
    step_count: int
    step_num: int
    success: bool
    think_or_act_result: Any
    thought: str
    tool_input: str
    tool_name: str
    trajectory: list
    trajectory_store: list
    type: str


# ═══════════════════════════════════════════════════════════
# Stores
# ═══════════════════════════════════════════════════════════

class Store_trajectory_store:
    """Trajectory (queue)"""
    def __init__(self):
        self.queue = []

    def read(self, key=None):
        return self.queue[0] if self.queue else None

    def write(self, value, key=None):
        self.queue.append(value)


# Store instances
_store_trajectory_store = Store_trajectory_store()


# ═══════════════════════════════════════════════════════════
# Agent Wrappers
# ═══════════════════════════════════════════════════════════

def invoke_reasoning_agent(user_message, output_schema=None):
    """Reasoning Agent"""
    system = """You are a ReAct agent. You solve problems by alternating between Thought and Action steps.

For each step, decide on ONE of three step types:
1. "thought" — reason about what to do next (set the thought field)
2. "action" — call a tool (set type to "action", and set tool_name and tool_input)
3. "answer" — provide your final answer when you have enough info (set the answer field)

Available tools:
- search: search Wikipedia for factual information
- lookup: get the full Wikipedia article intro for a specific term
- calculate: evaluate a mathematical expression (e.g. "2**10" or "sqrt(144)")

You will receive the full trajectory so far (all previous Thoughts, Actions, and Observations).
Continue from where you left off. Output only ONE step as JSON.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Reasoning Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result



# ═══════════════════════════════════════════════════════════
# Tool Implementations
# ═══════════════════════════════════════════════════════════

def tool_search_tool(input_text):
    """Search: Web search for factual information"""
    import requests
    import re as _re
    _headers = {"User-Agent": "OpenClaw/1.0 (agent research project)"} 
    try:
        resp = requests.get("https://en.wikipedia.org/w/api.php", params={
            "action": "query", "list": "search", "srsearch": input_text,
            "format": "json", "srlimit": 5
        }, headers=_headers, timeout=10)
        data = resp.json()
        results = data.get("query", {}).get("search", [])
        if not results:
            return f"No results found for: {input_text}"
        lines = []
        for r in results:
            snippet = _re.sub(r"<[^>]+>", "", r.get("snippet", ""))
            lines.append(f"{r['title']}: {snippet}")
        return "\n".join(lines)
    except Exception as e:
        return f"Search error: {e}"


def tool_lookup_tool(input_text):
    """Lookup: Look up a specific term or entity"""
    import requests
    _headers = {"User-Agent": "OpenClaw/1.0 (agent research project)"}
    try:
        resp = requests.get("https://en.wikipedia.org/w/api.php", params={
            "action": "query", "titles": input_text, "prop": "extracts",
            "exintro": True, "explaintext": True, "format": "json"
        }, headers=_headers, timeout=10)
        data = resp.json()
        pages = data.get("query", {}).get("pages", {})
        for pid, page in pages.items():
            if pid == "-1":
                return f"No Wikipedia article found for: {input_text}"
            extract = page.get("extract", "")
            if extract:
                return extract[:1500]
            return f"Article found but no extract available for: {input_text}"
        return f"No results for: {input_text}"
    except Exception as e:
        return f"Lookup error: {e}"


def tool_calculate_tool(input_text):
    """Calculate: Evaluate a mathematical expression"""
    import math
    _safe_ns = {
        "abs": abs, "round": round, "min": min, "max": max,
        "sum": sum, "pow": pow, "int": int, "float": float,
        "math": math, "pi": math.pi, "e": math.e,
        "sqrt": math.sqrt, "log": math.log, "sin": math.sin,
        "cos": math.cos, "tan": math.tan,
    }
    try:
        result = eval(input_text, {"__builtins__": {}}, _safe_ns)
        return str(result)
    except Exception as e:
        return f"Calculation error: {e}"



# ═══════════════════════════════════════════════════════════
# Node Functions
# ═══════════════════════════════════════════════════════════

def node_receive_query(state: AgentState) -> dict:
    """
    Receive Query
    Accept user query and initialize the trajectory
    """
    print(f"  → Receive Query")
    updates = {}

    # Logic from spec
    updates["trajectory"] = []
    updates["step_count"] = 0
    updates["max_steps"] = 10
    print(f"    Query: {state.get('query', '')}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_think_or_act(state: AgentState) -> dict:
    """
    Think / Act
    Send trajectory to reasoning agent, get next Thought, Action, or Answer
    """
    print(f"  → Think / Act")
    updates = {}

    # Logic from spec
    updates["step_count"] = state.get("step_count", 0) + 1
    print(f"    Step {state.get('step_count', "")}/{state.get('max_steps', 10)}")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Get next step
    _cur = dict(state)
    _cur.update(updates)
    reasoning_agent_input = build_input(_cur, "ReActInput")
    reasoning_agent_msg = json.dumps(reasoning_agent_input, default=str)
    reasoning_agent_raw = invoke_reasoning_agent(reasoning_agent_msg, output_schema="ReActStep")
    reasoning_agent_result = parse_response(reasoning_agent_raw, "ReActStep")
    updates["_schema_violations"] = len(validate_output(reasoning_agent_result, "ReActStep"))
    updates.update(reasoning_agent_result)
    updates["re_act_step"] = reasoning_agent_result
    updates["think_or_act_result"] = reasoning_agent_result
    print(f"    ← Reasoning Agent: {reasoning_agent_result}")

    return updates


def node_execute_action(state: AgentState) -> dict:
    """
    Execute Action
    Run the tool specified in the action and capture observation
    """
    print(f"  → Execute Action")
    updates = {}

    # Logic from spec
    action = state.get("action", "")
    tool_name = state.get("tool_name", "search")
    tool_input = state.get("tool_input", action)
    print(f"    Action[{tool_name}]: {tool_input[:100]}")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Tool dispatch
    _cur = dict(state)
    _cur.update(updates)
    _tool_name = _cur.get("tool_name", "").lower().strip()
    _tool_input = str(_cur.get("tool_input", _cur.get("action", "")))
    if _tool_name == "search":
        _tool_result = tool_search_tool(_tool_input)
    elif _tool_name == "lookup":
        _tool_result = tool_lookup_tool(_tool_input)
    elif _tool_name == "calculate":
        _tool_result = tool_calculate_tool(_tool_input)
    else:
        _tool_result = f"Unknown tool: {_tool_name}. Available: search, lookup, calculate"
    updates["observation"] = _tool_result
    print(f"    Observation: {_tool_result[:200]}")

    return updates


def node_record_step(state: AgentState) -> dict:
    """
    Record Step
    Append the current step (thought/action/observation) to trajectory
    """
    print(f"  → Record Step")
    updates = {}

    # Logic from spec
    step = {
        "step_num": state.get("step_count", 0),
        "thought": state.get("thought", ""),
        "action": state.get("action", ""),
        "observation": state.get("observation", ""),
    }
    trajectory = state.get("trajectory", [])
    trajectory.append(step)
    updates["trajectory"] = trajectory
    print(f"    Trajectory length: {len(trajectory)}")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Write: Persist step
    _cur = dict(state)
    _cur.update(updates)
    trajectory_store_write = build_input(_cur, "TrajectoryEntry")
    _store_trajectory_store.write(trajectory_store_write)

    return updates


def node_emit_answer(state: AgentState) -> dict:
    """
    Emit Answer
    Return the final answer to the user
    """
    print(f"  → Emit Answer")
    updates = {}

    # Logic from spec
    answer = state.get("answer", state.get("thought", "No answer found"))
    print(f"    Final Answer: {answer[:200]}")
    updates["_done"] = True
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


# ═══════════════════════════════════════════════════════════
# Gate Routing Functions
# ═══════════════════════════════════════════════════════════

def route_check_step_type(state: AgentState) -> str:
    """Gate: Step type? — type == answer"""
    if state.get("type") == "answer":
        print(f"    → is answer")
        return "emit_answer"
    else:
        print(f"    → is thought or action")
        return "check_action"


def route_check_action(state: AgentState) -> str:
    """Gate: Has action? — tool_name is not empty"""
    if bool(state.get("tool_name")):
        print(f"    → has tool_name")
        return "execute_action"
    else:
        print(f"    → no tool_name (thought only)")
        return "record_step"


def route_check_max_steps(state: AgentState) -> str:
    """Gate: Max steps? — step_count >= max_steps"""
    if (state.get("step_count", 0)) >= (state.get("max_steps", 0)):
        print(f"    → at limit")
        return "emit_answer"
    else:
        print(f"    → under limit")
        return "think_or_act"


# ═══════════════════════════════════════════════════════════
# Graph Construction
# ═══════════════════════════════════════════════════════════

def build_graph():
    graph = StateGraph(AgentState)

    graph.add_node("receive_query", node_receive_query)
    graph.add_node("think_or_act", node_think_or_act)
    graph.add_node("execute_action", node_execute_action)
    graph.add_node("record_step", node_record_step)
    graph.add_node("emit_answer", node_emit_answer)

    graph.set_entry_point("receive_query")

    graph.add_edge("receive_query", "think_or_act")
    graph.add_conditional_edges(
        "think_or_act",
        route_check_step_type,
        {
            "emit_answer": "emit_answer",
            "check_action": "check_action",
        }
    )
    graph.add_edge("execute_action", "record_step")
    graph.add_conditional_edges(
        "record_step",
        route_check_max_steps,
        {
            "think_or_act": "think_or_act",
            "emit_answer": "emit_answer",
        }
    )
    graph.add_edge("emit_answer", END)

    # Pass-through node for chained gate: check_action
    graph.add_node("check_action", lambda state: {})
    graph.add_conditional_edges(
        "check_action",
        route_check_action,
        {
            "record_step": "record_step",
            "execute_action": "execute_action",
        }
    )

    return graph.compile()


# ═══════════════════════════════════════════════════════════
# Entry Point
# ═══════════════════════════════════════════════════════════

class _StateCompat:
    """Wrapper to make LangGraph state compatible with test harness."""
    def __init__(self, state_dict):
        self.data = {k: v for k, v in state_dict.items() if not k.startswith("_")}
        self.data.update({k: v for k, v in state_dict.items() if k.startswith("_")})
        self.iteration = state_dict.get("_iteration", 0)
        self.schema_violations = state_dict.get("_schema_violations", 0)

    def get(self, key, default=None):
        return self.data.get(key, default)


MAX_ITERATIONS = int(os.environ.get("OPENCLAW_MAX_ITER", "100"))


def run(initial_data=None):
    """ReAct — LangGraph execution"""
    app = build_graph()

    # Build initial state
    state = {}
    if initial_data:
        state.update(initial_data)
    state["_iteration"] = 0
    state["_schema_violations"] = 0
    state["_done"] = False

    print(f"\n════════════════════════════════════════════════════════════")
    print(f"  ReAct (LangGraph)")
    print(f"  Reason + Act agent that interleaves thinking with tool use to solve problems")
    print(f"════════════════════════════════════════════════════════════\n")

    # LangGraph recursion limit maps roughly to our MAX_ITERATIONS
    try:
        final_state = app.invoke(state, {"recursion_limit": MAX_ITERATIONS * 3})
    except Exception as e:
        print(f"\n  [ERROR] {type(e).__name__}: {e}")
        final_state = state

    _clean_exit = True
    dump_trace(iterations=final_state.get("_iteration", 0), clean_exit=_clean_exit)
    print(f"\nFinal state keys: {list(final_state.keys())}")
    return _StateCompat(final_state)


if __name__ == "__main__":
    initial = {}
    initial["query"] = input("Enter query: ")
    run(initial)