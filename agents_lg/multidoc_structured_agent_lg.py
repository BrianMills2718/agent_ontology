#!/usr/bin/env python3
"""
MultiDoc Structured — Generated by Agent Ontology Instantiation Engine (LangGraph backend)
Spec: Multi-step document reasoning agent with explicit extraction, cross-checking, and verification stages. Designed to outperform single-shot on questions requiring contradiction detection, arithmetic aggregation, and multi-source reasoning.

"""

import json
import operator
import os
import sys
import time
from datetime import datetime
from typing import Any, TypedDict, Annotated

from langgraph.graph import StateGraph, END

# ═══════════════════════════════════════════════════════════
# Trace Log
# ═══════════════════════════════════════════════════════════

TRACE = []

def trace_call(agent_label, model, system_prompt, user_message, response, duration_ms):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "agent": agent_label,
        "model": model,
        "system_prompt": system_prompt,
        "user_message": user_message,
        "response": response,
        "duration_ms": duration_ms,
    }
    TRACE.append(entry)
    print(f"    [{agent_label}] ({model}, {duration_ms}ms)")
    print(f"      IN:  {user_message[:300]}")
    print(f"      OUT: {response[:300]}")


def dump_trace(path="trace.json", iterations=0, clean_exit=True):
    total_ms = sum(e["duration_ms"] for e in TRACE)
    agents_used = list(set(e["agent"] for e in TRACE))
    schema_ok = 0
    for e in TRACE:
        try:
            r = e["response"].strip()
            if r.startswith("```"): r = "\n".join(r.split("\n")[1:-1])
            json.loads(r if r.startswith("{") else r[r.find("{"):r.rfind("}")+1])
            schema_ok += 1
        except (json.JSONDecodeError, ValueError):
            pass
    est_input_tokens = sum(len(e.get("user_message",""))//4 for e in TRACE)
    est_output_tokens = sum(len(e.get("response",""))//4 for e in TRACE)
    metrics = {
        "total_llm_calls": len(TRACE),
        "total_duration_ms": total_ms,
        "avg_call_ms": total_ms // max(len(TRACE), 1),
        "iterations": iterations,
        "clean_exit": clean_exit,
        "agents_used": agents_used,
        "schema_compliance": f"{schema_ok}/{len(TRACE)}",
        "est_input_tokens": est_input_tokens,
        "est_output_tokens": est_output_tokens,
    }
    output = {"metrics": metrics, "trace": TRACE}
    with open(path, "w") as f:
        json.dump(output, f, indent=2)
    print(f"\nTrace written to {path} ({len(TRACE)} calls, {total_ms}ms total)")
    print(f"  Schema compliance: {schema_ok}/{len(TRACE)}, est tokens: ~{est_input_tokens}in/~{est_output_tokens}out")
    return metrics

# ═══════════════════════════════════════════════════════════
# LLM Call Infrastructure
# ═══════════════════════════════════════════════════════════

_MODEL_OVERRIDE = os.environ.get("AGENT_ONTOLOGY_MODEL", "")
_OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")


def _openrouter_model_id(model):
    """Map spec model names to OpenRouter model IDs (provider/model format)."""
    if "/" in model:
        return model
    if model.startswith("gemini"):
        return f"google/{model}"
    if model.startswith("claude") or model.startswith("anthropic"):
        return f"anthropic/{model}"
    if model.startswith("gpt") or model.startswith("o1") or model.startswith("o3"):
        return f"openai/{model}"
    return model


def _get_chat_model(model, temperature=0.7, max_tokens=8192):
    """Get a LangChain ChatModel instance for the given model name."""
    if _OPENROUTER_API_KEY:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=_openrouter_model_id(model),
            temperature=temperature,
            max_tokens=max_tokens,
            base_url="https://openrouter.ai/api/v1",
            api_key=_OPENROUTER_API_KEY,
        )
    if model.startswith("gemini"):
        from langchain_google_genai import ChatGoogleGenerativeAI
        return ChatGoogleGenerativeAI(model=model, temperature=temperature,
                                      max_output_tokens=max_tokens,
                                      google_api_key=os.environ.get("GEMINI_API_KEY", ""))
    elif model.startswith("claude") or model.startswith("anthropic"):
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(model=model, temperature=temperature, max_tokens=max_tokens)
    else:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(model=model, temperature=temperature, max_tokens=max_tokens)


def call_llm(model, system_prompt, user_message, temperature=0.7, max_tokens=8192, retries=3):
    if _MODEL_OVERRIDE:
        model = _MODEL_OVERRIDE
    from langchain_core.messages import SystemMessage, HumanMessage
    for attempt in range(retries):
        try:
            chat = _get_chat_model(model, temperature, max_tokens)
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_message)]
            response = chat.invoke(messages)
            content = response.content
            # LangChain may return content as a list of blocks (e.g. Gemini)
            if isinstance(content, list):
                content = " ".join(b.get("text", str(b)) if isinstance(b, dict) else str(b) for b in content)
            return content
        except Exception as e:
            if attempt < retries - 1:
                wait = 2 ** attempt
                print(f"    [RETRY] {type(e).__name__}: {e} — retrying in {wait}s (attempt {attempt+1}/{retries})")
                import time as _time; _time.sleep(wait)
            else:
                print(f"    [FAIL] {type(e).__name__}: {e} after {retries} attempts")
                return json.dumps({"stub": True, "model": model, "error": str(e)})


def call_embedding(texts, model="text-embedding-3-small", provider="openai"):
    """Generate embeddings for a list of texts."""
    if isinstance(texts, str):
        texts = [texts]
    if provider == "openai" or model.startswith("text-embedding"):
        from openai import OpenAI
        client = OpenAI()
        response = client.embeddings.create(model=model, input=texts)
        return [item.embedding for item in response.data]
    elif provider == "google" or model.startswith("models/"):
        from google import genai
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY", ""))
        result = client.models.embed_content(model=model or "models/text-embedding-004", contents=texts)
        return result.embeddings
    elif provider == "huggingface" or provider == "local":
        try:
            from sentence_transformers import SentenceTransformer
            _emb_model = SentenceTransformer(model or "all-MiniLM-L6-v2")
            return _emb_model.encode(texts).tolist()
        except ImportError:
            return [[] for _ in texts]
    else:
        from openai import OpenAI
        client = OpenAI()
        response = client.embeddings.create(model=model, input=texts)
        return [item.embedding for item in response.data]

# ═══════════════════════════════════════════════════════════
# Schema Registry
# ═══════════════════════════════════════════════════════════

SCHEMAS = {
    "ReasoningInput": {
        "description": """Input with context and query""",
        "fields": [{"name": "context", "type": "string"}, {"name": "query", "type": "string"}],
    },
    "ExtractionOutput": {
        "description": """Extracted facts with source attribution""",
        "fields": [{"name": "extracted_facts", "type": "array"}, {"name": "contradictions", "type": "array"}],
    },
    "ReasoningStepInput": {
        "description": """Input to the reasoning step""",
        "fields": [{"name": "extracted_facts", "type": "array"}, {"name": "contradictions", "type": "array"}, {"name": "query", "type": "string"}],
    },
    "ReasoningOutput": {
        "description": """Final answer with reasoning""",
        "fields": [{"name": "answer", "type": "string"}, {"name": "reasoning", "type": "string"}],
    },
    "VerificationInput": {
        "description": """Input to the verification step""",
        "fields": [{"name": "context", "type": "string"}, {"name": "query", "type": "string"}, {"name": "answer", "type": "string"}, {"name": "reasoning", "type": "string"}],
    },
}


def validate_output(data, schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema or "raw" in data:
        return []
    issues = []
    for field in schema["fields"]:
        fname = field["name"]
        ftype = field["type"]
        if fname not in data:
            issues.append(f"Missing field '{fname}' ({ftype})")
            continue
        val = data[fname]
        if ftype == "string" and not isinstance(val, str):
            issues.append(f"Field '{fname}' expected string, got {type(val).__name__}")
        elif ftype == "integer" and not isinstance(val, (int, float)):
            issues.append(f"Field '{fname}' expected integer, got {type(val).__name__}")
        elif ftype.startswith("list") and not isinstance(val, list):
            issues.append(f"Field '{fname}' expected list, got {type(val).__name__}")
        elif ftype.startswith("enum["):
            allowed = [v.strip() for v in ftype[5:-1].split(",")]
            if val not in allowed:
                issues.append(f"Field '{fname}' value '{val}' not in {allowed}")
    if issues:
        print(f"    [SCHEMA] {schema_name}: {len(issues)} issue(s): {issues[0]}")
    return issues


def build_input(state, schema_name):
    """Build an input dict for an agent call using schema field names."""
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return dict(state)
    result = {}
    for field in schema["fields"]:
        fname = field["name"]
        if fname in state:
            result[fname] = state[fname]
        else:
            for _k, _v in state.items():
                if isinstance(_v, dict) and fname in _v:
                    result[fname] = _v[fname]
                    break
    return result


def output_instruction(schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return ""
    fields = ", ".join(f'"{f["name"]}": <{f["type"]}>' for f in schema["fields"])
    return f"\n\nRespond with ONLY valid JSON matching this schema: {{{fields}}}"


def parse_response(response, schema_name):
    import re as _re
    text = response.strip()
    if text.startswith("```"):
        lines = text.split("\n")
        lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        text = "\n".join(lines)
    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
        return {"value": parsed}
    except json.JSONDecodeError:
        pass
    start = text.find("{")
    end = text.rfind("}") + 1
    if start >= 0 and end > start:
        candidate = text[start:end]
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass
        fixed = _re.sub(r",\s*}", "}", candidate)
        fixed = _re.sub(r",\s*]", "]", fixed)
        try:
            return json.loads(fixed)
        except json.JSONDecodeError:
            pass
        depth = 0
        for i, ch in enumerate(text[start:], start):
            if ch == "{": depth += 1
            elif ch == "}": depth -= 1
            if depth == 0:
                try:
                    return json.loads(text[start:i+1])
                except json.JSONDecodeError:
                    break
    return {"raw": response}

# ═══════════════════════════════════════════════════════════
# State TypedDict
# ═══════════════════════════════════════════════════════════

class AgentState(TypedDict, total=False):
    """Typed state for MultiDoc Structured"""
    _canned_responses: list
    _done: bool
    _iteration: int
    _schema_violations: Annotated[int, operator.add]
    answer: str
    context: str
    contradictions: Any
    extract_facts_result: Any
    extracted_facts: Any
    query: str
    reason_result: Any
    reasoning: str
    verify_result: Any


# ═══════════════════════════════════════════════════════════
# Agent Wrappers
# ═══════════════════════════════════════════════════════════

def invoke_extractor(user_message, output_schema=None):
    """Fact Extractor"""
    system = """You are a fact extraction assistant. Given a set of fact cards and a question, extract ONLY the specific facts relevant to answering the question.
For each relevant fact, note: - The source card ID (A, B, C, etc.) - The specific fact or number - Any caveats (e.g., "self-reported", "according to audit", "before/after event")
If two sources contradict each other, extract BOTH facts and flag the contradiction.
Output as JSON: {"extracted_facts": [{"source": "A", "fact": "...", "caveat": "..."}], "contradictions": [{"fact1_source": "A", "fact2_source": "B", "description": "..."}]}
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=8192,
    )
    trace_call("Fact Extractor", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_reasoner(user_message, output_schema=None):
    """Reasoning Agent"""
    system = """You are a reasoning assistant. Given extracted facts (with source IDs and caveats) and a question, reason step-by-step to produce an answer.
Rules: - When sources contradict, prefer independent audits/studies over self-reported data. - For arithmetic: show your calculation step by step. - For negation questions ("which did NOT..."): check each option systematically. - For temporal questions: establish a timeline before answering.
Output as JSON: {"reasoning": "step-by-step explanation", "answer": "concise answer"}
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=8192,
    )
    trace_call("Reasoning Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_verifier(user_message, output_schema=None):
    """Answer Verifier"""
    system = """You are a verification assistant. Given the original question, fact cards, and a proposed answer with reasoning, verify the answer is correct.
Check: 1. Does the answer actually address the question asked? 2. Is the answer supported by the cited sources? 3. If arithmetic was involved, is the calculation correct? 4. Were any contradictions handled correctly (preferring independent sources)? 5. For negation questions, were all options checked?
IMPORTANT: Always output the actual answer text in the "answer" field, never "same answer". If the answer is correct, output: {"verified": true, "answer": "<the actual answer>", "reasoning": "why it's correct"} If incorrect, output: {"verified": false, "answer": "<corrected answer>", "reasoning": "what was wrong and the correction"}
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=8192,
    )
    trace_call("Answer Verifier", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result



# ═══════════════════════════════════════════════════════════
# Node Functions
# ═══════════════════════════════════════════════════════════

def node_receive_query(state: AgentState) -> dict:
    """
    Receive Query
    Accept the question and fact card context
    """
    print(f"  → Receive Query")
    updates = {}

    return updates


def node_extract_facts(state: AgentState) -> dict:
    """
    Extract Facts
    Extract relevant facts from each source with attribution
    """
    print(f"  → Extract Facts")
    updates = {}

    # Invoke: extractor
    _cur = dict(state)
    _cur.update(updates)
    extractor_input = build_input(_cur, "ReasoningInput")
    extractor_msg = json.dumps(extractor_input, default=str)
    extractor_raw = invoke_extractor(extractor_msg, output_schema="ExtractionOutput")
    extractor_result = parse_response(extractor_raw, "ExtractionOutput")
    updates["_schema_violations"] = len(validate_output(extractor_result, "ExtractionOutput"))
    updates.update(extractor_result)
    updates["extraction_output"] = extractor_result
    updates["extract_facts_result"] = extractor_result
    print(f"    ← Fact Extractor: {extractor_result}")

    return updates


def node_reason(state: AgentState) -> dict:
    """
    Reason
    Reason step-by-step using extracted facts to produce an answer
    """
    print(f"  → Reason")
    updates = {}

    # Invoke: reasoner
    _cur = dict(state)
    _cur.update(updates)
    reasoner_input = build_input(_cur, "ReasoningStepInput")
    reasoner_msg = json.dumps(reasoner_input, default=str)
    reasoner_raw = invoke_reasoner(reasoner_msg, output_schema="ReasoningOutput")
    reasoner_result = parse_response(reasoner_raw, "ReasoningOutput")
    updates["_schema_violations"] = len(validate_output(reasoner_result, "ReasoningOutput"))
    updates.update(reasoner_result)
    updates["reasoning_output"] = reasoner_result
    updates["reason_result"] = reasoner_result
    print(f"    ← Reasoning Agent: {reasoner_result}")

    return updates


def node_verify(state: AgentState) -> dict:
    """
    Verify Answer
    Cross-check the answer against original sources
    """
    print(f"  → Verify Answer")
    updates = {}

    # Invoke: verifier
    _cur = dict(state)
    _cur.update(updates)
    verifier_input = build_input(_cur, "VerificationInput")
    verifier_msg = json.dumps(verifier_input, default=str)
    verifier_raw = invoke_verifier(verifier_msg, output_schema="ReasoningOutput")
    verifier_result = parse_response(verifier_raw, "ReasoningOutput")
    updates["_schema_violations"] = len(validate_output(verifier_result, "ReasoningOutput"))
    updates.update(verifier_result)
    updates["reasoning_output"] = verifier_result
    updates["verify_result"] = verifier_result
    print(f"    ← Answer Verifier: {verifier_result}")

    return updates


def node_emit_answer(state: AgentState) -> dict:
    """
    Emit Answer
    Return the verified final answer
    """
    print(f"  → Emit Answer")
    updates = {}

    return updates


# ═══════════════════════════════════════════════════════════
# Gate Routing Functions
# ═══════════════════════════════════════════════════════════

# ═══════════════════════════════════════════════════════════
# Graph Construction
# ═══════════════════════════════════════════════════════════

def build_graph():
    graph = StateGraph(AgentState)

    graph.add_node("receive_query", node_receive_query)
    graph.add_node("extract_facts", node_extract_facts)
    graph.add_node("reason", node_reason)
    graph.add_node("verify", node_verify)
    graph.add_node("emit_answer", node_emit_answer)

    graph.set_entry_point("receive_query")

    graph.add_edge("receive_query", "extract_facts")
    graph.add_edge("extract_facts", "reason")
    graph.add_edge("reason", "verify")
    graph.add_edge("verify", "emit_answer")
    graph.add_edge("emit_answer", END)

    return graph.compile()


# ═══════════════════════════════════════════════════════════
# Entry Point
# ═══════════════════════════════════════════════════════════

class _StateCompat:
    """Wrapper to make LangGraph state compatible with test harness."""
    def __init__(self, state_dict):
        self.data = {k: v for k, v in state_dict.items() if not k.startswith("_")}
        self.data.update({k: v for k, v in state_dict.items() if k.startswith("_")})
        self.iteration = state_dict.get("_iteration", 0)
        self.schema_violations = state_dict.get("_schema_violations", 0)

    def get(self, key, default=None):
        return self.data.get(key, default)


MAX_ITERATIONS = int(os.environ.get("AGENT_ONTOLOGY_MAX_ITER", "100"))


def run(initial_data=None):
    """MultiDoc Structured — LangGraph execution"""
    app = build_graph()

    # Build initial state
    state = {}
    if initial_data:
        state.update(initial_data)
    state["_iteration"] = 0
    state["_schema_violations"] = 0
    state["_done"] = False

    print(f"\n════════════════════════════════════════════════════════════")
    print(f"  MultiDoc Structured (LangGraph)")
    print(f"  Multi-step document reasoning agent with explicit extraction, cross-checking, and verification stages. Designed to outperform single-shot on questions requiring contradiction detection, arithmetic aggregation, and multi-source reasoning.")
    print(f"════════════════════════════════════════════════════════════\n")

    # LangGraph recursion limit maps roughly to our MAX_ITERATIONS
    try:
        final_state = app.invoke(state, {"recursion_limit": MAX_ITERATIONS * 3})
    except Exception as e:
        print(f"\n  [ERROR] {type(e).__name__}: {e}")
        final_state = state

    _clean_exit = True
    dump_trace(iterations=final_state.get("_iteration", 0), clean_exit=_clean_exit)
    print(f"\nFinal state keys: {list(final_state.keys())}")
    return _StateCompat(final_state)


if __name__ == "__main__":
    run()