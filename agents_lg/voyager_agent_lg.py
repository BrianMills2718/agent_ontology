#!/usr/bin/env python3
"""
Voyager Exploration Agent — Generated by Agent Ontology Instantiation Engine (LangGraph backend)
Spec: An open-ended exploration agent that autonomously proposes objectives, learns skills, and accumulates them in a persistent library.
"""

import json
import operator
import os
import sys
import time
from datetime import datetime
from typing import Any, TypedDict, Annotated

from langgraph.graph import StateGraph, END

# ═══════════════════════════════════════════════════════════
# Trace Log
# ═══════════════════════════════════════════════════════════

TRACE = []

def trace_call(agent_label, model, system_prompt, user_message, response, duration_ms):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "agent": agent_label,
        "model": model,
        "system_prompt": system_prompt,
        "user_message": user_message,
        "response": response,
        "duration_ms": duration_ms,
    }
    TRACE.append(entry)
    print(f"    [{agent_label}] ({model}, {duration_ms}ms)")
    print(f"      IN:  {user_message[:300]}")
    print(f"      OUT: {response[:300]}")


def dump_trace(path="trace.json", iterations=0, clean_exit=True):
    total_ms = sum(e["duration_ms"] for e in TRACE)
    agents_used = list(set(e["agent"] for e in TRACE))
    schema_ok = 0
    for e in TRACE:
        try:
            r = e["response"].strip()
            if r.startswith("```"): r = "\n".join(r.split("\n")[1:-1])
            json.loads(r if r.startswith("{") else r[r.find("{"):r.rfind("}")+1])
            schema_ok += 1
        except (json.JSONDecodeError, ValueError):
            pass
    est_input_tokens = sum(len(e.get("user_message",""))//4 for e in TRACE)
    est_output_tokens = sum(len(e.get("response",""))//4 for e in TRACE)
    metrics = {
        "total_llm_calls": len(TRACE),
        "total_duration_ms": total_ms,
        "avg_call_ms": total_ms // max(len(TRACE), 1),
        "iterations": iterations,
        "clean_exit": clean_exit,
        "agents_used": agents_used,
        "schema_compliance": f"{schema_ok}/{len(TRACE)}",
        "est_input_tokens": est_input_tokens,
        "est_output_tokens": est_output_tokens,
    }
    output = {"metrics": metrics, "trace": TRACE}
    with open(path, "w") as f:
        json.dump(output, f, indent=2)
    print(f"\nTrace written to {path} ({len(TRACE)} calls, {total_ms}ms total)")
    print(f"  Schema compliance: {schema_ok}/{len(TRACE)}, est tokens: ~{est_input_tokens}in/~{est_output_tokens}out")
    return metrics

# ═══════════════════════════════════════════════════════════
# LLM Call Infrastructure
# ═══════════════════════════════════════════════════════════

_MODEL_OVERRIDE = os.environ.get("AGENT_ONTOLOGY_MODEL", "")
_OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")


def _openrouter_model_id(model):
    """Map spec model names to OpenRouter model IDs (provider/model format)."""
    if "/" in model:
        return model
    if model.startswith("gemini"):
        return f"google/{model}"
    if model.startswith("claude") or model.startswith("anthropic"):
        return f"anthropic/{model}"
    if model.startswith("gpt") or model.startswith("o1") or model.startswith("o3"):
        return f"openai/{model}"
    return model


def _get_chat_model(model, temperature=0.7, max_tokens=4096):
    """Get a LangChain ChatModel instance for the given model name."""
    if _OPENROUTER_API_KEY:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=_openrouter_model_id(model),
            temperature=temperature,
            max_tokens=max_tokens,
            base_url="https://openrouter.ai/api/v1",
            api_key=_OPENROUTER_API_KEY,
        )
    if model.startswith("gemini"):
        from langchain_google_genai import ChatGoogleGenerativeAI
        return ChatGoogleGenerativeAI(model=model, temperature=temperature,
                                      max_output_tokens=max_tokens,
                                      google_api_key=os.environ.get("GEMINI_API_KEY", ""))
    elif model.startswith("claude") or model.startswith("anthropic"):
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(model=model, temperature=temperature, max_tokens=max_tokens)
    else:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(model=model, temperature=temperature, max_tokens=max_tokens)


def call_llm(model, system_prompt, user_message, temperature=0.7, max_tokens=4096, retries=3):
    if _MODEL_OVERRIDE:
        model = _MODEL_OVERRIDE
    from langchain_core.messages import SystemMessage, HumanMessage
    for attempt in range(retries):
        try:
            chat = _get_chat_model(model, temperature, max_tokens)
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_message)]
            response = chat.invoke(messages)
            content = response.content
            # LangChain may return content as a list of blocks (e.g. Gemini)
            if isinstance(content, list):
                content = " ".join(b.get("text", str(b)) if isinstance(b, dict) else str(b) for b in content)
            return content
        except Exception as e:
            if attempt < retries - 1:
                wait = 2 ** attempt
                print(f"    [RETRY] {type(e).__name__}: {e} — retrying in {wait}s (attempt {attempt+1}/{retries})")
                import time as _time; _time.sleep(wait)
            else:
                print(f"    [FAIL] {type(e).__name__}: {e} after {retries} attempts")
                return json.dumps({"stub": True, "model": model, "error": str(e)})

# ═══════════════════════════════════════════════════════════
# Schema Registry
# ═══════════════════════════════════════════════════════════

SCHEMAS = {
    "CurriculumInput": {
        "description": """""",
        "fields": [{"name": "env_description", "type": "string"}, {"name": "skill_summary", "type": "string"}],
    },
    "ObjectiveOutput": {
        "description": """""",
        "fields": [{"name": "objective", "type": "string"}],
    },
    "CoderInput": {
        "description": """""",
        "fields": [{"name": "objective", "type": "string"}, {"name": "retrieved_skills", "type": "list<string>"}, {"name": "reflection_feedback", "type": "string"}],
    },
    "CodeOutput": {
        "description": """""",
        "fields": [{"name": "skill_name", "type": "string"}, {"name": "description", "type": "string"}, {"name": "code", "type": "string"}],
    },
    "ExecutionInput": {
        "description": """""",
        "fields": [{"name": "code", "type": "string"}],
    },
    "ExecutionResult": {
        "description": """""",
        "fields": [{"name": "logs", "type": "string"}, {"name": "success", "type": "boolean"}],
    },
    "ReflectionInput": {
        "description": """""",
        "fields": [{"name": "objective", "type": "string"}, {"name": "code", "type": "string"}, {"name": "logs", "type": "string"}],
    },
    "ReflectionOutput": {
        "description": """""",
        "fields": [{"name": "success", "type": "boolean"}, {"name": "feedback", "type": "string"}],
    },
    "SkillEntry": {
        "description": """""",
        "fields": [{"name": "skill_name", "type": "string"}, {"name": "code", "type": "string"}, {"name": "description", "type": "string"}],
    },
}


def validate_output(data, schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema or "raw" in data:
        return []
    issues = []
    for field in schema["fields"]:
        fname = field["name"]
        ftype = field["type"]
        if fname not in data:
            issues.append(f"Missing field '{fname}' ({ftype})")
            continue
        val = data[fname]
        if ftype == "string" and not isinstance(val, str):
            issues.append(f"Field '{fname}' expected string, got {type(val).__name__}")
        elif ftype == "integer" and not isinstance(val, (int, float)):
            issues.append(f"Field '{fname}' expected integer, got {type(val).__name__}")
        elif ftype.startswith("list") and not isinstance(val, list):
            issues.append(f"Field '{fname}' expected list, got {type(val).__name__}")
        elif ftype.startswith("enum["):
            allowed = [v.strip() for v in ftype[5:-1].split(",")]
            if val not in allowed:
                issues.append(f"Field '{fname}' value '{val}' not in {allowed}")
    if issues:
        print(f"    [SCHEMA] {schema_name}: {len(issues)} issue(s): {issues[0]}")
    return issues


def build_input(state, schema_name):
    """Build an input dict for an agent call using schema field names."""
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return dict(state)
    result = {}
    for field in schema["fields"]:
        fname = field["name"]
        if fname in state:
            result[fname] = state[fname]
        else:
            for _k, _v in state.items():
                if isinstance(_v, dict) and fname in _v:
                    result[fname] = _v[fname]
                    break
    return result


def output_instruction(schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return ""
    fields = ", ".join(f'"{f["name"]}": <{f["type"]}>' for f in schema["fields"])
    return f"\n\nRespond with ONLY valid JSON matching this schema: {{{fields}}}"


def parse_response(response, schema_name):
    import re as _re
    text = response.strip()
    if text.startswith("```"):
        lines = text.split("\n")
        lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        text = "\n".join(lines)
    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
        return {"value": parsed}
    except json.JSONDecodeError:
        pass
    start = text.find("{")
    end = text.rfind("}") + 1
    if start >= 0 and end > start:
        candidate = text[start:end]
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass
        fixed = _re.sub(r",\s*}", "}", candidate)
        fixed = _re.sub(r",\s*]", "]", fixed)
        try:
            return json.loads(fixed)
        except json.JSONDecodeError:
            pass
        depth = 0
        for i, ch in enumerate(text[start:], start):
            if ch == "{": depth += 1
            elif ch == "}": depth -= 1
            if depth == 0:
                try:
                    return json.loads(text[start:i+1])
                except json.JSONDecodeError:
                    break
    return {"raw": response}

# ═══════════════════════════════════════════════════════════
# State TypedDict
# ═══════════════════════════════════════════════════════════

class AgentState(TypedDict, total=False):
    """Typed state for Voyager Exploration Agent"""
    _canned_responses: list
    _done: bool
    _iteration: int
    _schema_violations: Annotated[int, operator.add]
    code: str
    coder_input: Any
    curriculum_input: Any
    description: str
    env_description: str
    evaluate_result_result: Any
    feedback: str
    generate_code_result: Any
    iteration_count: Any
    logs: str
    max_iterations: Any
    objective: str
    propose_objective_result: Any
    reflection_feedback: str
    reflection_input: Any
    retrieved_skills: list
    retry_count: Any
    skill_library: list
    skill_name: str
    skill_summary: str
    success: bool


# ═══════════════════════════════════════════════════════════
# Stores
# ═══════════════════════════════════════════════════════════

try:
    import chromadb
    _chroma_client = chromadb.Client()
    _USE_CHROMA = True
except ImportError:
    _USE_CHROMA = False


class _ChromaVectorStore:
    def __init__(self, name):
        self._fallback = []
        self._collection = None
        if _USE_CHROMA:
            self._collection = _chroma_client.get_or_create_collection(name)
        else:
            print(f"    [VectorStore] using in-memory fallback")

    def read(self, query=None, top_k=5):
        if self._collection is not None:
            if query:
                results = self._collection.query(query_texts=[query], n_results=min(top_k, max(self._collection.count(), 1)))
                docs = results.get("documents", [[]])[0]
                metas = results.get("metadatas", [[]])[0]
                return [{"text": d, "metadata": m} for d, m in zip(docs, metas)]
            else:
                if self._collection.count() == 0:
                    return []
                all_data = self._collection.get()
                docs = all_data.get("documents", [])
                metas = all_data.get("metadatas", [])
                return [{"text": d, "metadata": m} for d, m in zip(docs, metas)]
        return self._fallback

    def write(self, value, key=None):
        text = value.get("text", str(value)) if isinstance(value, dict) else str(value)
        metadata = value.get("metadata", {}) if isinstance(value, dict) else {}
        clean_meta = {}
        for k, v in (metadata or {}).items():
            if isinstance(v, (str, int, float, bool)):
                clean_meta[k] = v
            elif v is not None:
                clean_meta[k] = str(v)
        if self._collection is not None:
            doc_id = key or f"doc_{self._collection.count()}"
            self._collection.add(documents=[text], metadatas=[clean_meta], ids=[doc_id])
        else:
            self._fallback.append(value if isinstance(value, dict) else {"text": text, "metadata": clean_meta})


class Store_skill_library:
    """Skill Library (vector)"""
    def __init__(self):
        self._store = _ChromaVectorStore("skill_library")

    def read(self, key=None):
        return self._store.read(query=key)

    def write(self, value, key=None):
        self._store.write(value, key=key)


# Store instances
_store_skill_library = Store_skill_library()


# ═══════════════════════════════════════════════════════════
# Agent Wrappers
# ═══════════════════════════════════════════════════════════

def invoke_curriculum_agent(user_message, output_schema=None):
    """Curriculum Agent"""
    system = """You are the Curriculum Agent for Voyager. Your goal is to propose novel and achievable objectives based on the current environment and the skills already discovered.
Examine the skill library summary and the environment description.
Propose an objective that expands the agent's capabilities.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Curriculum Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_coder_agent(user_message, output_schema=None):
    """Code Generation Agent"""
    system = """You are the Code Generation Agent. You write implementation code to accomplish a specific objective.
You have access to a set of retrieved skills that you can call or adapt.
If you receive self-reflection feedback from a previous failed attempt, use it to fix the errors.
Output the skill name, a brief description, and the complete Python code.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Code Generation Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_reflector_agent(user_message, output_schema=None):
    """Self-Reflection Agent"""
    system = """You are the Self-Reflection Agent. You evaluate the execution of a generated skill.
Compare the intended objective with the actual execution logs and errors.
Determine if the objective was met. If not, provide specific feedback on how to fix the code.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Self-Reflection Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result



# ═══════════════════════════════════════════════════════════
# Tool Implementations
# ═══════════════════════════════════════════════════════════

def tool_environment(input_text):
    """Minecraft Environment: The game environment where code is executed."""
    return f"[tool Minecraft Environment not implemented for input: {input_text}]"



# ═══════════════════════════════════════════════════════════
# Node Functions
# ═══════════════════════════════════════════════════════════

def node_start_exploration(state: AgentState) -> dict:
    """
    Initialize Exploration
    """
    print(f"  → Initialize Exploration")
    updates = {}

    # Logic from spec
    updates["iteration_count"] = 0
    updates["max_iterations"] = 50
    updates["env_description"] = "Spawn point in a forest biome near a river."
    updates["reflection_feedback"] = ""
    updates["retry_count"] = 0
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_propose_objective(state: AgentState) -> dict:
    """
    Propose Objective
    """
    print(f"  → Propose Objective")
    updates = {}

    # Logic from spec
    # Prepare input for curriculum agent
    updates["curriculum_input"] = {
      "env_description": state.get("env_description"),
      "skill_summary": "List of currently known skills..." 
    }
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: curriculum_agent
    _cur = dict(state)
    _cur.update(updates)
    curriculum_agent_input = build_input(_cur, "CurriculumInput")
    curriculum_agent_msg = json.dumps(curriculum_agent_input, default=str)
    curriculum_agent_raw = invoke_curriculum_agent(curriculum_agent_msg, output_schema="ObjectiveOutput")
    curriculum_agent_result = parse_response(curriculum_agent_raw, "ObjectiveOutput")
    updates["_schema_violations"] = len(validate_output(curriculum_agent_result, "ObjectiveOutput"))
    updates.update(curriculum_agent_result)
    updates["objective_output"] = curriculum_agent_result
    updates["propose_objective_result"] = curriculum_agent_result
    print(f"    ← Curriculum Agent: {curriculum_agent_result}")

    return updates


def node_retrieve_skills(state: AgentState) -> dict:
    """
    Retrieve Relevant Skills
    """
    print(f"  → Retrieve Relevant Skills")
    updates = {}

    # Read: 
    skill_library_data = _store_skill_library.read()
    updates["skill_library"] = skill_library_data

    # Logic from spec
    # Logic to query the skill_library based on the objective
    objective = state.get("objective", "")
    print(f"Retrieving skills for: {objective}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_generate_code(state: AgentState) -> dict:
    """
    Generate Skill Code
    """
    print(f"  → Generate Skill Code")
    updates = {}

    # Logic from spec
    updates["coder_input"] = {
      "objective": state.get("objective"),
      "retrieved_skills": state.get("retrieved_skills", []),
      "reflection_feedback": state.get("reflection_feedback", "")
    }
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: coder_agent
    _cur = dict(state)
    _cur.update(updates)
    coder_agent_input = build_input(_cur, "CoderInput")
    coder_agent_msg = json.dumps(coder_agent_input, default=str)
    coder_agent_raw = invoke_coder_agent(coder_agent_msg, output_schema="CodeOutput")
    coder_agent_result = parse_response(coder_agent_raw, "CodeOutput")
    updates["_schema_violations"] = len(validate_output(coder_agent_result, "CodeOutput"))
    updates.update(coder_agent_result)
    updates["code_output"] = coder_agent_result
    updates["generate_code_result"] = coder_agent_result
    print(f"    ← Code Generation Agent: {coder_agent_result}")

    return updates


def node_execute_skill(state: AgentState) -> dict:
    """
    Execute Skill
    """
    print(f"  → Execute Skill")
    updates = {}

    # Logic from spec
    print(f"Executing code for skill: {state.get('skill_name')}")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke tool: Minecraft Environment
    _cur = dict(state)
    _cur.update(updates)
    _tool_input = str(_cur.get("tool_input", _cur.get("input", "")))
    _tool_result = tool_environment(_tool_input)
    updates["observation"] = _tool_result
    print(f"    Observation: {_tool_result[:200]}")

    return updates


def node_evaluate_result(state: AgentState) -> dict:
    """
    Evaluate Result
    """
    print(f"  → Evaluate Result")
    updates = {}

    # Logic from spec
    updates["reflection_input"] = {
      "objective": state.get("objective"),
      "code": state.get("code"),
      "logs": state.get("logs")
    }
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: reflector_agent
    _cur = dict(state)
    _cur.update(updates)
    reflector_agent_input = build_input(_cur, "ReflectionInput")
    reflector_agent_msg = json.dumps(reflector_agent_input, default=str)
    reflector_agent_raw = invoke_reflector_agent(reflector_agent_msg, output_schema="ReflectionOutput")
    reflector_agent_result = parse_response(reflector_agent_raw, "ReflectionOutput")
    updates["_schema_violations"] = len(validate_output(reflector_agent_result, "ReflectionOutput"))
    updates.update(reflector_agent_result)
    updates["reflection_output"] = reflector_agent_result
    updates["evaluate_result_result"] = reflector_agent_result
    print(f"    ← Self-Reflection Agent: {reflector_agent_result}")

    return updates


def node_save_skill(state: AgentState) -> dict:
    """
    Save to Library
    """
    print(f"  → Save to Library")
    updates = {}

    # Logic from spec
    print(f"Saving successful skill: {state.get('skill_name')}")
    updates["retry_count"] = 0
    updates["reflection_feedback"] = ""
    if updates.get("_done") or state.get("_done"):
        return updates

    # Write: 
    _cur = dict(state)
    _cur.update(updates)
    skill_library_write = build_input(_cur, "SkillEntry")
    _store_skill_library.write(skill_library_write)

    return updates


def node_increment_iteration(state: AgentState) -> dict:
    """
    Increment Iteration
    """
    print(f"  → Increment Iteration")
    updates = {}

    # Logic from spec
    updates["iteration_count"] = state.get("iteration_count", 0) + 1
    updates["retry_count"] = 0
    updates["reflection_feedback"] = ""
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_end_exploration(state: AgentState) -> dict:
    """
    End Exploration
    """
    print(f"  → End Exploration")
    updates = {}

    # Logic from spec
    updates['_done'] = True
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


# ═══════════════════════════════════════════════════════════
# Gate Routing Functions
# ═══════════════════════════════════════════════════════════

def route_check_success(state: AgentState) -> str:
    """Gate: Is Skill Successful? — success == True"""
    if state.get("success") == True:
        print(f"    → yes")
        return "save_skill"
    else:
        print(f"    → no")
        return "check_retry_limit"


def route_check_retry_limit(state: AgentState) -> str:
    """Gate: Retry Limit? — retry_count < 3"""
    if (state.get("retry_count", 0)) < 3:
        print(f"    → retry")
        return "generate_code"
    else:
        print(f"    → abort")
        return "increment_iteration"


def route_check_exploration_limit(state: AgentState) -> str:
    """Gate: Continue Exploration? — iteration_count < max_iterations"""
    if (state.get("iteration_count", 0)) < (state.get("max_iterations", 0)):
        print(f"    → continue")
        return "propose_objective"
    else:
        print(f"    → stop")
        return "end_exploration"


# ═══════════════════════════════════════════════════════════
# Graph Construction
# ═══════════════════════════════════════════════════════════

def build_graph():
    graph = StateGraph(AgentState)

    graph.add_node("start_exploration", node_start_exploration)
    graph.add_node("propose_objective", node_propose_objective)
    graph.add_node("retrieve_skills", node_retrieve_skills)
    graph.add_node("generate_code", node_generate_code)
    graph.add_node("execute_skill", node_execute_skill)
    graph.add_node("evaluate_result", node_evaluate_result)
    graph.add_node("save_skill", node_save_skill)
    graph.add_node("increment_iteration", node_increment_iteration)
    graph.add_node("end_exploration", node_end_exploration)

    graph.set_entry_point("start_exploration")

    graph.add_edge("start_exploration", "propose_objective")
    graph.add_edge("propose_objective", "retrieve_skills")
    graph.add_edge("retrieve_skills", "generate_code")
    graph.add_edge("generate_code", "execute_skill")
    graph.add_edge("execute_skill", "evaluate_result")
    graph.add_conditional_edges(
        "evaluate_result",
        route_check_success,
        {
            "save_skill": "save_skill",
            "check_retry_limit": "check_retry_limit",
        }
    )
    graph.add_edge("save_skill", "increment_iteration")
    graph.add_conditional_edges(
        "increment_iteration",
        route_check_exploration_limit,
        {
            "propose_objective": "propose_objective",
            "end_exploration": "end_exploration",
        }
    )
    graph.add_edge("end_exploration", END)

    # Pass-through node for chained gate: check_retry_limit
    graph.add_node("check_retry_limit", lambda state: {})
    graph.add_conditional_edges(
        "check_retry_limit",
        route_check_retry_limit,
        {
            "generate_code": "generate_code",
            "increment_iteration": "increment_iteration",
        }
    )

    return graph.compile()


# ═══════════════════════════════════════════════════════════
# Entry Point
# ═══════════════════════════════════════════════════════════

class _StateCompat:
    """Wrapper to make LangGraph state compatible with test harness."""
    def __init__(self, state_dict):
        self.data = {k: v for k, v in state_dict.items() if not k.startswith("_")}
        self.data.update({k: v for k, v in state_dict.items() if k.startswith("_")})
        self.iteration = state_dict.get("_iteration", 0)
        self.schema_violations = state_dict.get("_schema_violations", 0)

    def get(self, key, default=None):
        return self.data.get(key, default)


MAX_ITERATIONS = int(os.environ.get("AGENT_ONTOLOGY_MAX_ITER", "100"))


def run(initial_data=None):
    """Voyager Exploration Agent — LangGraph execution"""
    app = build_graph()

    # Build initial state
    state = {}
    if initial_data:
        state.update(initial_data)
    state["_iteration"] = 0
    state["_schema_violations"] = 0
    state["_done"] = False

    print(f"\n════════════════════════════════════════════════════════════")
    print(f"  Voyager Exploration Agent (LangGraph)")
    print(f"  An open-ended exploration agent that autonomously proposes objectives, learns skills, and accumulates them in a persistent library.")
    print(f"════════════════════════════════════════════════════════════\n")

    # LangGraph recursion limit maps roughly to our MAX_ITERATIONS
    try:
        final_state = app.invoke(state, {"recursion_limit": MAX_ITERATIONS * 3})
    except Exception as e:
        print(f"\n  [ERROR] {type(e).__name__}: {e}")
        final_state = state

    _clean_exit = True
    dump_trace(iterations=final_state.get("_iteration", 0), clean_exit=_clean_exit)
    print(f"\nFinal state keys: {list(final_state.keys())}")
    return _StateCompat(final_state)


if __name__ == "__main__":
    run()