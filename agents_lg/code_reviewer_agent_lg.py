#!/usr/bin/env python3
"""
Code Review Agent — Generated by OpenClaw Instantiation Engine (LangGraph backend)
Spec: Automated code review agent that analyzes pull requests with specialized reviewers and synthesizes a final review, looping until quality is satisfactory.
"""

import json
import os
import sys
import time
from datetime import datetime
from typing import Any, TypedDict, Annotated

from langgraph.graph import StateGraph, END

# ═══════════════════════════════════════════════════════════
# Trace Log
# ═══════════════════════════════════════════════════════════

TRACE = []

def trace_call(agent_label, model, system_prompt, user_message, response, duration_ms):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "agent": agent_label,
        "model": model,
        "system_prompt": system_prompt,
        "user_message": user_message,
        "response": response,
        "duration_ms": duration_ms,
    }
    TRACE.append(entry)
    print(f"    [{agent_label}] ({model}, {duration_ms}ms)")
    print(f"      IN:  {user_message[:300]}")
    print(f"      OUT: {response[:300]}")


def dump_trace(path="trace.json", iterations=0, clean_exit=True):
    total_ms = sum(e["duration_ms"] for e in TRACE)
    agents_used = list(set(e["agent"] for e in TRACE))
    schema_ok = 0
    for e in TRACE:
        try:
            r = e["response"].strip()
            if r.startswith("```"): r = "\n".join(r.split("\n")[1:-1])
            json.loads(r if r.startswith("{") else r[r.find("{"):r.rfind("}")+1])
            schema_ok += 1
        except (json.JSONDecodeError, ValueError):
            pass
    est_input_tokens = sum(len(e.get("user_message",""))//4 for e in TRACE)
    est_output_tokens = sum(len(e.get("response",""))//4 for e in TRACE)
    metrics = {
        "total_llm_calls": len(TRACE),
        "total_duration_ms": total_ms,
        "avg_call_ms": total_ms // max(len(TRACE), 1),
        "iterations": iterations,
        "clean_exit": clean_exit,
        "agents_used": agents_used,
        "schema_compliance": f"{schema_ok}/{len(TRACE)}",
        "est_input_tokens": est_input_tokens,
        "est_output_tokens": est_output_tokens,
    }
    output = {"metrics": metrics, "trace": TRACE}
    with open(path, "w") as f:
        json.dump(output, f, indent=2)
    print(f"\nTrace written to {path} ({len(TRACE)} calls, {total_ms}ms total)")
    print(f"  Schema compliance: {schema_ok}/{len(TRACE)}, est tokens: ~{est_input_tokens}in/~{est_output_tokens}out")
    return metrics

# ═══════════════════════════════════════════════════════════
# LLM Call Infrastructure
# ═══════════════════════════════════════════════════════════

_MODEL_OVERRIDE = os.environ.get("OPENCLAW_MODEL", "")
_OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")


def _openrouter_model_id(model):
    """Map spec model names to OpenRouter model IDs (provider/model format)."""
    if "/" in model:
        return model
    if model.startswith("gemini"):
        return f"google/{model}"
    if model.startswith("claude") or model.startswith("anthropic"):
        return f"anthropic/{model}"
    if model.startswith("gpt") or model.startswith("o1") or model.startswith("o3"):
        return f"openai/{model}"
    return model


def _get_chat_model(model, temperature=0.7, max_tokens=4096):
    """Get a LangChain ChatModel instance for the given model name."""
    if _OPENROUTER_API_KEY:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=_openrouter_model_id(model),
            temperature=temperature,
            max_tokens=max_tokens,
            base_url="https://openrouter.ai/api/v1",
            api_key=_OPENROUTER_API_KEY,
        )
    if model.startswith("gemini"):
        from langchain_google_genai import ChatGoogleGenerativeAI
        return ChatGoogleGenerativeAI(model=model, temperature=temperature,
                                      max_output_tokens=max_tokens,
                                      google_api_key=os.environ.get("GEMINI_API_KEY", ""))
    elif model.startswith("claude") or model.startswith("anthropic"):
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(model=model, temperature=temperature, max_tokens=max_tokens)
    else:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(model=model, temperature=temperature, max_tokens=max_tokens)


def call_llm(model, system_prompt, user_message, temperature=0.7, max_tokens=4096, retries=3):
    if _MODEL_OVERRIDE:
        model = _MODEL_OVERRIDE
    from langchain_core.messages import SystemMessage, HumanMessage
    for attempt in range(retries):
        try:
            chat = _get_chat_model(model, temperature, max_tokens)
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_message)]
            response = chat.invoke(messages)
            content = response.content
            # LangChain may return content as a list of blocks (e.g. Gemini)
            if isinstance(content, list):
                content = " ".join(b.get("text", str(b)) if isinstance(b, dict) else str(b) for b in content)
            return content
        except Exception as e:
            if attempt < retries - 1:
                wait = 2 ** attempt
                print(f"    [RETRY] {type(e).__name__}: {e} — retrying in {wait}s (attempt {attempt+1}/{retries})")
                import time as _time; _time.sleep(wait)
            else:
                print(f"    [FAIL] {type(e).__name__}: {e} after {retries} attempts")
                return json.dumps({"stub": True, "model": model, "error": str(e)})

# ═══════════════════════════════════════════════════════════
# Schema Registry
# ═══════════════════════════════════════════════════════════

SCHEMAS = {
    "PRInput": {
        "description": """Input data for a pull request""",
        "fields": [{"name": "diff", "type": "string"}, {"name": "files", "type": "list<string>"}, {"name": "description", "type": "string"}],
    },
    "PRMetadata": {
        "description": """Stored pull request metadata""",
        "fields": [{"name": "diff", "type": "string"}, {"name": "files", "type": "list<string>"}, {"name": "description", "type": "string"}],
    },
    "SecurityReview": {
        "description": """Structured security review output""",
        "fields": [{"name": "issues", "type": "list<Issue>"}, {"name": "summary", "type": "string"}],
    },
    "StyleReview": {
        "description": """Structured style review output""",
        "fields": [{"name": "issues", "type": "list<Issue>"}, {"name": "summary", "type": "string"}],
    },
    "LogicReview": {
        "description": """Structured logic review output""",
        "fields": [{"name": "issues", "type": "list<Issue>"}, {"name": "summary", "type": "string"}],
    },
    "Issue": {
        "description": """A single review issue""",
        "fields": [{"name": "severity", "type": "enum[critical, warning, info]"}, {"name": "file", "type": "string"}, {"name": "line", "type": "integer"}, {"name": "description", "type": "string"}],
    },
    "SynthesizerInput": {
        "description": """Input to the lead reviewer synthesizer""",
        "fields": [{"name": "security_review", "type": "SecurityReview"}, {"name": "style_review", "type": "StyleReview"}, {"name": "logic_review", "type": "LogicReview"}],
    },
    "SynthesizedReview": {
        "description": """Final synthesized review output""",
        "fields": [{"name": "quality_score", "type": "integer"}, {"name": "issues", "type": "list<Issue>"}, {"name": "recommendation", "type": "enum[approve, request changes, comment]"}, {"name": "summary", "type": "string"}],
    },
    "PRStoreData": {
        "description": """Data stored in the PR key-value store""",
        "fields": [{"name": "pr_metadata", "type": "PRMetadata"}, {"name": "review_history", "type": "list<SynthesizedReview>"}],
    },
}


def validate_output(data, schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema or "raw" in data:
        return []
    issues = []
    for field in schema["fields"]:
        fname = field["name"]
        ftype = field["type"]
        if fname not in data:
            issues.append(f"Missing field '{fname}' ({ftype})")
            continue
        val = data[fname]
        if ftype == "string" and not isinstance(val, str):
            issues.append(f"Field '{fname}' expected string, got {type(val).__name__}")
        elif ftype == "integer" and not isinstance(val, (int, float)):
            issues.append(f"Field '{fname}' expected integer, got {type(val).__name__}")
        elif ftype.startswith("list") and not isinstance(val, list):
            issues.append(f"Field '{fname}' expected list, got {type(val).__name__}")
        elif ftype.startswith("enum["):
            allowed = [v.strip() for v in ftype[5:-1].split(",")]
            if val not in allowed:
                issues.append(f"Field '{fname}' value '{val}' not in {allowed}")
    if issues:
        print(f"    [SCHEMA] {schema_name}: {len(issues)} issue(s): {issues[0]}")
    return issues


def build_input(state, schema_name):
    """Build an input dict for an agent call using schema field names."""
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return dict(state)
    result = {}
    for field in schema["fields"]:
        fname = field["name"]
        if fname in state:
            result[fname] = state[fname]
        else:
            for _k, _v in state.items():
                if isinstance(_v, dict) and fname in _v:
                    result[fname] = _v[fname]
                    break
    return result


def output_instruction(schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return ""
    fields = ", ".join(f'"{f["name"]}": <{f["type"]}>' for f in schema["fields"])
    return f"\n\nRespond with ONLY valid JSON matching this schema: {{{fields}}}"


def parse_response(response, schema_name):
    import re as _re
    text = response.strip()
    if text.startswith("```"):
        lines = text.split("\n")
        lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        text = "\n".join(lines)
    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
        return {"value": parsed}
    except json.JSONDecodeError:
        pass
    start = text.find("{")
    end = text.rfind("}") + 1
    if start >= 0 and end > start:
        candidate = text[start:end]
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass
        fixed = _re.sub(r",\s*}", "}", candidate)
        fixed = _re.sub(r",\s*]", "]", fixed)
        try:
            return json.loads(fixed)
        except json.JSONDecodeError:
            pass
        depth = 0
        for i, ch in enumerate(text[start:], start):
            if ch == "{": depth += 1
            elif ch == "}": depth -= 1
            if depth == 0:
                try:
                    return json.loads(text[start:i+1])
                except json.JSONDecodeError:
                    break
    return {"raw": response}

# ═══════════════════════════════════════════════════════════
# State TypedDict
# ═══════════════════════════════════════════════════════════

class AgentState(TypedDict, total=False):
    """Typed state for Code Review Agent"""
    _canned_responses: list
    _done: bool
    _iteration: int
    _schema_violations: int
    description: str
    diff: str
    file: str
    files: list
    issues: list
    line: int
    logic_input: Any
    logic_review: Any
    pr_metadata: Any
    pr_store: dict
    quality_score: int
    recommendation: str
    review_cycles: Any
    review_history: list
    review_to_post: Any
    security_input: Any
    security_review: Any
    severity: str
    style_input: Any
    style_review: Any
    summary: str
    synth_input: Any
    synthesized_review: Any


# ═══════════════════════════════════════════════════════════
# Stores
# ═══════════════════════════════════════════════════════════

class Store_pr_store:
    """PR Metadata and Review Store (kv)"""
    def __init__(self):
        self.data = {}

    def read(self, key=None):
        return self.data if key is None else self.data.get(key)

    def write(self, value, key=None):
        if key is not None:
            self.data[key] = value
        else:
            self.data = value


# Store instances
_store_pr_store = Store_pr_store()


# ═══════════════════════════════════════════════════════════
# Agent Wrappers
# ═══════════════════════════════════════════════════════════

def invoke_intake_agent(user_message, output_schema=None):
    """Intake Agent"""
    system = """You receive pull request metadata including diff, files changed, and PR description. Store the PR metadata for downstream analysis.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Intake Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_security_reviewer(user_message, output_schema=None):
    """Security Reviewer"""
    system = """You analyze the full pull request diff for security vulnerabilities such as SQL injection, XSS, hardcoded secrets, and other risks. Provide a structured review of security issues.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Security Reviewer", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_style_reviewer(user_message, output_schema=None):
    """Style Reviewer"""
    system = """You analyze the full pull request diff for code style issues including naming conventions, formatting consistency, and style guide adherence. Provide a structured style review.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Style Reviewer", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_logic_reviewer(user_message, output_schema=None):
    """Logic Reviewer"""
    system = """You analyze the full pull request diff for logical errors, edge cases, and performance issues. Provide a structured logic review.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Logic Reviewer", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_lead_reviewer(user_message, output_schema=None):
    """Lead Reviewer"""
    system = """You synthesize the security, style, and logic reviews into a single structured review. Provide an overall quality score (1-10), a list of issues with severity (critical/warning/info), file, line, and description, and a summary recommendation (approve, request changes, or comment).
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Lead Reviewer", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result



# ═══════════════════════════════════════════════════════════
# Node Functions
# ═══════════════════════════════════════════════════════════

def node_intake_pr(state: AgentState) -> dict:
    """
    Intake Pull Request
    Receive PR metadata and store it
    """
    print(f"  → Intake Pull Request")
    updates = {}

    # Logic from spec
    # Store the PR metadata in dict(state) for downstream use
    updates["pr_metadata"] = state.get("pr_metadata", {})
    # Assume input contains pr_diff, pr_files, pr_description
    # Store as is for reviewers
    state.get("pr_metadata", "")["diff"] = state.get("diff", "")
    state.get("pr_metadata", "")["files"] = state.get("files", [])
    state.get("pr_metadata", "")["description"] = state.get("description", "")
    # Save to store will be done in write edge
    if updates.get("_done") or state.get("_done"):
        return updates

    # Write: Store PR metadata
    _cur = dict(state)
    _cur.update(updates)
    pr_store_write = build_input(_cur, "PRMetadata")
    _store_pr_store.write(pr_store_write)

    return updates


def node_analyze_security(state: AgentState) -> dict:
    """
    Analyze Security
    Prepare and send PR metadata to Security Reviewer
    """
    print(f"  → Analyze Security")
    updates = {}

    # Logic from spec
    # Pass full PR metadata to security reviewer
    updates["security_input"] = state.get("pr_metadata", {})
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Invoke Security Reviewer
    _cur = dict(state)
    _cur.update(updates)
    security_reviewer_input = build_input(_cur, "PRMetadata")
    security_reviewer_msg = json.dumps(security_reviewer_input, default=str)
    security_reviewer_raw = invoke_security_reviewer(security_reviewer_msg, output_schema="SecurityReview")
    security_reviewer_result = parse_response(security_reviewer_raw, "SecurityReview")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(security_reviewer_result, "SecurityReview"))
    updates.update(security_reviewer_result)
    updates["security_review"] = security_reviewer_result
    updates["analyze_security_result"] = security_reviewer_result
    print(f"    ← Security Reviewer: {security_reviewer_result}")

    return updates


def node_analyze_style(state: AgentState) -> dict:
    """
    Analyze Style
    Prepare and send PR metadata to Style Reviewer
    """
    print(f"  → Analyze Style")
    updates = {}

    # Logic from spec
    # Pass full PR metadata to style reviewer
    updates["style_input"] = state.get("pr_metadata", {})
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Invoke Style Reviewer
    _cur = dict(state)
    _cur.update(updates)
    style_reviewer_input = build_input(_cur, "PRMetadata")
    style_reviewer_msg = json.dumps(style_reviewer_input, default=str)
    style_reviewer_raw = invoke_style_reviewer(style_reviewer_msg, output_schema="StyleReview")
    style_reviewer_result = parse_response(style_reviewer_raw, "StyleReview")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(style_reviewer_result, "StyleReview"))
    updates.update(style_reviewer_result)
    updates["style_review"] = style_reviewer_result
    updates["analyze_style_result"] = style_reviewer_result
    print(f"    ← Style Reviewer: {style_reviewer_result}")

    return updates


def node_analyze_logic(state: AgentState) -> dict:
    """
    Analyze Logic
    Prepare and send PR metadata to Logic Reviewer
    """
    print(f"  → Analyze Logic")
    updates = {}

    # Logic from spec
    # Pass full PR metadata to logic reviewer
    updates["logic_input"] = state.get("pr_metadata", {})
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Invoke Logic Reviewer
    _cur = dict(state)
    _cur.update(updates)
    logic_reviewer_input = build_input(_cur, "PRMetadata")
    logic_reviewer_msg = json.dumps(logic_reviewer_input, default=str)
    logic_reviewer_raw = invoke_logic_reviewer(logic_reviewer_msg, output_schema="LogicReview")
    logic_reviewer_result = parse_response(logic_reviewer_raw, "LogicReview")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(logic_reviewer_result, "LogicReview"))
    updates.update(logic_reviewer_result)
    updates["logic_review"] = logic_reviewer_result
    updates["analyze_logic_result"] = logic_reviewer_result
    print(f"    ← Logic Reviewer: {logic_reviewer_result}")

    return updates


def node_synthesize_review(state: AgentState) -> dict:
    """
    Synthesize Review
    Combine all three reviews into a single structured review
    """
    print(f"  → Synthesize Review")
    updates = {}

    # Logic from spec
    # Combine security, style, and logic reviews into one input for lead reviewer
    updates["synth_input"] = {
      "security_review": state.get("security_review", {}),
      "style_review": state.get("style_review", {}),
      "logic_review": state.get("logic_review", {})
    }
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Invoke Lead Reviewer
    _cur = dict(state)
    _cur.update(updates)
    lead_reviewer_input = build_input(_cur, "SynthesizerInput")
    lead_reviewer_msg = json.dumps(lead_reviewer_input, default=str)
    lead_reviewer_raw = invoke_lead_reviewer(lead_reviewer_msg, output_schema="SynthesizedReview")
    lead_reviewer_result = parse_response(lead_reviewer_raw, "SynthesizedReview")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(lead_reviewer_result, "SynthesizedReview"))
    updates.update(lead_reviewer_result)
    updates["synthesized_review"] = lead_reviewer_result
    updates["synthesize_review_result"] = lead_reviewer_result
    print(f"    ← Lead Reviewer: {lead_reviewer_result}")

    return updates


def node_post_review(state: AgentState) -> dict:
    """
    Post Review
    Post synthesized review as PR comment and update store
    """
    print(f"  → Post Review")
    updates = {}

    # Logic from spec
    # Here would be logic to post comment to PR (external)
    # Update review history in store
    updates["review_to_post"] = state.get("synthesized_review", {})
    if updates.get("_done") or state.get("_done"):
        return updates

    # Write: Store review history
    _cur = dict(state)
    _cur.update(updates)
    pr_store_write = build_input(_cur, "SynthesizedReview")
    _store_pr_store.write(pr_store_write)

    return updates


def node_request_fixes(state: AgentState) -> dict:
    """
    Request Fixes from User
    """
    print(f"  → Request Fixes from User")
    updates = {}

    # Checkpoint (HITL)
    _canned = state.get("_canned_responses", [])
    if _canned:
        response = _canned[0]
        updates["_canned_responses"] = _canned[1:]
    else:
        response = input("The review quality score is below 7. Please address the issues and push new commits. [fixes pushed]: ").strip().lower()
    updates["checkpoint_response"] = response
    return updates


def node_wait_for_new_commits(state: AgentState) -> dict:
    """
    Wait for New Commits
    """
    print(f"  → Wait for New Commits")
    updates = {}

    # Checkpoint (HITL)
    _canned = state.get("_canned_responses", [])
    if _canned:
        response = _canned[0]
        updates["_canned_responses"] = _canned[1:]
    else:
        response = input("Waiting for new commits to be pushed after requested fixes. [new commits pushed]: ").strip().lower()
    updates["checkpoint_response"] = response
    return updates


def node_end_process(state: AgentState) -> dict:
    """
    End Process
    Review process complete with satisfactory quality score
    """
    print(f"  → End Process")
    updates = {}

    # Logic from spec
    updates["_done"] = True
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


# ═══════════════════════════════════════════════════════════
# Gate Routing Functions
# ═══════════════════════════════════════════════════════════

def route_check_quality(state: AgentState) -> str:
    """Gate: Is Quality Score >= 7? — quality_score >= 7"""
    if (state.get("quality_score", 0)) >= 7:
        print(f"    → yes")
        return "end_process"
    else:
        print(f"    → no")
        return "request_fixes"


# ═══════════════════════════════════════════════════════════
# Graph Construction
# ═══════════════════════════════════════════════════════════

def build_graph():
    graph = StateGraph(AgentState)

    graph.add_node("intake_pr", node_intake_pr)
    graph.add_node("analyze_security", node_analyze_security)
    graph.add_node("analyze_style", node_analyze_style)
    graph.add_node("analyze_logic", node_analyze_logic)
    graph.add_node("synthesize_review", node_synthesize_review)
    graph.add_node("post_review", node_post_review)
    graph.add_node("request_fixes", node_request_fixes)
    graph.add_node("wait_for_new_commits", node_wait_for_new_commits)
    graph.add_node("end_process", node_end_process)

    graph.set_entry_point("intake_pr")

    graph.add_edge("intake_pr", "analyze_security")
    graph.add_edge("intake_pr", "analyze_style")
    graph.add_edge("intake_pr", "analyze_logic")
    graph.add_edge("analyze_security", "synthesize_review")
    graph.add_edge("analyze_style", "synthesize_review")
    graph.add_edge("analyze_logic", "synthesize_review")
    graph.add_edge("synthesize_review", "post_review")
    graph.add_conditional_edges(
        "post_review",
        route_check_quality,
        {
            "end_process": "end_process",
            "request_fixes": "request_fixes",
        }
    )
    graph.add_edge("request_fixes", "wait_for_new_commits")
    graph.add_edge("wait_for_new_commits", "intake_pr")
    graph.add_edge("end_process", END)

    return graph.compile()


# ═══════════════════════════════════════════════════════════
# Entry Point
# ═══════════════════════════════════════════════════════════

class _StateCompat:
    """Wrapper to make LangGraph state compatible with test harness."""
    def __init__(self, state_dict):
        self.data = {k: v for k, v in state_dict.items() if not k.startswith("_")}
        self.data.update({k: v for k, v in state_dict.items() if k.startswith("_")})
        self.iteration = state_dict.get("_iteration", 0)
        self.schema_violations = state_dict.get("_schema_violations", 0)


MAX_ITERATIONS = int(os.environ.get("OPENCLAW_MAX_ITER", "100"))


def run(initial_data=None):
    """Code Review Agent — LangGraph execution"""
    app = build_graph()

    # Build initial state
    state = {}
    if initial_data:
        state.update(initial_data)
    state["_iteration"] = 0
    state["_schema_violations"] = 0
    state["_done"] = False

    print(f"\n════════════════════════════════════════════════════════════")
    print(f"  Code Review Agent (LangGraph)")
    print(f"  Automated code review agent that analyzes pull requests with specialized reviewers and synthesizes a final review, looping until quality is satisfactory.")
    print(f"════════════════════════════════════════════════════════════\n")

    # LangGraph recursion limit maps roughly to our MAX_ITERATIONS
    try:
        final_state = app.invoke(state, {"recursion_limit": MAX_ITERATIONS * 3})
    except Exception as e:
        print(f"\n  [ERROR] {type(e).__name__}: {e}")
        final_state = state

    _clean_exit = True
    dump_trace(iterations=final_state.get("_iteration", 0), clean_exit=_clean_exit)
    print(f"\nFinal state keys: {list(final_state.keys())}")
    return _StateCompat(final_state)


if __name__ == "__main__":
    run()