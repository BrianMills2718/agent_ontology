#!/usr/bin/env python3
"""
Crew — Generated by OpenClaw Instantiation Engine (LangGraph backend)
Spec: Multi-agent collaboration system where specialized agents work together under a coordinator
"""

import json
import os
import sys
import time
from datetime import datetime
from typing import Any, TypedDict, Annotated

from langgraph.graph import StateGraph, END

# ═══════════════════════════════════════════════════════════
# Trace Log
# ═══════════════════════════════════════════════════════════

TRACE = []

def trace_call(agent_label, model, system_prompt, user_message, response, duration_ms):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "agent": agent_label,
        "model": model,
        "system_prompt": system_prompt,
        "user_message": user_message,
        "response": response,
        "duration_ms": duration_ms,
    }
    TRACE.append(entry)
    print(f"    [{agent_label}] ({model}, {duration_ms}ms)")
    print(f"      IN:  {user_message[:300]}")
    print(f"      OUT: {response[:300]}")


def dump_trace(path="trace.json", iterations=0, clean_exit=True):
    total_ms = sum(e["duration_ms"] for e in TRACE)
    agents_used = list(set(e["agent"] for e in TRACE))
    schema_ok = 0
    for e in TRACE:
        try:
            r = e["response"].strip()
            if r.startswith("```"): r = "\n".join(r.split("\n")[1:-1])
            json.loads(r if r.startswith("{") else r[r.find("{"):r.rfind("}")+1])
            schema_ok += 1
        except (json.JSONDecodeError, ValueError):
            pass
    est_input_tokens = sum(len(e.get("user_message",""))//4 for e in TRACE)
    est_output_tokens = sum(len(e.get("response",""))//4 for e in TRACE)
    metrics = {
        "total_llm_calls": len(TRACE),
        "total_duration_ms": total_ms,
        "avg_call_ms": total_ms // max(len(TRACE), 1),
        "iterations": iterations,
        "clean_exit": clean_exit,
        "agents_used": agents_used,
        "schema_compliance": f"{schema_ok}/{len(TRACE)}",
        "est_input_tokens": est_input_tokens,
        "est_output_tokens": est_output_tokens,
    }
    output = {"metrics": metrics, "trace": TRACE}
    with open(path, "w") as f:
        json.dump(output, f, indent=2)
    print(f"\nTrace written to {path} ({len(TRACE)} calls, {total_ms}ms total)")
    print(f"  Schema compliance: {schema_ok}/{len(TRACE)}, est tokens: ~{est_input_tokens}in/~{est_output_tokens}out")
    return metrics

# ═══════════════════════════════════════════════════════════
# LLM Call Infrastructure
# ═══════════════════════════════════════════════════════════

_MODEL_OVERRIDE = os.environ.get("OPENCLAW_MODEL", "")
_OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "")


def _openrouter_model_id(model):
    """Map spec model names to OpenRouter model IDs (provider/model format)."""
    if "/" in model:
        return model
    if model.startswith("gemini"):
        return f"google/{model}"
    if model.startswith("claude") or model.startswith("anthropic"):
        return f"anthropic/{model}"
    if model.startswith("gpt") or model.startswith("o1") or model.startswith("o3"):
        return f"openai/{model}"
    return model


def _get_chat_model(model, temperature=0.7, max_tokens=4096):
    """Get a LangChain ChatModel instance for the given model name."""
    if _OPENROUTER_API_KEY:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=_openrouter_model_id(model),
            temperature=temperature,
            max_tokens=max_tokens,
            base_url="https://openrouter.ai/api/v1",
            api_key=_OPENROUTER_API_KEY,
        )
    if model.startswith("gemini"):
        from langchain_google_genai import ChatGoogleGenerativeAI
        return ChatGoogleGenerativeAI(model=model, temperature=temperature,
                                      max_output_tokens=max_tokens,
                                      google_api_key=os.environ.get("GEMINI_API_KEY", ""))
    elif model.startswith("claude") or model.startswith("anthropic"):
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(model=model, temperature=temperature, max_tokens=max_tokens)
    else:
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(model=model, temperature=temperature, max_tokens=max_tokens)


def call_llm(model, system_prompt, user_message, temperature=0.7, max_tokens=4096, retries=3):
    if _MODEL_OVERRIDE:
        model = _MODEL_OVERRIDE
    from langchain_core.messages import SystemMessage, HumanMessage
    for attempt in range(retries):
        try:
            chat = _get_chat_model(model, temperature, max_tokens)
            messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_message)]
            response = chat.invoke(messages)
            content = response.content
            # LangChain may return content as a list of blocks (e.g. Gemini)
            if isinstance(content, list):
                content = " ".join(b.get("text", str(b)) if isinstance(b, dict) else str(b) for b in content)
            return content
        except Exception as e:
            if attempt < retries - 1:
                wait = 2 ** attempt
                print(f"    [RETRY] {type(e).__name__}: {e} — retrying in {wait}s (attempt {attempt+1}/{retries})")
                import time as _time; _time.sleep(wait)
            else:
                print(f"    [FAIL] {type(e).__name__}: {e} after {retries} attempts")
                return json.dumps({"stub": True, "model": model, "error": str(e)})

# ═══════════════════════════════════════════════════════════
# Schema Registry
# ═══════════════════════════════════════════════════════════

SCHEMAS = {
    "CoordinatorInput": {
        "description": """Input to the coordinator""",
        "fields": [{"name": "objective", "type": "string"}],
    },
    "AssignmentList": {
        "description": """List of agent assignments""",
        "fields": [{"name": "assignments", "type": "list<object>"}, {"name": "objective", "type": "string"}],
    },
    "AgentTask": {
        "description": """Task for an individual agent""",
        "fields": [{"name": "task_description", "type": "string"}, {"name": "context", "type": "list<string>"}, {"name": "objective", "type": "string"}],
    },
    "AgentResult": {
        "description": """Result from an agent""",
        "fields": [{"name": "agent_output", "type": "string"}, {"name": "result", "type": "string"}],
    },
    "ReviewInput": {
        "description": """Input to the reviewer""",
        "fields": [{"name": "content_to_review", "type": "string"}, {"name": "objective", "type": "string"}],
    },
    "ReviewResult": {
        "description": """Review output""",
        "fields": [{"name": "review_score", "type": "integer"}, {"name": "approved", "type": "boolean"}, {"name": "improvements", "type": "string"}],
    },
    "SynthesisInput": {
        "description": """Input to synthesizer""",
        "fields": [{"name": "all_results", "type": "list<string>"}, {"name": "objective", "type": "string"}],
    },
    "SynthesisOutput": {
        "description": """Final synthesized output""",
        "fields": [{"name": "final_output", "type": "string"}, {"name": "synthesis", "type": "string"}],
    },
    "WorkItem": {
        "description": """Workspace entry""",
        "fields": [{"name": "key", "type": "string"}, {"name": "value", "type": "string"}, {"name": "agent", "type": "string"}],
    },
}


def validate_output(data, schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema or "raw" in data:
        return []
    issues = []
    for field in schema["fields"]:
        fname = field["name"]
        ftype = field["type"]
        if fname not in data:
            issues.append(f"Missing field '{fname}' ({ftype})")
            continue
        val = data[fname]
        if ftype == "string" and not isinstance(val, str):
            issues.append(f"Field '{fname}' expected string, got {type(val).__name__}")
        elif ftype == "integer" and not isinstance(val, (int, float)):
            issues.append(f"Field '{fname}' expected integer, got {type(val).__name__}")
        elif ftype.startswith("list") and not isinstance(val, list):
            issues.append(f"Field '{fname}' expected list, got {type(val).__name__}")
        elif ftype.startswith("enum["):
            allowed = [v.strip() for v in ftype[5:-1].split(",")]
            if val not in allowed:
                issues.append(f"Field '{fname}' value '{val}' not in {allowed}")
    if issues:
        print(f"    [SCHEMA] {schema_name}: {len(issues)} issue(s): {issues[0]}")
    return issues


def build_input(state, schema_name):
    """Build an input dict for an agent call using schema field names."""
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return dict(state)
    result = {}
    for field in schema["fields"]:
        fname = field["name"]
        if fname in state:
            result[fname] = state[fname]
        else:
            for _k, _v in state.items():
                if isinstance(_v, dict) and fname in _v:
                    result[fname] = _v[fname]
                    break
    return result


def output_instruction(schema_name):
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return ""
    fields = ", ".join(f'"{f["name"]}": <{f["type"]}>' for f in schema["fields"])
    return f"\n\nRespond with ONLY valid JSON matching this schema: {{{fields}}}"


def parse_response(response, schema_name):
    import re as _re
    text = response.strip()
    if text.startswith("```"):
        lines = text.split("\n")
        lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        text = "\n".join(lines)
    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
        return {"value": parsed}
    except json.JSONDecodeError:
        pass
    start = text.find("{")
    end = text.rfind("}") + 1
    if start >= 0 and end > start:
        candidate = text[start:end]
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass
        fixed = _re.sub(r",\s*}", "}", candidate)
        fixed = _re.sub(r",\s*]", "]", fixed)
        try:
            return json.loads(fixed)
        except json.JSONDecodeError:
            pass
        depth = 0
        for i, ch in enumerate(text[start:], start):
            if ch == "{": depth += 1
            elif ch == "}": depth -= 1
            if depth == 0:
                try:
                    return json.loads(text[start:i+1])
                except json.JSONDecodeError:
                    break
    return {"raw": response}

# ═══════════════════════════════════════════════════════════
# State TypedDict
# ═══════════════════════════════════════════════════════════

class AgentState(TypedDict, total=False):
    """Typed state for Crew"""
    _canned_responses: list
    _done: bool
    _iteration: int
    _schema_violations: int
    agent: str
    agent_output: str
    agent_results: Any
    all_results: list
    approved: bool
    assigned_agent: Any
    assignments: list
    content_to_review: str
    context: list
    current_assignment: Any
    current_assignment_idx: Any
    feedback: Any
    final_output: str
    improvements: str
    key: str
    max_revisions: Any
    objective: str
    researcher: Any
    result: str
    review_score: int
    revision_count: Any
    shared_workspace: dict
    synthesis: str
    task_description: str
    total_assignments: Any
    value: str
    writer: Any


# ═══════════════════════════════════════════════════════════
# Stores
# ═══════════════════════════════════════════════════════════

class Store_shared_workspace:
    """Shared Workspace (kv)"""
    def __init__(self):
        self.data = {}

    def read(self, key=None):
        return self.data if key is None else self.data.get(key)

    def write(self, value, key=None):
        if key is not None:
            self.data[key] = value
        else:
            self.data = value


# Store instances
_store_shared_workspace = Store_shared_workspace()


# ═══════════════════════════════════════════════════════════
# Agent Wrappers
# ═══════════════════════════════════════════════════════════

def invoke_coordinator(user_message, output_schema=None):
    """Coordinator"""
    system = """You are a project coordinator managing a team of AI agents. Given an objective,
break it into assignments for your team: a Researcher, a Writer, and a Reviewer.
Each assignment should specify: agent (researcher/writer/reviewer), task description,
and any dependencies on other assignments. Return as a JSON list of assignments.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Coordinator", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_researcher(user_message, output_schema=None):
    """Researcher"""
    system = """You are a research specialist. You receive a research task and produce comprehensive,
factual findings. Structure your output clearly with sections and bullet points.
Focus on accuracy and completeness.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Researcher", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_writer(user_message, output_schema=None):
    """Writer"""
    system = """You are a professional writer. You receive a writing task along with research context.
Produce clear, engaging, well-structured content. Use the research provided as your
source material. Maintain a professional tone.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Writer", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_reviewer(user_message, output_schema=None):
    """Reviewer"""
    system = """You are a quality reviewer. You receive content to review against the original objective.
Check for: accuracy, completeness, clarity, consistency. Provide a quality score (1-10)
and specific improvement suggestions. If score >= 7, approve. Otherwise, list required changes.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Reviewer", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result


def invoke_synthesizer(user_message, output_schema=None):
    """Synthesizer"""
    system = """You combine multiple agent results into a single coherent output. Integrate research,
writing, and review feedback into a polished final deliverable. Resolve any inconsistencies
between agent outputs.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Synthesizer", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result



# ═══════════════════════════════════════════════════════════
# Node Functions
# ═══════════════════════════════════════════════════════════

def node_receive_objective(state: AgentState) -> dict:
    """
    Receive Objective
    Accept the team objective
    """
    print(f"  → Receive Objective")
    updates = {}

    # Logic from spec
    updates["agent_results"] = {}
    updates["revision_count"] = 0
    updates["max_revisions"] = 2
    print(f"    Objective: {state.get('objective', '')}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_plan_assignments(state: AgentState) -> dict:
    """
    Plan Assignments
    Coordinator breaks objective into agent assignments
    """
    print(f"  → Plan Assignments")
    updates = {}

    # Invoke: Create assignments
    _cur = dict(state)
    _cur.update(updates)
    coordinator_input = build_input(_cur, "CoordinatorInput")
    coordinator_msg = json.dumps(coordinator_input, default=str)
    coordinator_raw = invoke_coordinator(coordinator_msg, output_schema="AssignmentList")
    coordinator_result = parse_response(coordinator_raw, "AssignmentList")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(coordinator_result, "AssignmentList"))
    updates.update(coordinator_result)
    updates["assignment_list"] = coordinator_result
    updates["plan_assignments_result"] = coordinator_result
    print(f"    ← Coordinator: {coordinator_result}")

    return updates


def node_execute_assignments(state: AgentState) -> dict:
    """
    Execute Assignments
    Run each assignment with the appropriate agent
    """
    print(f"  → Execute Assignments")
    updates = {}

    # Logic from spec
    assignments = state.get("assignments", [])
    updates["current_assignment_idx"] = 0
    updates["total_assignments"] = len(assignments)
    print(f"    {len(assignments)} assignments to execute")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_run_agent(state: AgentState) -> dict:
    """
    Run Agent
    Execute the current assignment with the assigned agent
    """
    print(f"  → Run Agent")
    updates = {}

    # Logic from spec
    assignments = state.get("assignments", [])
    idx = state.get("current_assignment_idx", 0)
    if idx < len(assignments):
        assignment = assignments[idx]
        updates["current_assignment"] = assignment
        updates["task_description"] = assignment.get("task", "")
        updates["assigned_agent"] = assignment.get("agent", "researcher")
        context_keys = assignment.get("depends_on", [])
        updates["context"] = [state.get("agent_results", "").get(k, "") for k in context_keys if k in state.get("agent_results", {})]
        print(f"    Assignment {idx + 1}/{len(assignments)}: [{state.get('assigned_agent', "")}] {state.get('task_description', "")[:80]}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_call_researcher(state: AgentState) -> dict:
    """
    Call Researcher
    Send task to researcher agent
    """
    print(f"  → Call Researcher")
    updates = {}

    # Invoke: Research
    _cur = dict(state)
    _cur.update(updates)
    researcher_input = build_input(_cur, "AgentTask")
    researcher_msg = json.dumps(researcher_input, default=str)
    researcher_raw = invoke_researcher(researcher_msg, output_schema="AgentResult")
    researcher_result = parse_response(researcher_raw, "AgentResult")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(researcher_result, "AgentResult"))
    updates.update(researcher_result)
    updates["agent_result"] = researcher_result
    updates["call_researcher_result"] = researcher_result
    print(f"    ← Researcher: {researcher_result}")

    return updates


def node_call_writer(state: AgentState) -> dict:
    """
    Call Writer
    Send task to writer agent
    """
    print(f"  → Call Writer")
    updates = {}

    # Invoke: Write
    _cur = dict(state)
    _cur.update(updates)
    writer_input = build_input(_cur, "AgentTask")
    writer_msg = json.dumps(writer_input, default=str)
    writer_raw = invoke_writer(writer_msg, output_schema="AgentResult")
    writer_result = parse_response(writer_raw, "AgentResult")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(writer_result, "AgentResult"))
    updates.update(writer_result)
    updates["agent_result"] = writer_result
    updates["call_writer_result"] = writer_result
    print(f"    ← Writer: {writer_result}")

    return updates


def node_call_reviewer_agent(state: AgentState) -> dict:
    """
    Call Reviewer
    Send task to reviewer agent
    """
    print(f"  → Call Reviewer")
    updates = {}

    # Invoke: Review
    _cur = dict(state)
    _cur.update(updates)
    reviewer_input = build_input(_cur, "ReviewInput")
    reviewer_msg = json.dumps(reviewer_input, default=str)
    reviewer_raw = invoke_reviewer(reviewer_msg, output_schema="ReviewResult")
    reviewer_result = parse_response(reviewer_raw, "ReviewResult")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(reviewer_result, "ReviewResult"))
    updates.update(reviewer_result)
    updates["review_result"] = reviewer_result
    updates["call_reviewer_agent_result"] = reviewer_result
    print(f"    ← Reviewer: {reviewer_result}")

    return updates


def node_collect_result(state: AgentState) -> dict:
    """
    Collect Result
    Store the agent's result and advance to next assignment
    """
    print(f"  → Collect Result")
    updates = {}

    # Logic from spec
    idx = state.get("current_assignment_idx", 0)
    assignment = state.get("current_assignment", {})
    result_text = state.get("agent_output", state.get("result", ""))
    agent_results = state.get("agent_results", {})
    agent_results[f"assignment_{idx}"] = result_text
    updates["agent_results"] = agent_results
    updates["current_assignment_idx"] = idx + 1
    print(f"    Collected result for assignment {idx + 1}")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Write: Store result
    _cur = dict(state)
    _cur.update(updates)
    shared_workspace_write = build_input(_cur, "WorkItem")
    _store_shared_workspace.write(shared_workspace_write)

    return updates


def node_review_all(state: AgentState) -> dict:
    """
    Review All
    Send all results to reviewer for quality check
    """
    print(f"  → Review All")
    updates = {}

    # Logic from spec
    agent_results = state.get("agent_results", {})
    updates["content_to_review"] = "\n\n".join(str(v) for v in agent_results.values())
    print(f"    Reviewing {len(agent_results)} results")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Quality review
    _cur = dict(state)
    _cur.update(updates)
    reviewer_input = build_input(_cur, "ReviewInput")
    reviewer_msg = json.dumps(reviewer_input, default=str)
    reviewer_raw = invoke_reviewer(reviewer_msg, output_schema="ReviewResult")
    reviewer_result = parse_response(reviewer_raw, "ReviewResult")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(reviewer_result, "ReviewResult"))
    updates.update(reviewer_result)
    updates["review_result"] = reviewer_result
    updates["review_all_result"] = reviewer_result
    print(f"    ← Reviewer: {reviewer_result}")

    return updates


def node_handle_revision(state: AgentState) -> dict:
    """
    Handle Revision
    Process review feedback and decide whether to revise
    """
    print(f"  → Handle Revision")
    updates = {}

    # Logic from spec
    count = state.get("revision_count", 0) + 1
    updates["revision_count"] = count
    max_rev = state.get("max_revisions", 2)
    if count >= max_rev:
        print(f"    Max revisions ({max_rev}) reached, proceeding")
    else:
        updates["feedback"] = state.get("improvements", "")
        print(f"    Revision {count}/{max_rev}")
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


def node_synthesize(state: AgentState) -> dict:
    """
    Synthesize
    Combine all agent results into the final deliverable
    """
    print(f"  → Synthesize")
    updates = {}

    # Logic from spec
    agent_results = state.get("agent_results", {})
    updates["all_results"] = list(agent_results.values())
    print(f"    Synthesizing {len(agent_results)} results into final output")
    if updates.get("_done") or state.get("_done"):
        return updates

    # Flatten nested dicts
    _combined = dict(state)
    _combined.update(updates)
    for _nested_val in list(_combined.values()):
        if isinstance(_nested_val, dict):
            for _nk, _nv in _nested_val.items():
                if _nk not in _combined:
                    updates[_nk] = _nv

    # Invoke: Combine results
    _cur = dict(state)
    _cur.update(updates)
    synthesizer_input = build_input(_cur, "SynthesisInput")
    synthesizer_msg = json.dumps(synthesizer_input, default=str)
    synthesizer_raw = invoke_synthesizer(synthesizer_msg, output_schema="SynthesisOutput")
    synthesizer_result = parse_response(synthesizer_raw, "SynthesisOutput")
    updates["_schema_violations"] = state.get("_schema_violations", 0) + len(validate_output(synthesizer_result, "SynthesisOutput"))
    updates.update(synthesizer_result)
    updates["synthesis_output"] = synthesizer_result
    updates["synthesize_result"] = synthesizer_result
    print(f"    ← Synthesizer: {synthesizer_result}")

    return updates


def node_emit_output(state: AgentState) -> dict:
    """
    Emit Output
    Return the final deliverable
    """
    print(f"  → Emit Output")
    updates = {}

    # Logic from spec
    output = state.get("final_output", state.get("synthesis", ""))
    print(f"    Final output: {str(output)[:200]}")
    updates["_done"] = True
    if updates.get("_done") or state.get("_done"):
        return updates

    return updates


# ═══════════════════════════════════════════════════════════
# Gate Routing Functions
# ═══════════════════════════════════════════════════════════

def route_dispatch_agent(state: AgentState) -> str:
    """Gate: Which agent? — assigned_agent == researcher"""
    if state.get("assigned_agent") == "researcher":
        print(f"    → is researcher")
        return "call_researcher"
    else:
        print(f"    → is writer or reviewer")
        return "check_writer"


def route_check_writer(state: AgentState) -> str:
    """Gate: Writer? — assigned_agent == writer"""
    if state.get("assigned_agent") == "writer":
        print(f"    → is writer")
        return "call_writer"
    else:
        print(f"    → is reviewer")
        return "call_reviewer_agent"


def route_check_more_assignments(state: AgentState) -> str:
    """Gate: More assignments? — current_assignment_idx < total_assignments"""
    if (state.get("current_assignment_idx", 0)) < (state.get("total_assignments", 0)):
        print(f"    → more to do")
        return "run_agent"
    else:
        print(f"    → no more")
        return "review_all"


def route_quality_gate(state: AgentState) -> str:
    """Gate: Quality OK? — review_score >= 7"""
    if (state.get("review_score", 0)) >= 7:
        print(f"    → approved")
        return "synthesize"
    else:
        print(f"    → not approved")
        return "handle_revision"


def route_revision_gate(state: AgentState) -> str:
    """Gate: Retry or finalize? — revision_count >= max_revisions"""
    if (state.get("revision_count", 0)) >= (state.get("max_revisions", 0)):
        print(f"    → at limit")
        return "synthesize"
    else:
        print(f"    → under limit")
        return "execute_assignments"


# ═══════════════════════════════════════════════════════════
# Graph Construction
# ═══════════════════════════════════════════════════════════

def build_graph():
    graph = StateGraph(AgentState)

    graph.add_node("receive_objective", node_receive_objective)
    graph.add_node("plan_assignments", node_plan_assignments)
    graph.add_node("execute_assignments", node_execute_assignments)
    graph.add_node("run_agent", node_run_agent)
    graph.add_node("call_researcher", node_call_researcher)
    graph.add_node("call_writer", node_call_writer)
    graph.add_node("call_reviewer_agent", node_call_reviewer_agent)
    graph.add_node("collect_result", node_collect_result)
    graph.add_node("review_all", node_review_all)
    graph.add_node("handle_revision", node_handle_revision)
    graph.add_node("synthesize", node_synthesize)
    graph.add_node("emit_output", node_emit_output)

    graph.set_entry_point("receive_objective")

    graph.add_edge("receive_objective", "plan_assignments")
    graph.add_edge("plan_assignments", "execute_assignments")
    graph.add_edge("execute_assignments", "run_agent")
    graph.add_conditional_edges(
        "run_agent",
        route_dispatch_agent,
        {
            "call_researcher": "call_researcher",
            "check_writer": "check_writer",
        }
    )
    graph.add_edge("call_researcher", "collect_result")
    graph.add_edge("call_writer", "collect_result")
    graph.add_edge("call_reviewer_agent", "collect_result")
    graph.add_conditional_edges(
        "collect_result",
        route_check_more_assignments,
        {
            "review_all": "review_all",
            "run_agent": "run_agent",
        }
    )
    graph.add_conditional_edges(
        "review_all",
        route_quality_gate,
        {
            "handle_revision": "handle_revision",
            "synthesize": "synthesize",
        }
    )
    graph.add_conditional_edges(
        "handle_revision",
        route_revision_gate,
        {
            "execute_assignments": "execute_assignments",
            "synthesize": "synthesize",
        }
    )
    graph.add_edge("synthesize", "emit_output")
    graph.add_edge("emit_output", END)

    # Pass-through node for chained gate: check_writer
    graph.add_node("check_writer", lambda state: {})
    graph.add_conditional_edges(
        "check_writer",
        route_check_writer,
        {
            "call_writer": "call_writer",
            "call_reviewer_agent": "call_reviewer_agent",
        }
    )

    return graph.compile()


# ═══════════════════════════════════════════════════════════
# Entry Point
# ═══════════════════════════════════════════════════════════

class _StateCompat:
    """Wrapper to make LangGraph state compatible with test harness."""
    def __init__(self, state_dict):
        self.data = {k: v for k, v in state_dict.items() if not k.startswith("_")}
        self.data.update({k: v for k, v in state_dict.items() if k.startswith("_")})
        self.iteration = state_dict.get("_iteration", 0)
        self.schema_violations = state_dict.get("_schema_violations", 0)


MAX_ITERATIONS = int(os.environ.get("OPENCLAW_MAX_ITER", "100"))


def run(initial_data=None):
    """Crew — LangGraph execution"""
    app = build_graph()

    # Build initial state
    state = {}
    if initial_data:
        state.update(initial_data)
    state["_iteration"] = 0
    state["_schema_violations"] = 0
    state["_done"] = False

    print(f"\n════════════════════════════════════════════════════════════")
    print(f"  Crew (LangGraph)")
    print(f"  Multi-agent collaboration system where specialized agents work together under a coordinator")
    print(f"════════════════════════════════════════════════════════════\n")

    # LangGraph recursion limit maps roughly to our MAX_ITERATIONS
    try:
        final_state = app.invoke(state, {"recursion_limit": MAX_ITERATIONS * 3})
    except Exception as e:
        print(f"\n  [ERROR] {type(e).__name__}: {e}")
        final_state = state

    _clean_exit = True
    dump_trace(iterations=final_state.get("_iteration", 0), clean_exit=_clean_exit)
    print(f"\nFinal state keys: {list(final_state.keys())}")
    return _StateCompat(final_state)


if __name__ == "__main__":
    run()