#!/usr/bin/env python3
"""
OpenClaw Instantiation Engine
Reads an agent spec YAML and generates a runnable Python agent.

Usage: python3 instantiate.py specs/babyagi.yaml -o agents/babyagi_agent.py
       python3 instantiate.py specs/claude-code.yaml -o agents/claude_code_agent.py
"""

import sys
import os
import yaml
import argparse

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))


def load_yaml(path):
    with open(path) as f:
        return yaml.safe_load(f)


def generate_agent(spec):
    """Generate a complete Python agent script from a spec."""
    name = spec["name"]
    entities = spec.get("entities", [])
    processes = spec.get("processes", [])
    edges = spec.get("edges", [])
    schemas = spec.get("schemas", [])
    entry_point = spec.get("entry_point")

    # Index everything
    entity_map = {e["id"]: e for e in entities}
    process_map = {p["id"]: p for p in processes}
    schema_map = {s["name"]: s for s in schemas}

    # Build adjacency: for each process, what flows/branches out?
    flow_graph = {}
    for e in edges:
        if e["type"] in ("flow", "branch"):
            src = e["from"]
            flow_graph.setdefault(src, []).append((e["to"], e))

    # Build invoke map: for each process, what entities does it invoke?
    invoke_map = {}
    for e in edges:
        if e["type"] == "invoke":
            invoke_map.setdefault(e["from"], []).append((e["to"], e))

    # Build store access: for each process, what stores does it read/write?
    store_access = {}
    for e in edges:
        if e["type"] in ("read", "write"):
            store_access.setdefault(e["from"], []).append((e["to"], e["type"], e))

    # Build loop map
    loop_map = {}
    for e in edges:
        if e["type"] == "loop":
            loop_map[e["from"]] = (e["to"], e)

    # Categorize entities
    agents = [e for e in entities if e["type"] == "agent"]
    stores = [e for e in entities if e["type"] == "store"]

    # ── Generate code ──
    lines = []
    w = lines.append

    # Header
    w('#!/usr/bin/env python3')
    w(f'"""')
    w(f'{name} — Generated by OpenClaw Instantiation Engine')
    w(f'Spec: {spec.get("description", "")}')
    w(f'"""')
    w('')
    w('import json')
    w('import os')
    w('import sys')
    w('import time')
    w('from datetime import datetime')
    w('')

    # ── Trace log ──
    w('# ═══════════════════════════════════════════════════════════')
    w('# Trace Log')
    w('# ═══════════════════════════════════════════════════════════')
    w('')
    w('TRACE = []')
    w('')
    w('def trace_call(agent_label, model, system_prompt, user_message, response, duration_ms):')
    w('    entry = {')
    w('        "timestamp": datetime.now().isoformat(),')
    w('        "agent": agent_label,')
    w('        "model": model,')
    w('        "system_prompt": system_prompt,')
    w('        "user_message": user_message,')
    w('        "response": response,')
    w('        "duration_ms": duration_ms,')
    w('    }')
    w('    TRACE.append(entry)')
    w('    print(f"    [{agent_label}] ({model}, {duration_ms}ms)")')
    w('    print(f"      IN:  {user_message[:300]}")')
    w('    print(f"      OUT: {response[:300]}")')
    w('')
    w('')
    w('def dump_trace(path="trace.json"):')
    w('    with open(path, "w") as f:')
    w('        json.dump(TRACE, f, indent=2)')
    w('    print(f"\\nTrace written to {path} ({len(TRACE)} calls)")')
    w('')

    # ── LLM call infrastructure ──
    w('# ═══════════════════════════════════════════════════════════')
    w('# LLM Call Infrastructure')
    w('# ═══════════════════════════════════════════════════════════')
    w('')
    w('def call_llm(model, system_prompt, user_message, temperature=0.7, max_tokens=4096):')
    w('    if model.startswith("claude") or model.startswith("anthropic"):')
    w('        return _call_anthropic(model, system_prompt, user_message, temperature, max_tokens)')
    w('    else:')
    w('        return _call_openai(model, system_prompt, user_message, temperature, max_tokens)')
    w('')
    w('')
    w('def _call_openai(model, system_prompt, user_message, temperature, max_tokens):')
    w('    try:')
    w('        from openai import OpenAI')
    w('        client = OpenAI()')
    w('        response = client.chat.completions.create(')
    w('            model=model,')
    w('            messages=[')
    w('                {"role": "system", "content": system_prompt},')
    w('                {"role": "user", "content": user_message},')
    w('            ],')
    w('            temperature=temperature,')
    w('            max_tokens=max_tokens,')
    w('        )')
    w('        return response.choices[0].message.content')
    w('    except Exception as e:')
    w('        print(f"[STUB] Would call OpenAI {model} — {user_message[:80]}")')
    w('        return json.dumps({"stub": True, "model": model})')
    w('')
    w('')
    w('def _call_anthropic(model, system_prompt, user_message, temperature, max_tokens):')
    w('    try:')
    w('        import anthropic')
    w('        client = anthropic.Anthropic()')
    w('        response = client.messages.create(')
    w('            model=model,')
    w('            max_tokens=max_tokens,')
    w('            system=system_prompt,')
    w('            messages=[{"role": "user", "content": user_message}],')
    w('        )')
    w('        return response.content[0].text')
    w('    except Exception as e:')
    w('        print(f"[STUB] Would call Anthropic {model} — {user_message[:80]}")')
    w('        return json.dumps({"stub": True, "model": model})')
    w('')

    # ── Schema registry ──
    w('# ═══════════════════════════════════════════════════════════')
    w('# Schema Registry')
    w('# ═══════════════════════════════════════════════════════════')
    w('')
    w('SCHEMAS = {')
    for s in schemas:
        sname = s["name"]
        fields = s.get("fields", [])
        desc = s.get("description", "")
        field_strs = []
        for f in fields:
            field_strs.append(f'{{"name": "{f["name"]}", "type": "{f["type"]}"}}')
        w(f'    "{sname}": {{')
        w(f'        "description": """{desc}""",')
        w(f'        "fields": [{", ".join(field_strs)}],')
        w(f'    }},')
    w('}')
    w('')

    # ── Schema helpers ──
    w('')
    w('def build_input(state, schema_name):')
    w('    """Build an input dict for an agent call using schema field names.')
    w('    Pulls matching keys from state.data."""')
    w('    schema = SCHEMAS.get(schema_name)')
    w('    if not schema:')
    w('        return state.data')
    w('    result = {}')
    w('    for field in schema["fields"]:')
    w('        fname = field["name"]')
    w('        if fname in state.data:')
    w('            result[fname] = state.data[fname]')
    w('    return result')
    w('')
    w('')
    w('def output_instruction(schema_name):')
    w('    """Generate a JSON output instruction string for the LLM."""')
    w('    schema = SCHEMAS.get(schema_name)')
    w('    if not schema:')
    w('        return ""')
    w('    fields = ", ".join(f\'"{f["name"]}": <{f["type"]}>\' for f in schema["fields"])')
    w('    return f"\\n\\nRespond with ONLY valid JSON matching this schema: {{{fields}}}"')
    w('')
    w('')
    w('def parse_response(response, schema_name):')
    w('    """Parse an LLM response according to an output schema.')
    w('    Returns a dict of field values, or {"raw": response} if parsing fails."""')
    w('    # Try to extract JSON from the response')
    w('    text = response.strip()')
    w('    # Handle markdown code blocks')
    w('    if text.startswith("```"):')
    w('        lines = text.split("\\n")')
    w('        lines = lines[1:]  # skip ```json')
    w('        if lines and lines[-1].strip() == "```":')
    w('            lines = lines[:-1]')
    w('        text = "\\n".join(lines)')
    w('    try:')
    w('        parsed = json.loads(text)')
    w('        if isinstance(parsed, dict):')
    w('            return parsed')
    w('        return {"value": parsed}')
    w('    except json.JSONDecodeError:')
    w('        # Try to find JSON object in the response')
    w('        start = text.find("{")')
    w('        end = text.rfind("}") + 1')
    w('        if start >= 0 and end > start:')
    w('            try:')
    w('                return json.loads(text[start:end])')
    w('            except json.JSONDecodeError:')
    w('                pass')
    w('        return {"raw": response}')
    w('')

    # ── Store classes ──
    if stores:
        w('')
        w('# ═══════════════════════════════════════════════════════════')
        w('# Stores')
        w('# ═══════════════════════════════════════════════════════════')
        # Emit ChromaDB vector store helper if any store is vector type
        has_vector = any(s.get("store_type") == "vector" for s in stores)
        if has_vector:
            w('')
            w('# ── ChromaDB Vector Store (falls back to in-memory list) ──')
            w('try:')
            w('    import chromadb')
            w('    _chroma_client = chromadb.Client()')
            w('    _USE_CHROMA = True')
            w('except ImportError:')
            w('    _USE_CHROMA = False')
            w('')
            w('')
            w('class _ChromaVectorStore:')
            w('    """Vector store backed by ChromaDB with in-memory fallback."""')
            w('    def __init__(self, name):')
            w('        self._fallback = []')
            w('        self._collection = None')
            w('        if _USE_CHROMA:')
            w('            self._collection = _chroma_client.get_or_create_collection(name)')
            w('            print(f"    [ChromaDB] collection \'{name}\' ready")')
            w('        else:')
            w('            print(f"    [VectorStore] using in-memory fallback (pip install chromadb for semantic search)")')
            w('')
            w('    def read(self, query=None, top_k=5):')
            w('        """Read all entries, or query for similar ones."""')
            w('        if self._collection is not None:')
            w('            if query:')
            w('                results = self._collection.query(query_texts=[query], n_results=min(top_k, max(self._collection.count(), 1)))')
            w('                docs = results.get("documents", [[]])[0]')
            w('                metas = results.get("metadatas", [[]])[0]')
            w('                return [{"text": d, "metadata": m} for d, m in zip(docs, metas)]')
            w('            else:')
            w('                if self._collection.count() == 0:')
            w('                    return []')
            w('                all_data = self._collection.get()')
            w('                docs = all_data.get("documents", [])')
            w('                metas = all_data.get("metadatas", [])')
            w('                return [{"text": d, "metadata": m} for d, m in zip(docs, metas)]')
            w('        return self._fallback')
            w('')
            w('    def write(self, value, key=None):')
            w('        """Write an entry. value should have "text" and optionally "metadata"."""')
            w('        text = value.get("text", str(value)) if isinstance(value, dict) else str(value)')
            w('        metadata = value.get("metadata", {}) if isinstance(value, dict) else {}')
            w('        # ChromaDB metadata values must be str, int, float, or bool')
            w('        clean_meta = {}')
            w('        for k, v in (metadata or {}).items():')
            w('            if isinstance(v, (str, int, float, bool)):')
            w('                clean_meta[k] = v')
            w('            elif v is not None:')
            w('                clean_meta[k] = str(v)')
            w('        if self._collection is not None:')
            w('            doc_id = key or f"doc_{self._collection.count()}"')
            w('            self._collection.add(documents=[text], metadatas=[clean_meta], ids=[doc_id])')
            w('        else:')
            w('            self._fallback.append(value if isinstance(value, dict) else {"text": text, "metadata": clean_meta})')
            w('')
            w('')

        w('')
        for s in stores:
            sid = s["id"]
            stype = s.get("store_type", "kv")
            label = s.get("label", sid)
            w(f'class Store_{_safe_name(sid)}:')
            w(f'    """{label} ({stype})"""')
            w(f'    def __init__(self):')
            if stype == "vector":
                w(f'        self._store = _ChromaVectorStore("{_safe_name(sid)}")')
            elif stype == "file":
                path = s.get("config", {}).get("path", f"/tmp/{sid}.jsonl")
                w(f'        self.path = os.path.expanduser("{path}")')
                w(f'        self.data = []')
            elif stype == "queue":
                w(f'        self.queue = []')
            else:
                w(f'        self.data = {{}}')
            w('')
            w(f'    def read(self, key=None):')
            if stype == "vector":
                w(f'        return self._store.read(query=key)')
            elif stype == "queue":
                w(f'        return self.queue[0] if self.queue else None')
            else:
                w(f'        return self.data if key is None else self.data.get(key)')
            w('')
            w(f'    def write(self, value, key=None):')
            if stype == "vector":
                w(f'        self._store.write(value, key=key)')
            elif stype == "queue":
                w(f'        self.queue.append(value)')
            elif stype == "file":
                w(f'        self.data.append(value)')
            else:
                w(f'        if key is not None:')
                w(f'            self.data[key] = value')
                w(f'        else:')
                w(f'            self.data = value')
            w('')
            w('')

    # ── Agent call wrappers (now schema-aware) ──
    if agents:
        w('')
        w('# ═══════════════════════════════════════════════════════════')
        w('# Agent Wrappers')
        w('# ═══════════════════════════════════════════════════════════')
        w('')
        for a in agents:
            aid = a["id"]
            model = a.get("model", "gpt-4")
            prompt = a.get("system_prompt", "You are a helpful assistant.")
            label = a.get("label", aid)
            config = a.get("config", {})
            temp = config.get("temperature", 0.7)
            max_tok = config.get("max_tokens", 4096)
            w(f'def invoke_{_safe_name(aid)}(user_message, output_schema=None):')
            w(f'    """{label}"""')
            w(f'    system = """{_escape_triple(prompt)}"""')
            w(f'    if output_schema:')
            w(f'        system += output_instruction(output_schema)')
            w(f'    t0 = time.time()')
            w(f'    result = call_llm(')
            w(f'        model="{model}",')
            w(f'        system_prompt=system,')
            w(f'        user_message=user_message,')
            w(f'        temperature={temp},')
            w(f'        max_tokens={max_tok},')
            w(f'    )')
            w(f'    trace_call("{label}", "{model}", system, user_message, result, int((time.time()-t0)*1000))')
            w(f'    return result')
            w('')
            w('')

    # ── Tool implementations ──
    tools = [e for e in entities if e["type"] == "tool"]
    if tools:
        w('')
        w('# ═══════════════════════════════════════════════════════════')
        w('# Tool Implementations')
        w('# ═══════════════════════════════════════════════════════════')
        w('')
        for t in tools:
            _generate_tool_function(t, w)

    # ── State object ──
    w('')
    w('# ═══════════════════════════════════════════════════════════')
    w('# Agent State')
    w('# ═══════════════════════════════════════════════════════════')
    w('')
    w('class AgentState:')
    w(f'    """Runtime state for {name}"""')
    w('    def __init__(self):')
    for s in stores:
        w(f'        self.{_safe_name(s["id"])} = Store_{_safe_name(s["id"])}()')
    w('        self.data = {}  # current data flowing through the pipeline')
    w('        self.iteration = 0')
    w('')
    w('')

    # ── Process functions ──
    w('# ═══════════════════════════════════════════════════════════')
    w('# Process Functions')
    w('# ═══════════════════════════════════════════════════════════')
    w('')

    for p in processes:
        pid = p["id"]
        ptype = p["type"]
        label = p.get("label", pid)
        desc = p.get("description", "")
        invocations = invoke_map.get(pid, [])
        store_ops = store_access.get(pid, [])

        w(f'def process_{_safe_name(pid)}(state):')
        w(f'    """')
        w(f'    {label}')
        if desc:
            w(f'    {desc}')
        w(f'    """')
        w(f'    print(f"  → {label}")')
        w('')

        if ptype == "step":
            # Inline logic (if specified in spec)
            logic = p.get("logic")
            if logic:
                w(f'    # Logic from spec')
                for line in logic.strip().split('\n'):
                    w(f'    {line}')
                w(f'    if state.data.get("_done"):')
                w(f'        return state')
                w('')

            # Store reads
            for (store_id, op, edge) in store_ops:
                if op == "read":
                    elabel = edge.get("label", "")
                    w(f'    # Read: {elabel}')
                    w(f'    {_safe_name(store_id)}_data = state.{_safe_name(store_id)}.read()')
                    w(f'    state.data["{store_id}"] = {_safe_name(store_id)}_data')
                    w('')

            # Invoke agents (schema-aware)
            for (entity_id, edge) in invocations:
                entity = entity_map.get(entity_id, {})
                etype = entity.get("type")
                if etype != "agent":
                    continue
                elabel = edge.get("label", entity_id)
                input_schema = edge.get("input")
                output_schema = edge.get("output")

                w(f'    # Invoke: {elabel}')
                if input_schema and input_schema in schema_map:
                    w(f'    {_safe_name(entity_id)}_input = build_input(state, "{input_schema}")')
                else:
                    w(f'    {_safe_name(entity_id)}_input = state.data.copy()')
                w(f'    {_safe_name(entity_id)}_msg = json.dumps({_safe_name(entity_id)}_input, default=str)')

                if output_schema and output_schema in schema_map:
                    w(f'    {_safe_name(entity_id)}_raw = invoke_{_safe_name(entity_id)}({_safe_name(entity_id)}_msg, output_schema="{output_schema}")')
                    w(f'    {_safe_name(entity_id)}_result = parse_response({_safe_name(entity_id)}_raw, "{output_schema}")')
                    w(f'    # Merge output fields into state.data')
                    w(f'    state.data.update({_safe_name(entity_id)}_result)')
                    w(f'    print(f"    ← {entity.get("label", entity_id)}: {{{_safe_name(entity_id)}_result}}")')
                else:
                    w(f'    {_safe_name(entity_id)}_result = invoke_{_safe_name(entity_id)}({_safe_name(entity_id)}_msg)')
                    w(f'    state.data["{entity_id}_result"] = {_safe_name(entity_id)}_result')
                    w(f'    print(f"    ← {entity.get("label", entity_id)}: {{{_safe_name(entity_id)}_result[:100]}}...")')
                w('')

            # Invoke tools (with dispatch)
            tool_invokes = [(eid, edge) for eid, edge in invocations
                           if entity_map.get(eid, {}).get("type") == "tool"]
            if tool_invokes:
                _emit_tool_dispatch(tool_invokes, entity_map, w)

            # Store writes — use write edge's data schema if available
            for (store_id, op, edge) in store_ops:
                if op == "write":
                    elabel = edge.get("label", "")
                    data_schema = edge.get("data")
                    w(f'    # Write: {elabel}')
                    if data_schema and data_schema in schema_map:
                        w(f'    {_safe_name(store_id)}_write = build_input(state, "{data_schema}")')
                        w(f'    state.{_safe_name(store_id)}.write({_safe_name(store_id)}_write)')
                    else:
                        w(f'    state.{_safe_name(store_id)}.write(state.data.copy())')
                    w('')

            w(f'    return state')

        elif ptype == "gate":
            condition = p.get("condition", "True")
            branches = p.get("branches", [])
            w(f'    # Gate: {condition}')
            for i, branch in enumerate(branches):
                w(f'    # Branch: {branch.get("condition", "")} → {branch.get("target", "")}')
            w('')

            # Generate inline condition evaluation
            check_expr = _generate_gate_check(condition)
            if len(branches) == 2:
                # Determine which branch is the TRUE case
                true_idx = _true_branch_index(condition, branches)
                false_idx = 1 - true_idx
                w(f'    if {check_expr}:')
                w(f'        print(f"    → {branches[true_idx].get("condition", "yes")}")')
                w(f'        return "{branches[true_idx]["target"]}"')
                w(f'    else:')
                w(f'        print(f"    → {branches[false_idx].get("condition", "no")}")')
                w(f'        return "{branches[false_idx]["target"]}"')
            else:
                for i, branch in enumerate(branches):
                    prefix = "if" if i == 0 else "elif"
                    w(f'    {prefix} {check_expr}:')
                    w(f'        return "{branch["target"]}"')
                w(f'    else:')
                w(f'        return "{branches[-1]["target"]}"')

        elif ptype == "checkpoint":
            prompt_text = p.get("prompt", "Continue?")
            options = p.get("options", ["approve", "deny"])
            w(f'    response = input("{prompt_text} [{"/".join(options)}]: ").strip().lower()')
            w(f'    state.data["checkpoint_response"] = response')
            w(f'    return state')

        elif ptype == "spawn":
            template = p.get("template", "self")
            cardinality = p.get("cardinality", 1)
            recursive = p.get("recursive", False)
            w(f'    # Spawn: template={template}, cardinality={cardinality}, recursive={recursive}')
            w(f'    print("    [SPAWN] Would create sub-agent from template: {template}")')
            w(f'    return state')

        elif ptype == "policy":
            w(f'    # Policy: cross-cutting concern')
            w(f'    pass')
            w(f'    return state')

        w('')
        w('')

    # (Gate conditions are evaluated inline — no generic evaluator needed)

    # ── Main loop ──
    w('# ═══════════════════════════════════════════════════════════')
    w('# State Machine Executor')
    w('# ═══════════════════════════════════════════════════════════')
    w('')
    w('PROCESSES = {')
    for p in processes:
        w(f'    "{p["id"]}": process_{_safe_name(p["id"])},')
    w('}')
    w('')

    # Build entity-bridged flow map: if process A invokes entity E, and E flows to process B,
    # then A should transition to B
    entity_flow = {}  # entity_id -> [process_id targets]
    for e in edges:
        if e["type"] == "flow" and e["from"] in entity_map and e["to"] in process_map:
            entity_flow.setdefault(e["from"], []).append(e["to"])

    w('TRANSITIONS = {')
    for p in processes:
        pid = p["id"]
        if p["type"] == "gate":
            w(f'    # "{pid}": determined by gate logic')
            continue
        outflows = flow_graph.get(pid, [])
        proc_targets = [(t, e) for t, e in outflows if t in process_map]

        # If no direct process targets, check entity-bridged flows
        if not proc_targets:
            invoked = invoke_map.get(pid, [])
            for inv_target, inv_edge in invoked:
                bridged = entity_flow.get(inv_target, [])
                for bt in bridged:
                    proc_targets.append((bt, inv_edge))

        if pid in loop_map:
            target, edge = loop_map[pid]
            w(f'    "{pid}": "{target}",  # loop: {edge.get("label", "")}')
        elif len(proc_targets) == 1:
            w(f'    "{pid}": "{proc_targets[0][0]}",')
        elif len(proc_targets) > 1:
            w(f'    "{pid}": "{proc_targets[0][0]}",  # multiple outflows, taking first')
        else:
            w(f'    "{pid}": None,  # terminal')
    w('}')
    w('')

    gate_ids = [p["id"] for p in processes if p["type"] == "gate"]

    w('')
    w(f'MAX_ITERATIONS = 100')
    w('')
    w('')
    w(f'def run(initial_data=None):')
    w(f'    """{name} — main execution loop"""')
    w(f'    state = AgentState()')
    w(f'    if initial_data:')
    w(f'        state.data.update(initial_data)')
    w(f'')
    w(f'    current = "{entry_point}"')
    w(f'    print(f"\\n{"═" * 60}")')
    w(f'    print(f"  {name}")')
    w(f'    print(f"  {spec.get("description", "")}")')
    w(f'    print(f"{"═" * 60}\\n")')
    w(f'')
    w(f'    while current and state.iteration < MAX_ITERATIONS:')
    w(f'        state.iteration += 1')
    w(f'        print(f"\\n[Iteration {{state.iteration}}] State: {{current}}")')
    w(f'')
    w(f'        process_fn = PROCESSES.get(current)')
    w(f'        if not process_fn:')
    w(f'            print(f"  Unknown process: {{current}}")')
    w(f'            break')
    w(f'')
    w(f'        result = process_fn(state)')
    w(f'')
    if gate_ids:
        w(f'        if current in {gate_ids}:')
        w(f'            current = result')
        w(f'        else:')
        w(f'            current = TRANSITIONS.get(current)')
    else:
        w(f'        current = TRANSITIONS.get(current)')
    w(f'')
    w(f'        if current is None or state.data.get("_done"):')
    w(f'            print("\\n  [DONE] Reached terminal state.")')
    w(f'            break')
    w(f'')
    w(f'    if state.iteration >= MAX_ITERATIONS:')
    w(f'        print(f"\\n  [STOPPED] Max iterations ({{MAX_ITERATIONS}}) reached.")')
    w(f'')
    w(f'    dump_trace()')
    w(f'    print(f"\\nFinal state.data keys: {{list(state.data.keys())}}")')
    w(f'    return state')
    w('')
    w('')
    w('if __name__ == "__main__":')

    # Detect user input: look for flow edges from human entities to the entry point,
    # then find the data schema to determine what fields to prompt for
    human_entities = [e for e in entities if e.get("type") == "human"]
    user_input_schema = None
    for edge in edges:
        if edge["type"] == "flow" and edge["from"] in [h["id"] for h in human_entities]:
            if edge.get("data"):
                user_input_schema = edge["data"]
                break

    if user_input_schema and user_input_schema in schema_map:
        schema = schema_map[user_input_schema]
        fields = schema.get("fields", [])
        if fields:
            w('    initial = {}')
            for field in fields:
                fname = field["name"]
                w(f'    initial["{fname}"] = input("Enter {fname}: ")')
            w('    run(initial)')
        else:
            w('    run()')
    else:
        w('    run()')

    return "\n".join(lines)


def _true_branch_index(condition, branches):
    """Determine which branch (0 or 1) corresponds to the gate condition being TRUE.
    Analyzes branch condition text for positive/negative indicators."""
    import re
    b0 = branches[0].get("condition", "").lower()
    b1 = branches[1].get("condition", "").lower()
    cond_lower = condition.lower()

    # Direct match: if a branch condition matches the gate condition exactly, it's the TRUE case
    if b1.strip() == cond_lower.strip():
        return 1
    if b0.strip() == cond_lower.strip():
        return 0

    # Mathematical inverse detection: > vs <=, >= vs <, etc.
    op_inverses = {'>': '<=', '>=': '<', '<': '>=', '<=': '>', '==': '!=', '!=': '=='}
    cond_op_match = re.search(r'([><=!]+)', condition)
    if cond_op_match:
        cond_op = cond_op_match.group(1)
        inv_op = op_inverses.get(cond_op)
        if inv_op:
            # If branch[0] uses the inverse operator, it's the FALSE case
            if inv_op in b0 and cond_op not in b0:
                return 1
            if inv_op in b1 and cond_op not in b1:
                return 0

    # Negative indicators: branch describes the condition NOT being met
    negatives = ["no ", "not ", "none", "without", "empty", "zero", "denied",
                 "under ", "below", "rejected", "failed", "missing"]
    # "ok" is negative when the gate checks for a problem (capacity, limit, error)
    problem_words = ["approaching", "capacity", "limit", "exceed", "error", "fail"]

    b0_is_negative = any(neg in b0 for neg in negatives)
    b1_is_negative = any(neg in b1 for neg in negatives)

    # "ok" in a problem-checking gate means "problem not present" = FALSE case
    if "ok" in b0 and any(pw in cond_lower for pw in problem_words):
        b0_is_negative = True
    if "ok" in b1 and any(pw in cond_lower for pw in problem_words):
        b1_is_negative = True

    if b0_is_negative and not b1_is_negative:
        return 1  # branch[1] is the TRUE case
    elif b1_is_negative and not b0_is_negative:
        return 0  # branch[0] is the TRUE case
    else:
        return 0  # default: branch[0] is TRUE case


def _generate_gate_check(condition):
    """Generate a Python expression string for a gate condition.
    Parses common patterns from human-readable condition strings."""
    import re
    c = condition.lower()

    # Extract the primary field path (first dotted identifier)
    field_match = re.match(r'([\w]+(?:\.[\w]+)*)', condition)
    field_path = field_match.group(1) if field_match else None

    # Build accessor for dotted paths
    def accessor(path):
        parts = path.split('.')
        if len(parts) == 1:
            return f'state.data.get("{parts[0]}")'
        # Navigate nested dicts: field.sub → state.data.get("field", {}).get("sub")
        expr = 'state.data'
        for p in parts[:-1]:
            expr = f'{expr}.get("{p}", {{}})'
        expr = f'{expr}.get("{parts[-1]}")'
        return expr

    def num_accessor(path):
        """Accessor that defaults to 0 for numeric comparisons."""
        parts = path.split('.')
        if len(parts) == 1:
            return f'state.data.get("{parts[0]}", 0)'
        expr = 'state.data'
        for p in parts[:-1]:
            expr = f'{expr}.get("{p}", {{}})'
        expr = f'{expr}.get("{parts[-1]}", 0)'
        return expr

    # Pattern: "field.length > 0" or "field.count > 0"
    if '.length' in c and '> 0' in c:
        base = field_path.rsplit('.', 1)[0] if '.' in field_path else field_path
        return f'len({accessor(base)} or [])'

    # Pattern: "field approaching capacity" or "field > threshold"
    if 'approaching' in c or 'capacity' in c:
        return f'(state.data.get("_context_token_count", 0) > state.data.get("_context_capacity", 100000) * 0.8)'

    # Pattern: "field matches X" (e.g. permission checks)
    if 'matches' in c or 'match' in c:
        return f'state.data.get("_permission_granted", True)'

    # Pattern: "field is not empty"
    if 'is not empty' in c or 'not empty' in c:
        if field_path:
            return f'bool({accessor(field_path)})'

    # Pattern: "field is empty"
    if 'is empty' in c and 'not' not in c:
        if field_path:
            return f'not bool({accessor(field_path)})'

    # Pattern: "field >= field2" or "field >= N" (comparison with >=)
    gte_match = re.search(r'([\w.]+)\s*>=\s*([\w.]+)', condition)
    if gte_match:
        lhs, rhs = gte_match.group(1), gte_match.group(2)
        if rhs.isdigit():
            return f'({num_accessor(lhs)}) >= {rhs}'
        elif '.' in rhs and rhs.split('.')[-1] == 'length':
            # field >= other.length
            base = rhs.rsplit('.', 1)[0]
            return f'({num_accessor(lhs)}) >= len({accessor(base)} or [])'
        else:
            return f'({num_accessor(lhs)}) >= ({num_accessor(rhs)})'

    # Pattern: "field > field2" or "field > N"
    gt_match = re.search(r'([\w.]+)\s*>\s*([\w.]+)', condition)
    if gt_match:
        lhs, rhs = gt_match.group(1), gt_match.group(2)
        if rhs.isdigit():
            return f'({num_accessor(lhs)}) > {rhs}'
        elif '.' in rhs and rhs.split('.')[-1] == 'length':
            base = rhs.rsplit('.', 1)[0]
            return f'({num_accessor(lhs)}) > len({accessor(base)} or [])'
        else:
            return f'({num_accessor(lhs)}) > ({num_accessor(rhs)})'

    # Pattern: "field < field2" or "field < N"
    lt_match = re.search(r'([\w.]+)\s*<\s*([\w.]+)', condition)
    if lt_match:
        lhs, rhs = lt_match.group(1), lt_match.group(2)
        if rhs.isdigit():
            return f'({num_accessor(lhs)}) < {rhs}'
        elif '.' in rhs and rhs.split('.')[-1] == 'length':
            base = rhs.rsplit('.', 1)[0]
            return f'({num_accessor(lhs)}) < len({accessor(base)} or [])'
        else:
            return f'({num_accessor(lhs)}) < ({num_accessor(rhs)})'

    # Pattern: "field == value"
    eq_match = re.search(r'([\w.]+)\s*==?\s*["\']?(\w+)["\']?', condition)
    if eq_match:
        lhs, rhs = eq_match.group(1), eq_match.group(2)
        if rhs.isdigit():
            return f'{num_accessor(lhs)} == {rhs}'
        if rhs in ('True', 'true'):
            return f'{accessor(lhs)} == True'
        if rhs in ('False', 'false'):
            return f'{accessor(lhs)} == False'
        if rhs in ('None', 'none', 'null'):
            return f'{accessor(lhs)} is None'
        return f'{accessor(lhs)} == "{rhs}"'

    # Fallback: check truthiness of first field
    if field_path:
        return f'bool({accessor(field_path)})'

    return 'True  # could not parse condition'


def _generate_tool_function(tool, w):
    """Generate a tool implementation function in the output code."""
    tid = tool["id"]
    safe = _safe_name(tid)
    label = tool.get("label", tid)
    desc = tool.get("description", "")
    keywords = (label + " " + desc).lower()

    w(f'def tool_{safe}(input_text):')
    w(f'    """{label}: {desc}"""')

    if "search" in keywords and "look" not in keywords:
        # Wikipedia search API
        w('    import requests')
        w('    import re as _re')
        w('    _headers = {"User-Agent": "OpenClaw/1.0 (agent research project)"} ')
        w('    try:')
        w('        resp = requests.get("https://en.wikipedia.org/w/api.php", params={')
        w('            "action": "query", "list": "search", "srsearch": input_text,')
        w('            "format": "json", "srlimit": 5')
        w('        }, headers=_headers, timeout=10)')
        w('        data = resp.json()')
        w('        results = data.get("query", {}).get("search", [])')
        w('        if not results:')
        w('            return f"No results found for: {input_text}"')
        w('        lines = []')
        w('        for r in results:')
        w('            snippet = _re.sub(r"<[^>]+>", "", r.get("snippet", ""))')
        w("            lines.append(f\"{r['title']}: {snippet}\")")
        w('        return "\\n".join(lines)')
        w('    except Exception as e:')
        w('        return f"Search error: {e}"')

    elif "lookup" in keywords or "look up" in keywords:
        # Wikipedia article lookup
        w('    import requests')
        w('    _headers = {"User-Agent": "OpenClaw/1.0 (agent research project)"}')
        w('    try:')
        w('        resp = requests.get("https://en.wikipedia.org/w/api.php", params={')
        w('            "action": "query", "titles": input_text, "prop": "extracts",')
        w('            "exintro": True, "explaintext": True, "format": "json"')
        w('        }, headers=_headers, timeout=10)')
        w('        data = resp.json()')
        w('        pages = data.get("query", {}).get("pages", {})')
        w('        for pid, page in pages.items():')
        w('            if pid == "-1":')
        w('                return f"No Wikipedia article found for: {input_text}"')
        w('            extract = page.get("extract", "")')
        w('            if extract:')
        w('                return extract[:1500]')
        w('            return f"Article found but no extract available for: {input_text}"')
        w('        return f"No results for: {input_text}"')
        w('    except Exception as e:')
        w('        return f"Lookup error: {e}"')

    elif "calcul" in keywords or "math" in keywords or "evaluat" in keywords:
        # Safe calculator
        w('    import math')
        w('    _safe_ns = {')
        w('        "abs": abs, "round": round, "min": min, "max": max,')
        w('        "sum": sum, "pow": pow, "int": int, "float": float,')
        w('        "math": math, "pi": math.pi, "e": math.e,')
        w('        "sqrt": math.sqrt, "log": math.log, "sin": math.sin,')
        w('        "cos": math.cos, "tan": math.tan,')
        w('    }')
        w('    try:')
        w('        result = eval(input_text, {"__builtins__": {}}, _safe_ns)')
        w('        return str(result)')
        w('    except Exception as e:')
        w('        return f"Calculation error: {e}"')

    else:
        # Generic stub for unknown tools
        w(f'    return f"[tool {label} not implemented for input: {{input_text}}]"')

    w('')
    w('')


def _emit_tool_dispatch(tool_invokes, entity_map, w):
    """Emit tool dispatch code for a process that invokes one or more tools."""
    if len(tool_invokes) == 1:
        entity_id, edge = tool_invokes[0]
        entity = entity_map[entity_id]
        label = entity.get("label", entity_id)
        w(f'    # Invoke tool: {label}')
        w('    _tool_input = str(state.data.get("tool_input", state.data.get("input", "")))')
        w(f'    _tool_result = tool_{_safe_name(entity_id)}(_tool_input)')
        w('    state.data["observation"] = _tool_result')
        w('    print(f"    Observation: {_tool_result[:200]}")')
        w('')
    else:
        available = ", ".join(entity_map[eid].get("label", eid).lower()
                             for eid, _ in tool_invokes)
        w('    # Tool dispatch')
        w('    _tool_name = state.data.get("tool_name", "").lower().strip()')
        w('    _tool_input = str(state.data.get("tool_input", state.data.get("action", "")))')
        for i, (entity_id, edge) in enumerate(tool_invokes):
            entity = entity_map[entity_id]
            label = entity.get("label", entity_id).lower()
            prefix = "if" if i == 0 else "elif"
            w(f'    {prefix} _tool_name == "{label}":')
            w(f'        _tool_result = tool_{_safe_name(entity_id)}(_tool_input)')
        w(f'    else:')
        w(f'        _tool_result = f"Unknown tool: {{_tool_name}}. Available: {available}"')
        w('    state.data["observation"] = _tool_result')
        w('    print(f"    Observation: {_tool_result[:200]}")')
        w('')


def _safe_name(s):
    return s.replace("-", "_").replace(" ", "_").replace(".", "_")


def _escape_triple(s):
    return s.replace('"""', '\\"\\"\\"')


def spec_stats(spec):
    """Return a summary string of spec contents."""
    entities = spec.get("entities", [])
    processes = spec.get("processes", [])
    edges = spec.get("edges", [])
    schemas = spec.get("schemas", [])
    gates = [p for p in processes if p.get("type") == "gate"]
    loops = [e for e in edges if e.get("type") == "loop"]
    agents = [e for e in entities if e.get("type") == "agent"]
    stores = [e for e in entities if e.get("type") == "store"]
    return (f"{len(entities)} entities ({len(agents)} agents, {len(stores)} stores) | "
            f"{len(processes)} processes ({len(gates)} gates) | "
            f"{len(edges)} edges ({len(loops)} loops) | "
            f"{len(schemas)} schemas")


def run_validation(spec_path):
    """Run validate.py on the spec, return (success, output)."""
    import subprocess
    validate_script = os.path.join(SCRIPT_DIR, "validate.py")
    if not os.path.exists(validate_script):
        return True, "validate.py not found, skipping"
    result = subprocess.run(
        [sys.executable, validate_script, spec_path],
        capture_output=True, text=True
    )
    output = result.stdout + result.stderr
    has_errors = "ERROR" in output or result.returncode != 0
    return not has_errors, output.strip()


def instantiate_one(spec_path, output_path, dry_run=False, validate=False):
    """Instantiate a single spec. Returns True on success."""
    spec = load_yaml(spec_path)
    name = spec.get("name", os.path.basename(spec_path))

    if validate:
        ok, msg = run_validation(spec_path)
        if not ok:
            print(f"FAIL {name}: validation errors")
            for line in msg.split("\n"):
                if "ERROR" in line:
                    print(f"  {line.strip()}")
            return False
        # Show warnings but continue
        for line in msg.split("\n"):
            if "WARNING" in line:
                print(f"  {line.strip()}")

    code = generate_agent(spec)

    if dry_run or not output_path:
        print(code)
    else:
        os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
        with open(output_path, "w") as f:
            f.write(code)
        os.chmod(output_path, 0o755)
        print(f"  {name}: {output_path} ({spec_stats(spec)})")
    return True


def main():
    parser = argparse.ArgumentParser(
        description="OpenClaw Instantiation Engine — generate runnable agents from specs",
        epilog="Examples:\n"
               "  python3 instantiate.py specs/babyagi.yaml -o agents/babyagi_agent.py\n"
               "  python3 instantiate.py --all specs/ -o agents/ --validate\n"
               "  python3 instantiate.py specs/react.yaml --stats",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument("spec", help="Path to spec YAML file, or directory with --all")
    parser.add_argument("-o", "--output", help="Output Python file or directory (with --all)")
    parser.add_argument("--dry-run", action="store_true", help="Print generated code, don't write")
    parser.add_argument("--validate", action="store_true", help="Validate spec before generating")
    parser.add_argument("--all", action="store_true", help="Process all *.yaml files in directory")
    parser.add_argument("--stats", action="store_true", help="Show spec stats without generating")
    args = parser.parse_args()

    if args.stats:
        # Just print stats
        if args.all and os.path.isdir(args.spec):
            for fname in sorted(os.listdir(args.spec)):
                if fname.endswith(".yaml"):
                    path = os.path.join(args.spec, fname)
                    spec = load_yaml(path)
                    print(f"  {spec.get('name', fname):20s}  {spec_stats(spec)}")
        else:
            spec = load_yaml(args.spec)
            print(f"{spec.get('name', args.spec)}: {spec_stats(spec)}")
        return

    if args.all:
        # Batch mode: process all YAML files in directory
        spec_dir = args.spec
        if not os.path.isdir(spec_dir):
            print(f"Error: {spec_dir} is not a directory (use --all with a directory)")
            sys.exit(1)

        out_dir = args.output or "agents"
        os.makedirs(out_dir, exist_ok=True)
        files = sorted(f for f in os.listdir(spec_dir) if f.endswith(".yaml"))
        success, fail = 0, 0

        print(f"Instantiating {len(files)} specs from {spec_dir}/ -> {out_dir}/")
        for fname in files:
            spec_path = os.path.join(spec_dir, fname)
            out_name = fname.replace(".yaml", "_agent.py").replace("-", "_")
            out_path = os.path.join(out_dir, out_name)
            ok = instantiate_one(spec_path, out_path, args.dry_run, args.validate)
            if ok:
                success += 1
            else:
                fail += 1

        print(f"\nDone: {success} generated, {fail} failed")
    else:
        # Single spec mode
        spec = load_yaml(args.spec)
        code = generate_agent(spec)

        if args.validate:
            ok, msg = run_validation(args.spec)
            if not ok:
                print(f"Validation failed:")
                print(msg)
                sys.exit(1)
            for line in msg.split("\n"):
                if "WARNING" in line:
                    print(f"  {line.strip()}")

        if args.dry_run or not args.output:
            print(code)
        else:
            os.makedirs(os.path.dirname(args.output) or ".", exist_ok=True)
            with open(args.output, "w") as f:
                f.write(code)
            os.chmod(args.output, 0o755)
            name = spec.get("name", args.spec)
            print(f"Generated: {args.output}")
            print(f"  {spec_stats(spec)}")
            print(f"Run with:  python3 {args.output}")


if __name__ == "__main__":
    main()
