#!/usr/bin/env python3
"""
ReAct — Generated by OpenClaw Instantiation Engine
Spec: Reason + Act agent that interleaves thinking with tool use to solve problems
"""

import json
import os
import sys
import time
from datetime import datetime

# ═══════════════════════════════════════════════════════════
# Trace Log
# ═══════════════════════════════════════════════════════════

TRACE = []

def trace_call(agent_label, model, system_prompt, user_message, response, duration_ms):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "agent": agent_label,
        "model": model,
        "system_prompt": system_prompt,
        "user_message": user_message,
        "response": response,
        "duration_ms": duration_ms,
    }
    TRACE.append(entry)
    print(f"    [{agent_label}] ({model}, {duration_ms}ms)")
    print(f"      IN:  {user_message[:300]}")
    print(f"      OUT: {response[:300]}")


def dump_trace(path="trace.json", iterations=0, clean_exit=True):
    # Compute metrics
    total_ms = sum(e["duration_ms"] for e in TRACE)
    agents_used = list(set(e["agent"] for e in TRACE))
    schema_ok = 0
    for e in TRACE:
        try:
            r = e["response"].strip()
            if r.startswith("```"): r = "\n".join(r.split("\n")[1:-1])
            json.loads(r if r.startswith("{") else r[r.find("{"):r.rfind("}")+1])
            schema_ok += 1
        except (json.JSONDecodeError, ValueError):
            pass
    est_input_tokens = sum(len(e.get("user_message",""))//4 for e in TRACE)
    est_output_tokens = sum(len(e.get("response",""))//4 for e in TRACE)
    metrics = {
        "total_llm_calls": len(TRACE),
        "total_duration_ms": total_ms,
        "avg_call_ms": total_ms // max(len(TRACE), 1),
        "iterations": iterations,
        "clean_exit": clean_exit,
        "agents_used": agents_used,
        "schema_compliance": f"{schema_ok}/{len(TRACE)}",
        "est_input_tokens": est_input_tokens,
        "est_output_tokens": est_output_tokens,
    }
    output = {"metrics": metrics, "trace": TRACE}
    with open(path, "w") as f:
        json.dump(output, f, indent=2)
    print(f"\nTrace written to {path} ({len(TRACE)} calls, {total_ms}ms total)")
    print(f"  Schema compliance: {schema_ok}/{len(TRACE)}, est tokens: ~{est_input_tokens}in/~{est_output_tokens}out")
    return metrics

# ═══════════════════════════════════════════════════════════
# LLM Call Infrastructure
# ═══════════════════════════════════════════════════════════

def call_llm(model, system_prompt, user_message, temperature=0.7, max_tokens=4096):
    if model.startswith("claude") or model.startswith("anthropic"):
        return _call_anthropic(model, system_prompt, user_message, temperature, max_tokens)
    elif model.startswith("gemini"):
        return _call_gemini(model, system_prompt, user_message, temperature, max_tokens)
    else:
        return _call_openai(model, system_prompt, user_message, temperature, max_tokens)


def _call_openai(model, system_prompt, user_message, temperature, max_tokens):
    try:
        from openai import OpenAI
        client = OpenAI()
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message},
            ],
            temperature=temperature,
            max_tokens=max_tokens,
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"[STUB] Would call OpenAI {model} — {user_message[:80]}")
        return json.dumps({"stub": True, "model": model})


def _call_anthropic(model, system_prompt, user_message, temperature, max_tokens):
    try:
        import anthropic
        client = anthropic.Anthropic()
        response = client.messages.create(
            model=model,
            max_tokens=max_tokens,
            system=system_prompt,
            messages=[{"role": "user", "content": user_message}],
        )
        return response.content[0].text
    except Exception as e:
        print(f"[STUB] Would call Anthropic {model} — {user_message[:80]}")
        return json.dumps({"stub": True, "model": model})


def _call_gemini(model, system_prompt, user_message, temperature, max_tokens):
    try:
        from google import genai
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY", ""))
        response = client.models.generate_content(
            model=model,
            contents=f"{system_prompt}\n\n{user_message}",
            config={"temperature": temperature, "max_output_tokens": max_tokens},
        )
        return response.text
    except Exception as e:
        print(f"[STUB] Would call Gemini {model} — {user_message[:80]}")
        return json.dumps({"stub": True, "model": model})

# ═══════════════════════════════════════════════════════════
# Schema Registry
# ═══════════════════════════════════════════════════════════

SCHEMAS = {
    "ReActInput": {
        "description": """Input to the reasoning agent""",
        "fields": [{"name": "query", "type": "string"}, {"name": "trajectory", "type": "list<TrajectoryEntry>"}, {"name": "step_count", "type": "integer"}],
    },
    "ReActStep": {
        "description": """One reasoning or action step""",
        "fields": [{"name": "type", "type": "enum[thought, action, answer]"}, {"name": "thought", "type": "string"}, {"name": "action", "type": "string"}, {"name": "tool_name", "type": "string"}, {"name": "tool_input", "type": "string"}, {"name": "answer", "type": "string"}],
    },
    "ToolInput": {
        "description": """Input to a tool""",
        "fields": [{"name": "tool_name", "type": "string"}, {"name": "input", "type": "string"}],
    },
    "ToolOutput": {
        "description": """Output from a tool""",
        "fields": [{"name": "output", "type": "string"}, {"name": "success", "type": "boolean"}],
    },
    "Observation": {
        "description": """Result of executing an action""",
        "fields": [{"name": "observation", "type": "string"}, {"name": "tool_name", "type": "string"}],
    },
    "TrajectoryEntry": {
        "description": """One step in the trajectory""",
        "fields": [{"name": "step_num", "type": "integer"}, {"name": "thought", "type": "string"}, {"name": "action", "type": "string"}, {"name": "observation", "type": "string"}],
    },
    "UserQuery": {
        "description": """User's question to the agent""",
        "fields": [{"name": "query", "type": "string"}],
    },
    "Answer": {
        "description": """Final answer""",
        "fields": [{"name": "answer", "type": "string"}, {"name": "trajectory", "type": "list<TrajectoryEntry>"}],
    },
}


def build_input(state, schema_name):
    """Build an input dict for an agent call using schema field names.
    Pulls matching keys from state.data."""
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return state.data
    result = {}
    for field in schema["fields"]:
        fname = field["name"]
        if fname in state.data:
            result[fname] = state.data[fname]
    return result


def output_instruction(schema_name):
    """Generate a JSON output instruction string for the LLM."""
    schema = SCHEMAS.get(schema_name)
    if not schema:
        return ""
    fields = ", ".join(f'"{f["name"]}": <{f["type"]}>' for f in schema["fields"])
    return f"\n\nRespond with ONLY valid JSON matching this schema: {{{fields}}}"


def parse_response(response, schema_name):
    """Parse an LLM response according to an output schema.
    Returns a dict of field values, or {"raw": response} if parsing fails."""
    # Try to extract JSON from the response
    text = response.strip()
    # Handle markdown code blocks
    if text.startswith("```"):
        lines = text.split("\n")
        lines = lines[1:]  # skip ```json
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        text = "\n".join(lines)
    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
        return {"value": parsed}
    except json.JSONDecodeError:
        # Try to find JSON object in the response
        start = text.find("{")
        end = text.rfind("}") + 1
        if start >= 0 and end > start:
            try:
                return json.loads(text[start:end])
            except json.JSONDecodeError:
                pass
        return {"raw": response}


# ═══════════════════════════════════════════════════════════
# Stores
# ═══════════════════════════════════════════════════════════

class Store_trajectory_store:
    """Trajectory (queue)"""
    def __init__(self):
        self.queue = []

    def read(self, key=None):
        return self.queue[0] if self.queue else None

    def write(self, value, key=None):
        self.queue.append(value)



# ═══════════════════════════════════════════════════════════
# Agent Wrappers
# ═══════════════════════════════════════════════════════════

def invoke_reasoning_agent(user_message, output_schema=None):
    """Reasoning Agent"""
    system = """You are a ReAct agent. You solve problems by alternating between Thought and Action steps.

For each step, decide on ONE of three step types:
1. "thought" — reason about what to do next (set the thought field)
2. "action" — call a tool (set type to "action", and set tool_name and tool_input)
3. "answer" — provide your final answer when you have enough info (set the answer field)

Available tools:
- search: search Wikipedia for factual information
- lookup: get the full Wikipedia article intro for a specific term
- calculate: evaluate a mathematical expression (e.g. "2**10" or "sqrt(144)")

You will receive the full trajectory so far (all previous Thoughts, Actions, and Observations).
Continue from where you left off. Output only ONE step as JSON.
"""
    if output_schema:
        system += output_instruction(output_schema)
    t0 = time.time()
    result = call_llm(
        model="gemini-3-flash-preview",
        system_prompt=system,
        user_message=user_message,
        temperature=0.7,
        max_tokens=4096,
    )
    trace_call("Reasoning Agent", "gemini-3-flash-preview", system, user_message, result, int((time.time()-t0)*1000))
    return result



# ═══════════════════════════════════════════════════════════
# Tool Implementations
# ═══════════════════════════════════════════════════════════

def tool_search_tool(input_text):
    """Search: Web search for factual information"""
    import requests
    import re as _re
    _headers = {"User-Agent": "OpenClaw/1.0 (agent research project)"} 
    try:
        resp = requests.get("https://en.wikipedia.org/w/api.php", params={
            "action": "query", "list": "search", "srsearch": input_text,
            "format": "json", "srlimit": 5
        }, headers=_headers, timeout=10)
        data = resp.json()
        results = data.get("query", {}).get("search", [])
        if not results:
            return f"No results found for: {input_text}"
        lines = []
        for r in results:
            snippet = _re.sub(r"<[^>]+>", "", r.get("snippet", ""))
            lines.append(f"{r['title']}: {snippet}")
        return "\n".join(lines)
    except Exception as e:
        return f"Search error: {e}"


def tool_lookup_tool(input_text):
    """Lookup: Look up a specific term or entity"""
    import requests
    _headers = {"User-Agent": "OpenClaw/1.0 (agent research project)"}
    try:
        resp = requests.get("https://en.wikipedia.org/w/api.php", params={
            "action": "query", "titles": input_text, "prop": "extracts",
            "exintro": True, "explaintext": True, "format": "json"
        }, headers=_headers, timeout=10)
        data = resp.json()
        pages = data.get("query", {}).get("pages", {})
        for pid, page in pages.items():
            if pid == "-1":
                return f"No Wikipedia article found for: {input_text}"
            extract = page.get("extract", "")
            if extract:
                return extract[:1500]
            return f"Article found but no extract available for: {input_text}"
        return f"No results for: {input_text}"
    except Exception as e:
        return f"Lookup error: {e}"


def tool_calculate_tool(input_text):
    """Calculate: Evaluate a mathematical expression"""
    import math
    _safe_ns = {
        "abs": abs, "round": round, "min": min, "max": max,
        "sum": sum, "pow": pow, "int": int, "float": float,
        "math": math, "pi": math.pi, "e": math.e,
        "sqrt": math.sqrt, "log": math.log, "sin": math.sin,
        "cos": math.cos, "tan": math.tan,
    }
    try:
        result = eval(input_text, {"__builtins__": {}}, _safe_ns)
        return str(result)
    except Exception as e:
        return f"Calculation error: {e}"



# ═══════════════════════════════════════════════════════════
# Agent State
# ═══════════════════════════════════════════════════════════

class AgentState:
    """Runtime state for ReAct"""
    def __init__(self):
        self.trajectory_store = Store_trajectory_store()
        self.data = {}  # current data flowing through the pipeline
        self.iteration = 0


# ═══════════════════════════════════════════════════════════
# Process Functions
# ═══════════════════════════════════════════════════════════

def process_receive_query(state):
    """
    Receive Query
    Accept user query and initialize the trajectory
    """
    print(f"  → Receive Query")

    # Logic from spec
    state.data["trajectory"] = []
    state.data["step_count"] = 0
    state.data["max_steps"] = 10
    print(f"    Query: {state.data.get('query', '')}")
    if state.data.get("_done"):
        return state

    return state


def process_think_or_act(state):
    """
    Think / Act
    Send trajectory to reasoning agent, get next Thought, Action, or Answer
    """
    print(f"  → Think / Act")

    # Logic from spec
    state.data["step_count"] = state.data.get("step_count", 0) + 1
    print(f"    Step {state.data['step_count']}/{state.data.get('max_steps', 10)}")
    if state.data.get("_done"):
        return state

    # Invoke: Get next step
    reasoning_agent_input = build_input(state, "ReActInput")
    reasoning_agent_msg = json.dumps(reasoning_agent_input, default=str)
    reasoning_agent_raw = invoke_reasoning_agent(reasoning_agent_msg, output_schema="ReActStep")
    reasoning_agent_result = parse_response(reasoning_agent_raw, "ReActStep")
    # Merge output fields into state.data
    state.data.update(reasoning_agent_result)
    state.data["re_act_step"] = reasoning_agent_result
    state.data["think_or_act_result"] = reasoning_agent_result
    print(f"    ← Reasoning Agent: {reasoning_agent_result}")

    return state


def process_check_step_type(state):
    """
    Step type?
    """
    print(f"  → Step type?")

    # Gate: type == answer
    # Branch: is answer → emit_answer
    # Branch: is thought or action → check_action

    if state.data.get("type") == "answer":
        print(f"    → is answer")
        return "emit_answer"
    else:
        print(f"    → is thought or action")
        return "check_action"


def process_check_action(state):
    """
    Has action?
    """
    print(f"  → Has action?")

    # Gate: tool_name is not empty
    # Branch: no tool_name (thought only) → record_step
    # Branch: has tool_name → execute_action

    if bool(state.data.get("tool_name")):
        print(f"    → has tool_name")
        return "execute_action"
    else:
        print(f"    → no tool_name (thought only)")
        return "record_step"


def process_execute_action(state):
    """
    Execute Action
    Run the tool specified in the action and capture observation
    """
    print(f"  → Execute Action")

    # Logic from spec
    action = state.data.get("action", "")
    tool_name = state.data.get("tool_name", "search")
    tool_input = state.data.get("tool_input", action)
    print(f"    Action[{tool_name}]: {tool_input[:100]}")
    if state.data.get("_done"):
        return state

    # Tool dispatch
    _tool_name = state.data.get("tool_name", "").lower().strip()
    _tool_input = str(state.data.get("tool_input", state.data.get("action", "")))
    if _tool_name == "search":
        _tool_result = tool_search_tool(_tool_input)
    elif _tool_name == "lookup":
        _tool_result = tool_lookup_tool(_tool_input)
    elif _tool_name == "calculate":
        _tool_result = tool_calculate_tool(_tool_input)
    else:
        _tool_result = f"Unknown tool: {_tool_name}. Available: search, lookup, calculate"
    state.data["observation"] = _tool_result
    print(f"    Observation: {_tool_result[:200]}")

    return state


def process_record_step(state):
    """
    Record Step
    Append the current step (thought/action/observation) to trajectory
    """
    print(f"  → Record Step")

    # Logic from spec
    step = {
        "step_num": state.data.get("step_count", 0),
        "thought": state.data.get("thought", ""),
        "action": state.data.get("action", ""),
        "observation": state.data.get("observation", ""),
    }
    trajectory = state.data.get("trajectory", [])
    trajectory.append(step)
    state.data["trajectory"] = trajectory
    print(f"    Trajectory length: {len(trajectory)}")
    if state.data.get("_done"):
        return state

    # Write: Persist step
    trajectory_store_write = build_input(state, "TrajectoryEntry")
    state.trajectory_store.write(trajectory_store_write)

    return state


def process_check_max_steps(state):
    """
    Max steps?
    """
    print(f"  → Max steps?")

    # Gate: step_count >= max_steps
    # Branch: under limit → think_or_act
    # Branch: at limit → emit_answer

    if (state.data.get("step_count", 0)) >= (state.data.get("max_steps", 0)):
        print(f"    → at limit")
        return "emit_answer"
    else:
        print(f"    → under limit")
        return "think_or_act"


def process_emit_answer(state):
    """
    Emit Answer
    Return the final answer to the user
    """
    print(f"  → Emit Answer")

    # Logic from spec
    answer = state.data.get("answer", state.data.get("thought", "No answer found"))
    print(f"    Final Answer: {answer[:200]}")
    state.data["_done"] = True
    if state.data.get("_done"):
        return state

    return state


# ═══════════════════════════════════════════════════════════
# State Machine Executor
# ═══════════════════════════════════════════════════════════

PROCESSES = {
    "receive_query": process_receive_query,
    "think_or_act": process_think_or_act,
    "check_step_type": process_check_step_type,
    "check_action": process_check_action,
    "execute_action": process_execute_action,
    "record_step": process_record_step,
    "check_max_steps": process_check_max_steps,
    "emit_answer": process_emit_answer,
}

TRANSITIONS = {
    "receive_query": "think_or_act",
    "think_or_act": "check_step_type",
    # "check_step_type": determined by gate logic
    # "check_action": determined by gate logic
    "execute_action": "record_step",
    "record_step": "check_max_steps",
    # "check_max_steps": determined by gate logic
    "emit_answer": None,  # terminal
}


MAX_ITERATIONS = 100


def run(initial_data=None):
    """ReAct — main execution loop"""
    state = AgentState()
    if initial_data:
        state.data.update(initial_data)

    current = "receive_query"
    print(f"\n════════════════════════════════════════════════════════════")
    print(f"  ReAct")
    print(f"  Reason + Act agent that interleaves thinking with tool use to solve problems")
    print(f"════════════════════════════════════════════════════════════\n")

    while current and state.iteration < MAX_ITERATIONS:
        state.iteration += 1
        print(f"\n[Iteration {state.iteration}] State: {current}")

        process_fn = PROCESSES.get(current)
        if not process_fn:
            print(f"  Unknown process: {current}")
            break

        result = process_fn(state)

        if current in ['check_step_type', 'check_action', 'check_max_steps']:
            current = result
        else:
            current = TRANSITIONS.get(current)

        # Fan-out: if transition is a list, run all branches sequentially
        while isinstance(current, list):
            _targets = current
            for _ft in _targets:
                state.iteration += 1
                print(f"\n[Iteration {state.iteration}] State: {_ft} (fan-out)")
                _fn = PROCESSES.get(_ft)
                if _fn:
                    _fn(state)
            current = TRANSITIONS.get(_targets[-1])

        if current is None or state.data.get("_done"):
            print("\n  [DONE] Reached terminal state.")
            break

    _clean_exit = state.iteration < MAX_ITERATIONS
    if state.iteration >= MAX_ITERATIONS:
        print(f"\n  [STOPPED] Max iterations ({MAX_ITERATIONS}) reached.")
        _clean_exit = False

    dump_trace(iterations=state.iteration, clean_exit=_clean_exit)
    print(f"\nFinal state.data keys: {list(state.data.keys())}")
    return state


if __name__ == "__main__":
    initial = {}
    initial["query"] = input("Enter query: ")
    run(initial)