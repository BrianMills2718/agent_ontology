# ===================================================================
# Meta-Prompting Agent -- Agent Spec (Agent Ontology v0.2)
# ===================================================================
# Implements the Meta-Prompting pattern.
#
# A meta-agent analyzes a user task, dynamically generates specialized
# sub-prompts, spawns worker agents with those generated prompts, and
# orchestrates a negotiation protocol to resolve conflicts between
# worker outputs. Supports recursive decomposition for complex tasks.
# This tests: dynamic prompt generation, recursive agent spawning,
# protocol for task negotiation, and multi-level delegation.

name: "Meta-Prompting"
version: "1.0"
description: "Meta-Prompting architecture: a meta-agent dynamically generates specialized sub-prompts, delegates to spawned worker agents, and uses a negotiation protocol to reconcile their outputs into a final answer."
entry_point: receive_task

# -- Entities -------------------------------------------------------

entities:

  - id: meta_agent
    type: agent
    label: "Meta Agent"
    model: gemini-3-flash-preview
    system_prompt: |
      You are a Meta-Prompting orchestrator. Given a complex task, your job is to:
      1. Analyze the task to identify what specialized expertise is needed.
      2. Decompose it into sub-tasks, each requiring a distinct skill.
      3. For each sub-task, generate a precise, specialized system prompt
         that will be used to configure a worker agent.
      4. Specify whether any sub-task requires recursive decomposition
         (is_complex = true if the sub-task itself needs further breakdown).

      Output JSON with "analysis" (string), "sub_tasks" (list of objects, each with
      "sub_task_id" (string), "description" (string), "generated_prompt" (string),
      "required_expertise" (string), "is_complex" (boolean), and
      "depends_on" (list of sub_task_id strings)).
    input_schema: MetaAgentInput
    output_schema: TaskDecomposition

  - id: worker_agent
    type: agent
    label: "Dynamic Worker Agent"
    model: gemini-3-flash-preview
    system_prompt: |
      You are a specialized worker agent. Your system prompt has been dynamically
      generated by a meta-agent to match the specific expertise needed for this
      sub-task. Follow the specialized instructions precisely.
      Output JSON with "result" (string), "confidence" (float 0-1), and
      "needs_clarification" (boolean, true if the sub-task is ambiguous).
    input_schema: WorkerInput
    output_schema: WorkerOutput

  - id: integrator_agent
    type: agent
    label: "Integrator Agent"
    model: gemini-3-flash-preview
    system_prompt: |
      You are an integration agent. You receive results from multiple specialized
      worker agents that each handled a sub-task. Your job is to:
      1. Verify consistency across worker outputs.
      2. Resolve conflicts or contradictions.
      3. Integrate all sub-task results into a single coherent answer.
      4. Assign a completeness score (1-10) indicating how well all sub-tasks
         were addressed.
      Output JSON with "integrated_answer" (string), "completeness_score" (integer 1-10),
      "conflicts_resolved" (list of strings), and "gaps_identified" (list of strings).
    input_schema: IntegratorInput
    output_schema: IntegratorOutput

  - id: task_registry
    type: store
    label: "Task Registry"
    store_type: kv
    schema: TaskRegistryEntry
    retention: session

  - id: prompt_library
    type: store
    label: "Prompt Library"
    store_type: kv
    schema: GeneratedPrompt
    retention: session

  - id: user
    type: human
    label: "User"

# -- Processes ------------------------------------------------------

processes:

  - id: receive_task
    type: step
    label: "Receive Task"
    description: "Accept user task and initialize meta-prompting state"
    data_out: MetaAgentInput
    logic: |
      state.data["depth"] = 0
      state.data["max_depth"] = 3
      state.data["completed_sub_tasks"] = {}
      state.data["pending_sub_tasks"] = []
      state.data["generated_prompts"] = {}
      state.data["worker_results"] = []
      print(f"    Task: {state.data.get('task', '')[:100]}")

  - id: decompose_task
    type: step
    label: "Decompose Task"
    description: "Invoke the meta-agent to analyze and decompose the task into sub-tasks with generated prompts"
    data_in: MetaAgentInput
    data_out: TaskDecomposition
    logic: |
      depth = state.data.get("depth", 0)
      print(f"    Decomposing at depth {depth}...")

  - id: register_sub_tasks
    type: step
    label: "Register Sub-Tasks"
    description: "Store generated sub-tasks and their prompts, determine execution order"
    logic: |
      sub_tasks = state.data.get("sub_tasks", [])
      prompts = state.data.get("generated_prompts", {})
      for st in sub_tasks:
          st_id = st.get("sub_task_id", "")
          prompts[st_id] = st.get("generated_prompt", "")
      state.data["generated_prompts"] = prompts
      # Build execution queue respecting dependencies
      pending = [st for st in sub_tasks if st.get("sub_task_id") not in state.data.get("completed_sub_tasks", {})]
      state.data["pending_sub_tasks"] = pending
      state.data["current_sub_task_idx"] = 0
      print(f"    Registered {len(pending)} sub-tasks with generated prompts")

  - id: check_pending
    type: gate
    label: "Sub-tasks remaining?"
    condition: "current_sub_task_idx < len(pending_sub_tasks)"
    branches:
      - condition: "sub-tasks remaining"
        target: prepare_worker
      - condition: "all sub-tasks done"
        target: integrate_results

  - id: prepare_worker
    type: step
    label: "Prepare Worker"
    description: "Configure the next worker agent with the dynamically generated prompt"
    logic: |
      idx = state.data.get("current_sub_task_idx", 0)
      pending = state.data.get("pending_sub_tasks", [])
      if idx < len(pending):
          sub_task = pending[idx]
          state.data["current_sub_task"] = sub_task
          state.data["worker_prompt"] = sub_task.get("generated_prompt", "")
          state.data["worker_description"] = sub_task.get("description", "")
          state.data["worker_expertise"] = sub_task.get("required_expertise", "")
          state.data["is_complex"] = sub_task.get("is_complex", False)
          # Resolve dependencies
          depends = sub_task.get("depends_on", [])
          completed = state.data.get("completed_sub_tasks", {})
          state.data["dependency_context"] = [completed.get(d, "") for d in depends if d in completed]
          print(f"    Preparing worker for: {sub_task.get('sub_task_id', '')} ({sub_task.get('required_expertise', '')})")

  - id: check_complexity
    type: gate
    label: "Needs recursive decomposition?"
    condition: "is_complex == True and depth < max_depth"
    branches:
      - condition: "complex sub-task, recurse"
        target: recurse_decomposition
      - condition: "simple sub-task, execute"
        target: execute_worker

  - id: recurse_decomposition
    type: spawn
    label: "Recursive Decomposition"
    description: "Recursively decompose a complex sub-task by spawning a new meta-prompting cycle"
    template: meta_agent
    cardinality: 1
    recursive: true
    max_depth: 3
    aggregation: collect

  - id: execute_worker
    type: step
    label: "Execute Worker"
    description: "Invoke the worker agent with the dynamically generated prompt and sub-task"
    data_in: WorkerInput
    data_out: WorkerOutput
    logic: |
      expertise = state.data.get("worker_expertise", "general")
      description = state.data.get("worker_description", "")
      print(f"    Executing worker [{expertise}]: {description[:80]}")

  - id: collect_worker_result
    type: step
    label: "Collect Worker Result"
    description: "Store worker result and advance to the next sub-task"
    logic: |
      idx = state.data.get("current_sub_task_idx", 0)
      sub_task = state.data.get("current_sub_task", {})
      st_id = sub_task.get("sub_task_id", f"sub_{idx}")
      result = state.data.get("result", "")
      confidence = state.data.get("confidence", 0.0)
      # Store result
      completed = state.data.get("completed_sub_tasks", {})
      completed[st_id] = result
      state.data["completed_sub_tasks"] = completed
      # Track for integration
      worker_results = state.data.get("worker_results", [])
      worker_results.append({
          "sub_task_id": st_id,
          "result": result,
          "confidence": confidence,
          "expertise": state.data.get("worker_expertise", ""),
      })
      state.data["worker_results"] = worker_results
      state.data["current_sub_task_idx"] = idx + 1
      print(f"    Collected result for {st_id} (confidence={confidence})")

  - id: negotiate_conflicts
    type: protocol
    label: "Conflict Negotiation"
    description: "Multi-party protocol where workers with conflicting outputs negotiate resolution"
    participants:
      - entity: meta_agent
        role: mediator
      - entity: worker_agent
        role: disputant
      - entity: integrator_agent
        role: arbitrator
    termination: "consensus reached or mediator decides after 2 rounds"
    max_rounds: 2
    rules:
      - "Each disputant presents evidence for their position"
      - "Mediator identifies the core conflict"
      - "Arbitrator proposes resolution"
      - "Disputants accept or counter-propose"

  - id: integrate_results
    type: step
    label: "Integrate Results"
    description: "Invoke the integrator agent to combine all worker results"
    data_in: IntegratorInput
    data_out: IntegratorOutput
    logic: |
      results = state.data.get("worker_results", [])
      print(f"    Integrating {len(results)} worker results...")

  - id: check_completeness
    type: gate
    label: "Integration complete?"
    condition: "completeness_score >= 7"
    branches:
      - condition: "complete enough"
        target: finalize_output
      - condition: "gaps identified"
        target: handle_gaps

  - id: handle_gaps
    type: step
    label: "Handle Gaps"
    description: "Generate additional sub-tasks to fill identified gaps"
    logic: |
      gaps = state.data.get("gaps_identified", [])
      depth = state.data.get("depth", 0) + 1
      state.data["depth"] = depth
      # Convert gaps into a new task for re-decomposition
      state.data["task"] = f"Fill the following gaps in the previous answer: {'; '.join(gaps)}"
      print(f"    Handling {len(gaps)} gaps at depth {depth}")

  - id: gap_limit_check
    type: gate
    label: "Gap filling allowed?"
    condition: "depth < max_depth"
    branches:
      - condition: "depth under limit"
        target: decompose_task
      - condition: "depth limit reached"
        target: finalize_output

  - id: finalize_output
    type: step
    label: "Finalize Output"
    description: "Return the final integrated answer with metadata"
    data_out: MetaPromptingResult
    logic: |
      completeness = state.data.get("completeness_score", 0)
      worker_count = len(state.data.get("worker_results", []))
      depth = state.data.get("depth", 0)
      prompts_generated = len(state.data.get("generated_prompts", {}))
      print(f"    Finalizing: {worker_count} workers used, {prompts_generated} prompts generated, depth={depth}")
      state.data["final_answer"] = state.data.get("integrated_answer", "")
      state.data["final_completeness"] = completeness
      state.data["total_workers"] = worker_count
      state.data["total_prompts_generated"] = prompts_generated
      state.data["_done"] = True

# -- Edges ----------------------------------------------------------

edges:

  # Entry
  - type: flow
    from: user
    to: receive_task
    label: "Submit task"
    data: MetaAgentInput

  - type: flow
    from: receive_task
    to: decompose_task
    label: "Start decomposition"

  # Meta-agent invocation
  - type: invoke
    from: decompose_task
    to: meta_agent
    label: "Analyze and decompose task"
    input: MetaAgentInput
    output: TaskDecomposition

  - type: flow
    from: decompose_task
    to: register_sub_tasks
    label: "Register sub-tasks"

  # Write generated prompts to prompt library
  - type: write
    from: register_sub_tasks
    to: prompt_library
    label: "Store generated prompts"
    data: GeneratedPrompt

  # Write task registry
  - type: write
    from: register_sub_tasks
    to: task_registry
    label: "Register sub-tasks"
    data: TaskRegistryEntry

  - type: flow
    from: register_sub_tasks
    to: check_pending
    label: "Check queue"

  # Pending gate branches
  - type: branch
    from: check_pending
    to: prepare_worker
    condition: "current_sub_task_idx < len(pending_sub_tasks)"

  - type: branch
    from: check_pending
    to: integrate_results
    condition: "current_sub_task_idx >= len(pending_sub_tasks)"

  - type: flow
    from: prepare_worker
    to: check_complexity
    label: "Check complexity"

  # Read dependency context from task registry
  - type: read
    from: prepare_worker
    to: task_registry
    label: "Read dependency results"

  # Complexity gate branches
  - type: branch
    from: check_complexity
    to: recurse_decomposition
    condition: "is_complex == True and depth < max_depth"

  - type: branch
    from: check_complexity
    to: execute_worker
    condition: "is_complex == False or depth >= max_depth"

  # Recursive spawn
  - type: invoke
    from: recurse_decomposition
    to: meta_agent
    label: "Recursive decomposition"
    input: MetaAgentInput
    output: TaskDecomposition

  - type: flow
    from: recurse_decomposition
    to: collect_worker_result
    label: "Collect recursive result"

  # Worker invocation
  - type: invoke
    from: execute_worker
    to: worker_agent
    label: "Execute with generated prompt"
    input: WorkerInput
    output: WorkerOutput

  - type: flow
    from: execute_worker
    to: collect_worker_result
    label: "Collect result"

  - type: flow
    from: collect_worker_result
    to: check_pending
    label: "Next sub-task"

  # Worker iteration loop
  - type: loop
    from: collect_worker_result
    to: check_pending
    label: "Process next sub-task"
    condition: "current_sub_task_idx < len(pending_sub_tasks)"

  # Integration
  - type: invoke
    from: integrate_results
    to: integrator_agent
    label: "Integrate worker results"
    input: IntegratorInput
    output: IntegratorOutput

  - type: flow
    from: integrate_results
    to: negotiate_conflicts
    label: "Resolve conflicts"

  - type: flow
    from: negotiate_conflicts
    to: check_completeness
    label: "Post-negotiation check"

  # Completeness gate branches
  - type: branch
    from: check_completeness
    to: finalize_output
    condition: "completeness_score >= 7"

  - type: branch
    from: check_completeness
    to: handle_gaps
    condition: "completeness_score < 7"

  - type: flow
    from: handle_gaps
    to: gap_limit_check
    label: "Check gap fill limit"

  # Gap limit gate branches
  - type: branch
    from: gap_limit_check
    to: decompose_task
    condition: "depth < max_depth"

  - type: branch
    from: gap_limit_check
    to: finalize_output
    condition: "depth >= max_depth"

  # Gap fill loop
  - type: loop
    from: gap_limit_check
    to: decompose_task
    label: "Fill gaps via re-decomposition"
    condition: "depth < max_depth"

# -- Schemas --------------------------------------------------------

schemas:

  - name: MetaAgentInput
    description: "Input to the meta-agent for task analysis"
    fields:
      - { name: task, type: string }
      - { name: depth, type: integer }
      - { name: context, type: string }

  - name: TaskDecomposition
    description: "Meta-agent's task decomposition with generated prompts"
    fields:
      - { name: analysis, type: string }
      - { name: sub_tasks, type: "list<SubTaskSpec>" }

  - name: SubTaskSpec
    description: "Specification for a single sub-task"
    fields:
      - { name: sub_task_id, type: string }
      - { name: description, type: string }
      - { name: generated_prompt, type: string }
      - { name: required_expertise, type: string }
      - { name: is_complex, type: boolean }
      - { name: depends_on, type: "list<string>" }

  - name: WorkerInput
    description: "Input to a worker agent"
    fields:
      - { name: sub_task_description, type: string }
      - { name: generated_prompt, type: string }
      - { name: dependency_context, type: "list<string>" }
      - { name: original_task, type: string }

  - name: WorkerOutput
    description: "Output from a worker agent"
    fields:
      - { name: result, type: string }
      - { name: confidence, type: float }
      - { name: needs_clarification, type: boolean }

  - name: IntegratorInput
    description: "Input to the integrator agent"
    fields:
      - { name: task, type: string }
      - { name: worker_results, type: "list<WorkerResultEntry>" }
      - { name: conflicts_detected, type: "list<string>" }

  - name: WorkerResultEntry
    description: "A single worker's result with metadata"
    fields:
      - { name: sub_task_id, type: string }
      - { name: result, type: string }
      - { name: confidence, type: float }
      - { name: expertise, type: string }

  - name: IntegratorOutput
    description: "Output from the integrator agent"
    fields:
      - { name: integrated_answer, type: string }
      - { name: completeness_score, type: integer }
      - { name: conflicts_resolved, type: "list<string>" }
      - { name: gaps_identified, type: "list<string>" }

  - name: TaskRegistryEntry
    description: "Entry in the task registry tracking sub-task status"
    fields:
      - { name: sub_task_id, type: string }
      - { name: status, type: "enum[pending, in_progress, completed, failed]" }
      - { name: result, type: string }
      - { name: assigned_prompt, type: string }

  - name: GeneratedPrompt
    description: "A dynamically generated prompt stored in the prompt library"
    fields:
      - { name: sub_task_id, type: string }
      - { name: prompt_text, type: string }
      - { name: required_expertise, type: string }
      - { name: depth, type: integer }

  - name: MetaPromptingResult
    description: "Final result from the meta-prompting process"
    fields:
      - { name: final_answer, type: string }
      - { name: final_completeness, type: integer }
      - { name: total_workers, type: integer }
      - { name: total_prompts_generated, type: integer }
      - { name: worker_results, type: "list<WorkerResultEntry>" }
      - { name: generated_prompts, type: "list<GeneratedPrompt>" }
